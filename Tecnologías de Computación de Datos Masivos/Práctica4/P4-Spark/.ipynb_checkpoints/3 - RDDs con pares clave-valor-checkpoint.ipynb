{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RDDs con pares clave/valor (*Pair RDDs*)\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Tipos de datos muy usados en Big Data (MapReduce)\n",
    "\n",
    "-   Spark dispone de operaciones especiales para su manejo\n",
    "               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación de *Pair RDDs*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   A partir de una lista de tuplas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n",
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "from test_helper import Test\n",
    "from __future__ import print_function\n",
    "\n",
    "prdd = sc.parallelize([('a',2), ('b',5), ('a',3)])\n",
    "Test.assertEquals(prdd.collect(), [('a', 2), ('b', 5), ('a', 3)])\n",
    "prdd = sc.parallelize(zip(['a', 'b', 'c'], range(3)))\n",
    "Test.assertEquals(prdd.collect(), [('a', 0), ('b', 1), ('c', 2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   A partir de otro RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Par (1ª palabra, línea): (u'-S\\xed', u'-S\\xed -respondi\\xf3 don Quijote-, y muchos; y es raz\\xf3n que los haya, para adorno')\n",
      "\n",
      "1 test passed.\n",
      "1 test passed.\n",
      "Particionado del RDD: [['a', 'b'], ['c', 'd'], ['e', 'f', 'g', 'h']]\n",
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "linesrdd = sc.textFile(\"datos/quijote.txt\")\n",
    "prdd = linesrdd.map(lambda x: (x.split(\" \")[0], x))\n",
    "print(\"Par (1ª palabra, línea): {0}\\n\".format(prdd.takeSample(False, 1)[0]))\n",
    "\n",
    "# keyBy(f): Crea tuplas de los elementos del RDD usando f para obtener la clave.\n",
    "nrdd = sc.parallelize(xrange(2,5))\n",
    "prdd = nrdd.keyBy(lambda x: x*x)\n",
    "Test.assertEquals(prdd.collect(), [(4, 2), (9, 3), (16, 4)])\n",
    "\n",
    "# zipWithIndex(): Zipea el RDD con los índices de sus elementos.\n",
    "# Este método dispara un spark job cuando el RDD tiene más de una partición.\n",
    "rdd = sc.parallelize([\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\"], 3)\n",
    "prdd = rdd.zipWithIndex()\n",
    "Test.assertEquals(prdd.collect(), [('a',0),('b',1),('c',2),('d',3),('e',4),('f',5),('g',6),('h',7)])\n",
    "\n",
    "# zipWithUniqueId(): Zipea el RDD con identificadores únicos (long) para cada elemento.\n",
    "# Los elementos en la partición k-ésima obtienen los ids k, n+k, 2*n+k,... siendo n = nº de particiones\n",
    "# No dispara un trabajo spark\n",
    "rdd = sc.parallelize([\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\"], 3)\n",
    "print(\"Particionado del RDD: {0}\".format(rdd.glom().collect()))\n",
    "prdd = rdd.zipWithUniqueId()\n",
    "Test.assertEquals(prdd.collect(), [('a',0),('b',3),('c',1),('d',4),('e',2),('f',5),('g',8),('h',11)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mediante un zip de dos RDDs\n",
    "    - Los RDDs deben tener el mismo número de particiones y el mismo número de elementos en cada partición"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "rdd1 = sc.parallelize(xrange(0,5), 2)\n",
    "rdd2 = sc.parallelize(range(1000, 1005), 2)\n",
    "prdd = rdd1.zip(rdd2)\n",
    "Test.assertEquals(prdd.collect(), [(0, 1000), (1, 1001), (2, 1002), (3, 1003), (4, 1004)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformaciones sobre un RDD clave/valor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformaciones de agregación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   `reduceByKey(func)`/`foldByKey(func)` devuelven un RDD con los valores con la misma\n",
    "    clave reducidos usando `func`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "from operator import add\n",
    "prdd   = sc.parallelize([(\"a\", 2), (\"b\", 5), (\"a\", 8)]).cache()\n",
    "redrdd = prdd.reduceByKey(add)\n",
    "Test.assertEquals(redrdd.collect(), [('a',10), ('b',5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   `groupByKey()` agrupa valores con la misma clave\n",
    "    - Operación muy costosa en comunicaciones\n",
    "    - Mejor usar operaciones de reducción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "groupdd = prdd.groupByKey()\n",
    "Test.assertEquals([(k, list(v)) for k,v in groupdd.collect()], [('a',[2,8]), ('b',[5])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `combineByKey(createCombiner(func1), mergeValue(func2), mergeCombiners(func3))`\n",
    "    - Función general para agregación por clave, similar a `aggregate`\n",
    "    - Especifica tres funciones:\n",
    "\n",
    "     1.  `createCombiner` al recorrer los elementos de cada partición, si\n",
    "        nos encontramos una clave nueva se crea un acumulador y se\n",
    "        inicializa con `func1`\n",
    "\n",
    "     2.  `mergeValue` mezcla los valores de cada clave en cada partición usando `func2`\n",
    "\n",
    "     3.  `mergeCombiners` mezcla los resultados de las diferentes\n",
    "        particiones mediante `func3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n",
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "# Calcula la media por clave usando combineByKey()\n",
    "l = sc.parallelize([(\"a\",2), (\"b\",5), (\"a\",8), (\"b\", 6), (\"b\",1)])\n",
    "# Para cada clave, suma y cuenta los valores\n",
    "sumCount = l.combineByKey(\n",
    "           (lambda x: (x, 1)),\n",
    "           (lambda x, y: (x[0]+y, x[1]+1)),\n",
    "           (lambda x, y: (x[0]+y[0], x[1]+y[1])))\n",
    "Test.assertEquals(sumCount.collect(), [('a', (10, 2)), ('b', (12, 3))])\n",
    "\n",
    "# Obtiene la media de los valores\n",
    "m = sumCount.mapValues(lambda v: v[0]/v[1])\n",
    "Test.assertEquals(m.collect(), [('a', 5), ('b', 4)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformaciones sobre claves o valores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   `keys()` devuelve un RDD con las claves\n",
    "-   `values()` devuelve un RDD con los valores\n",
    "-   `sortByKey()` devuelve un RDD clave/valor con las claves ordenadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RDD completo:                 [('a', 2), ('b', 5), ('a', 8)]\n",
      "RDD con las claves:           ['a', 'b', 'a']\n",
      "RDD con los valores:          [2, 5, 8]\n",
      "RDD con las claves ordenadas: [('a', 2), ('a', 8), ('b', 5)]\n"
     ]
    }
   ],
   "source": [
    "print(\"RDD completo: {0:>46s}\".format(prdd.collect()))\n",
    "print(\"RDD con las claves: {0:>25s}\".format(prdd.keys().collect()))\n",
    "print(\"RDD con los valores: {0:>18}\".format(prdd.values().collect()))\n",
    "print(\"RDD con las claves ordenadas: {0}\".format(prdd.sortByKey().collect()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   `mapValues(func)` devuelve un RDD aplicando una función sobre los\n",
    "    valores\n",
    "-   `flatMapValues(func)` devuelve un RDD aplicando una función sobre\n",
    "    los valores y “aplanando” la salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n",
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "mapv = prdd.mapValues(lambda x: (x, 10*x))\n",
    "Test.assertEquals(mapv.collect(),  [('a', (2, 20)), ('b', (5, 50)), ('a', (8, 80))])\n",
    "fmapv = prdd.flatMapValues(lambda x: (x, 10*x))\n",
    "Test.assertEquals(fmapv.collect(), [('a', 2), ('a', 20), ('b', 5), ('b', 50), ('a', 8), ('a', 80)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformaciones sobre dos RDDs clave/valor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   `join`/`rightOuterJoin`/`leftOuterJoin`/`fullOuterJoin` realiza\n",
    "    inner/outer joins entre los dos RDDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n",
      "1 test passed.\n",
      "1 test passed.\n",
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "rdd1 = sc.parallelize([(\"a\",2), (\"b\",5), (\"a\",8)]).cache()\n",
    "rdd2 = sc.parallelize([(\"c\",7), (\"a\",1)]).cache()\n",
    "\n",
    "rdd3 = rdd1.join(rdd2)\n",
    "Test.assertEquals(rdd3.collect(), [('a',(2,1)),('a',(8,1))])\n",
    "\n",
    "rdd4 = rdd1.leftOuterJoin(rdd2)\n",
    "Test.assertEquals(rdd4.collect(), [('a',(2,1)),('a',(8,1)),('b',(5,None))])\n",
    "\n",
    "rdd5 = rdd1.rightOuterJoin(rdd2)\n",
    "Test.assertEquals(rdd5.collect(), [('a',(2,1)),('a',(8,1)),('c',(None,7))])\n",
    "\n",
    "rdd6 = rdd1.fullOuterJoin(rdd2)\n",
    "Test.assertEquals(rdd6.collect(), [('a',(2,1)),('a',(8,1)),('c',(None,7)),('b',(5,None))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   `subtractByKey` elimina elementos con una clave presente en otro RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "rdd7 = rdd1.subtractByKey(rdd2)\n",
    "Test.assertEquals(rdd7.collect(), [('b', 5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   `cogroup` agrupa los datos que comparten la misma clave en ambos\n",
    "    RDDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "rdd8 = rdd1.cogroup(rdd2)\n",
    "Test.assertEquals(rdd8.mapValues(lambda v: [list(l) for l in v]).collectAsMap(),\n",
    "                 {'a': [[2, 8], [1]], 'b': [[5], []],'c': [[], [7]]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acciones sobre RDDs clave/valor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   `countByKey()` devuelve un mapa indicando el número de ocurrencias de cada clave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "prdd = sc.parallelize([(\"a\", 2), (\"b\", 5), (\"a\", 8)]).cache()\n",
    "countMap = prdd.countByKey()\n",
    "Test.assertEquals(countMap, {'a': 2, 'b': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   `collectAsMap()` obtiene el RDD en forma de mapa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "rddMap = prdd.collectAsMap()\n",
    "Test.assertEquals(rddMap, {'a': 8, 'b': 5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   `lookup(key)` devuelve una lista con los valores asociados con una clave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "listA = prdd.lookup('a')\n",
    "Test.assertEquals(listA, [2, 8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Práctica 2\n",
    "\n",
    "A partir del fichero cite75_99.txt obtener el número de citas que recibe cada patente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n",
      "1 test passed.\n",
      "1 test passed.\n",
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "rdd = sc.textFile(\"datos/patentes-mini/cite75_99.txt\")\n",
    "\n",
    "prdd = sc.parallelize(rdd.map(lambda x: (x.split(\",\")[1].encode('utf-8'),x.split(\",\")[0].encode('utf-8'))).collect()).cache()\n",
    "\n",
    "ncitas = prdd.combineByKey(\n",
    "           (lambda x: (x, 1)),\n",
    "           (lambda x, y: (x[0]+y, x[1]+1)),\n",
    "           (lambda x, y: (x[0]+y[0], x[1]+y[1]))).mapValues(lambda v: v[1])\n",
    "\n",
    "\n",
    "Test.assertEquals(ncitas.lookup('3986997'), [2])\n",
    "Test.assertEquals(ncitas.lookup('4418284'), [2])\n",
    "Test.assertEquals(ncitas.lookup('4314227'), [3])\n",
    "Test.assertEquals(ncitas.lookup('3911418'), [3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir del fichero apat63_99.txt, obten la media de reivindicaciones (\"claims\", campo 8) de las patentes por países (\"country\", campo 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n",
      "1 test passed.\n",
      "1 test passed.\n",
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "def pasarEntero(valor):\n",
    "    if(valor == \"\"): return 0;\n",
    "    else: return int(valor)\n",
    "\n",
    "rdd = sc.textFile(\"datos/patentes-mini/apat63_99.txt\")\n",
    "\n",
    "prdd = rdd.map(lambda x: (x.split(\",\")[4].encode('utf-8'),x.split(\",\")[8].encode('utf-8')))\n",
    "\n",
    "#print (prdd.collect())\n",
    "\n",
    "prdd_filtrado = prdd.filter(lambda x: x[0] != '\\\"COUNTRY\\\"')\n",
    "\n",
    "# Aplica un filtro para eliminar la cabecera y crea un RDD clave valor con (country, claims)\n",
    "# además, hay que pasar los valores a entero para poder sumarlos\n",
    "countryclaims = prdd_filtrado.map(lambda x: (x[0],pasarEntero(x[1])))\n",
    "#print (countryclaims.collect())\n",
    "#print (countryclaims.lookup('\"GB\"'))\n",
    "# Usa combineByKey para que, para cada clave, sume y cuente los valores\n",
    "sumCount = countryclaims.combineByKey(\n",
    "           (lambda x: (x, 1)),\n",
    "           (lambda x, y: (x[0]+y, x[1]+1)),\n",
    "           (lambda x, y: (x[0]+y[0], x[1]+y[1])))\n",
    "\n",
    "Test.assertEquals(sumCount.lookup('\"GB\"'), [(4650, 504)])\n",
    "Test.assertEquals(sumCount.lookup('\"US\"'), [(135880, 11651)])\n",
    "\n",
    "# Obtiene la media de los valores\n",
    "mean = sumCount.mapValues(lambda v: float(v[0])/v[1])\n",
    "\n",
    "Test.assertEquals(mean.lookup('\"GB\"'), [float(4650)/504])\n",
    "Test.assertEquals(mean.lookup('\"US\"'), [float(135880)/11651])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
