moises@zollkron:~/Tema5-Spark-notebook$ spark-submit --master local[*] sparkpractica.py datos/patentes-mini/cite75_99.txt datos/patentes-mini/apat63_99.seq outdir1 outdir2
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
16/12/20 01:54:15 INFO SparkContext: Running Spark version 2.0.2
16/12/20 01:54:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
16/12/20 01:54:15 WARN Utils: Your hostname, zollkron resolves to a loopback address: 127.0.1.1; using 192.168.1.109 instead (on interface wlan0)
16/12/20 01:54:15 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
16/12/20 01:54:15 INFO SecurityManager: Changing view acls to: moises
16/12/20 01:54:15 INFO SecurityManager: Changing modify acls to: moises
16/12/20 01:54:15 INFO SecurityManager: Changing view acls groups to: 
16/12/20 01:54:15 INFO SecurityManager: Changing modify acls groups to: 
16/12/20 01:54:15 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(moises); groups with view permissions: Set(); users  with modify permissions: Set(moises); groups with modify permissions: Set()
16/12/20 01:54:16 INFO Utils: Successfully started service 'sparkDriver' on port 42124.
16/12/20 01:54:16 INFO SparkEnv: Registering MapOutputTracker
16/12/20 01:54:16 INFO SparkEnv: Registering BlockManagerMaster
16/12/20 01:54:16 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-e489de00-510f-4af2-a31d-b9025a229a2f
16/12/20 01:54:16 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
16/12/20 01:54:16 INFO SparkEnv: Registering OutputCommitCoordinator
16/12/20 01:54:16 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
16/12/20 01:54:16 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
16/12/20 01:54:16 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
16/12/20 01:54:16 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
16/12/20 01:54:16 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.
16/12/20 01:54:16 WARN Utils: Service 'SparkUI' could not bind on port 4045. Attempting port 4046.
16/12/20 01:54:16 INFO Utils: Successfully started service 'SparkUI' on port 4046.
16/12/20 01:54:16 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.1.109:4046
16/12/20 01:54:16 INFO SparkContext: Added file file:/home/moises/Tema5-Spark-notebook/sparkpractica.py at file:/home/moises/Tema5-Spark-notebook/sparkpractica.py with timestamp 1482195256987
16/12/20 01:54:16 INFO Utils: Copying /home/moises/Tema5-Spark-notebook/sparkpractica.py to /tmp/spark-b2d27e6a-bcb4-4d5f-9d5c-4a28dc16341f/userFiles-7942428b-9288-4b13-b17d-e6fd3b75f6a3/sparkpractica.py
16/12/20 01:54:17 INFO Executor: Starting executor ID driver on host localhost
16/12/20 01:54:17 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40171.
16/12/20 01:54:17 INFO NettyBlockTransferService: Server created on 192.168.1.109:40171
16/12/20 01:54:17 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.1.109, 40171)
16/12/20 01:54:17 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.1.109:40171 with 366.3 MB RAM, BlockManagerId(driver, 192.168.1.109, 40171)
16/12/20 01:54:17 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.1.109, 40171)
16/12/20 01:54:18 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 236.5 KB, free 366.1 MB)
16/12/20 01:54:18 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 22.9 KB, free 366.0 MB)
16/12/20 01:54:18 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.1.109:40171 (size: 22.9 KB, free: 366.3 MB)
16/12/20 01:54:18 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:-2
16/12/20 01:54:18 INFO FileInputFormat: Total input paths to process : 1
16/12/20 01:54:18 INFO SparkContext: Starting job: sortByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:44
16/12/20 01:54:18 INFO DAGScheduler: Registering RDD 3 (reduceByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:44)
16/12/20 01:54:18 INFO DAGScheduler: Got job 0 (sortByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:44) with 2 output partitions
16/12/20 01:54:18 INFO DAGScheduler: Final stage: ResultStage 1 (sortByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:44)
16/12/20 01:54:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
16/12/20 01:54:18 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
16/12/20 01:54:18 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[3] at reduceByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:44), which has no missing parents
16/12/20 01:54:18 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 9.2 KB, free 366.0 MB)
16/12/20 01:54:18 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KB, free 366.0 MB)
16/12/20 01:54:18 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.1.109:40171 (size: 5.8 KB, free: 366.3 MB)
16/12/20 01:54:18 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1012
16/12/20 01:54:18 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[3] at reduceByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:44)
16/12/20 01:54:18 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
16/12/20 01:54:18 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0, PROCESS_LOCAL, 5579 bytes)
16/12/20 01:54:18 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1, PROCESS_LOCAL, 5579 bytes)
16/12/20 01:54:18 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
16/12/20 01:54:18 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
16/12/20 01:54:18 INFO Executor: Fetching file:/home/moises/Tema5-Spark-notebook/sparkpractica.py with timestamp 1482195256987
16/12/20 01:54:18 INFO Utils: /home/moises/Tema5-Spark-notebook/sparkpractica.py has been previously copied to /tmp/spark-b2d27e6a-bcb4-4d5f-9d5c-4a28dc16341f/userFiles-7942428b-9288-4b13-b17d-e6fd3b75f6a3/sparkpractica.py
16/12/20 01:54:19 INFO HadoopRDD: Input split: file:/home/moises/Tema5-Spark-notebook/datos/patentes-mini/cite75_99.txt:0+66121
16/12/20 01:54:19 INFO HadoopRDD: Input split: file:/home/moises/Tema5-Spark-notebook/datos/patentes-mini/cite75_99.txt:66121+66122
16/12/20 01:54:19 INFO deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
16/12/20 01:54:19 INFO deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
16/12/20 01:54:19 INFO deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
16/12/20 01:54:19 INFO deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
16/12/20 01:54:19 INFO deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
16/12/20 01:54:19 INFO PythonRunner: Times: total = 485, boot = 317, init = 77, finish = 91
16/12/20 01:54:19 INFO PythonRunner: Times: total = 470, boot = 328, init = 59, finish = 83
16/12/20 01:54:19 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1781 bytes result sent to driver
16/12/20 01:54:19 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1860 bytes result sent to driver
16/12/20 01:54:19 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 911 ms on localhost (1/2)
16/12/20 01:54:19 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1005 ms on localhost (2/2)
16/12/20 01:54:19 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
16/12/20 01:54:19 INFO DAGScheduler: ShuffleMapStage 0 (reduceByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:44) finished in 1,033 s
16/12/20 01:54:19 INFO DAGScheduler: looking for newly runnable stages
16/12/20 01:54:19 INFO DAGScheduler: running: Set()
16/12/20 01:54:19 INFO DAGScheduler: waiting: Set(ResultStage 1)
16/12/20 01:54:19 INFO DAGScheduler: failed: Set()
16/12/20 01:54:19 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[6] at sortByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:44), which has no missing parents
16/12/20 01:54:19 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 7.1 KB, free 366.0 MB)
16/12/20 01:54:19 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.3 KB, free 366.0 MB)
16/12/20 01:54:19 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.1.109:40171 (size: 4.3 KB, free: 366.3 MB)
16/12/20 01:54:19 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1012
16/12/20 01:54:19 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (PythonRDD[6] at sortByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:44)
16/12/20 01:54:19 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
16/12/20 01:54:19 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, partition 0, ANY, 5320 bytes)
16/12/20 01:54:19 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, localhost, partition 1, ANY, 5320 bytes)
16/12/20 01:54:19 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
16/12/20 01:54:19 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
16/12/20 01:54:19 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/12/20 01:54:19 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/12/20 01:54:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
16/12/20 01:54:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
16/12/20 01:54:19 INFO PythonRunner: Times: total = 18, boot = -291, init = 305, finish = 4
16/12/20 01:54:19 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1854 bytes result sent to driver
16/12/20 01:54:19 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 67 ms on localhost (1/2)
16/12/20 01:54:19 INFO PythonRunner: Times: total = 41, boot = -303, init = 340, finish = 4
16/12/20 01:54:19 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1941 bytes result sent to driver
16/12/20 01:54:19 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 89 ms on localhost (2/2)
16/12/20 01:54:19 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
16/12/20 01:54:19 INFO DAGScheduler: ResultStage 1 (sortByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:44) finished in 0,094 s
16/12/20 01:54:19 INFO DAGScheduler: Job 0 finished: sortByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:44, took 1,315248 s
16/12/20 01:54:19 INFO SparkContext: Starting job: sortByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:44
16/12/20 01:54:19 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 157 bytes
16/12/20 01:54:19 INFO DAGScheduler: Got job 1 (sortByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:44) with 2 output partitions
16/12/20 01:54:19 INFO DAGScheduler: Final stage: ResultStage 3 (sortByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:44)
16/12/20 01:54:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
16/12/20 01:54:19 INFO DAGScheduler: Missing parents: List()
16/12/20 01:54:19 INFO DAGScheduler: Submitting ResultStage 3 (PythonRDD[7] at sortByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:44), which has no missing parents
16/12/20 01:54:19 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 7.2 KB, free 366.0 MB)
16/12/20 01:54:19 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 4.4 KB, free 366.0 MB)
16/12/20 01:54:19 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 192.168.1.109:40171 (size: 4.4 KB, free: 366.3 MB)
16/12/20 01:54:19 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1012
16/12/20 01:54:19 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 3 (PythonRDD[7] at sortByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:44)
16/12/20 01:54:19 INFO TaskSchedulerImpl: Adding task set 3.0 with 2 tasks
16/12/20 01:54:19 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 4, localhost, partition 0, ANY, 5321 bytes)
16/12/20 01:54:19 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 5, localhost, partition 1, ANY, 5321 bytes)
16/12/20 01:54:19 INFO Executor: Running task 0.0 in stage 3.0 (TID 4)
16/12/20 01:54:19 INFO Executor: Running task 1.0 in stage 3.0 (TID 5)
16/12/20 01:54:20 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/12/20 01:54:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/12/20 01:54:20 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/12/20 01:54:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/12/20 01:54:20 INFO PythonRunner: Times: total = 42, boot = -59, init = 96, finish = 5
16/12/20 01:54:20 INFO PythonRunner: Times: total = 43, boot = -84, init = 121, finish = 6
16/12/20 01:54:20 INFO Executor: Finished task 1.0 in stage 3.0 (TID 5). 2033 bytes result sent to driver
16/12/20 01:54:20 INFO Executor: Finished task 0.0 in stage 3.0 (TID 4). 2023 bytes result sent to driver
16/12/20 01:54:20 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 5) in 62 ms on localhost (1/2)
16/12/20 01:54:20 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 4) in 64 ms on localhost (2/2)
16/12/20 01:54:20 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
16/12/20 01:54:20 INFO DAGScheduler: ResultStage 3 (sortByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:44) finished in 0,067 s
16/12/20 01:54:20 INFO DAGScheduler: Job 1 finished: sortByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:44, took 0,082260 s
16/12/20 01:54:20 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 236.5 KB, free 365.8 MB)
16/12/20 01:54:20 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 22.9 KB, free 365.8 MB)
16/12/20 01:54:20 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 192.168.1.109:40171 (size: 22.9 KB, free: 366.2 MB)
16/12/20 01:54:20 INFO SparkContext: Created broadcast 4 from sequenceFile at PythonRDD.scala:526
16/12/20 01:54:20 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 236.5 KB, free 365.5 MB)
16/12/20 01:54:20 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 22.9 KB, free 365.5 MB)
16/12/20 01:54:20 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 192.168.1.109:40171 (size: 22.9 KB, free: 366.2 MB)
16/12/20 01:54:20 INFO SparkContext: Created broadcast 5 from broadcast at PythonRDD.scala:527
16/12/20 01:54:20 INFO FileInputFormat: Total input paths to process : 2
16/12/20 01:54:20 INFO SparkContext: Starting job: take at SerDeUtil.scala:203
16/12/20 01:54:20 INFO DAGScheduler: Got job 2 (take at SerDeUtil.scala:203) with 1 output partitions
16/12/20 01:54:20 INFO DAGScheduler: Final stage: ResultStage 4 (take at SerDeUtil.scala:203)
16/12/20 01:54:20 INFO DAGScheduler: Parents of final stage: List()
16/12/20 01:54:20 INFO DAGScheduler: Missing parents: List()
16/12/20 01:54:20 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[13] at map at PythonHadoopUtil.scala:181), which has no missing parents
16/12/20 01:54:20 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 3.2 KB, free 365.5 MB)
16/12/20 01:54:20 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1996.0 B, free 365.5 MB)
16/12/20 01:54:20 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 192.168.1.109:40171 (size: 1996.0 B, free: 366.2 MB)
16/12/20 01:54:20 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1012
16/12/20 01:54:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[13] at map at PythonHadoopUtil.scala:181)
16/12/20 01:54:20 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
16/12/20 01:54:20 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 6, localhost, partition 0, PROCESS_LOCAL, 5499 bytes)
16/12/20 01:54:20 INFO Executor: Running task 0.0 in stage 4.0 (TID 6)
16/12/20 01:54:20 INFO HadoopRDD: Input split: file:/home/moises/Tema5-Spark-notebook/datos/apat63_99-seq/part-00000:0+234177
16/12/20 01:54:20 INFO Executor: Finished task 0.0 in stage 4.0 (TID 6). 1008 bytes result sent to driver
16/12/20 01:54:20 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 6) in 33 ms on localhost (1/1)
16/12/20 01:54:20 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
16/12/20 01:54:20 INFO DAGScheduler: ResultStage 4 (take at SerDeUtil.scala:203) finished in 0,025 s
16/12/20 01:54:20 INFO DAGScheduler: Job 2 finished: take at SerDeUtil.scala:203, took 0,044520 s
16/12/20 01:54:20 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
16/12/20 01:54:20 INFO SparkContext: Starting job: saveAsTextFile at NativeMethodAccessorImpl.java:-2
16/12/20 01:54:20 INFO DAGScheduler: Registering RDD 9 (sortByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:44)
16/12/20 01:54:20 INFO DAGScheduler: Registering RDD 19 (subtractByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:58)
16/12/20 01:54:20 INFO DAGScheduler: Registering RDD 26 (subtractByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:63)
16/12/20 01:54:20 INFO DAGScheduler: Registering RDD 33 (fullOuterJoin at /home/moises/Tema5-Spark-notebook/sparkpractica.py:69)
16/12/20 01:54:20 INFO DAGScheduler: Got job 3 (saveAsTextFile at NativeMethodAccessorImpl.java:-2) with 8 output partitions
16/12/20 01:54:20 INFO DAGScheduler: Final stage: ResultStage 10 (saveAsTextFile at NativeMethodAccessorImpl.java:-2)
16/12/20 01:54:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)
16/12/20 01:54:20 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)
16/12/20 01:54:20 INFO DAGScheduler: Submitting ShuffleMapStage 6 (PairwiseRDD[9] at sortByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:44), which has no missing parents
16/12/20 01:54:20 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 7.9 KB, free 365.5 MB)
16/12/20 01:54:20 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 4.9 KB, free 365.5 MB)
16/12/20 01:54:20 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 192.168.1.109:40171 (size: 4.9 KB, free: 366.2 MB)
16/12/20 01:54:20 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1012
16/12/20 01:54:20 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 6 (PairwiseRDD[9] at sortByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:44)
16/12/20 01:54:20 INFO TaskSchedulerImpl: Adding task set 6.0 with 2 tasks
16/12/20 01:54:20 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 7, localhost, partition 0, ANY, 5231 bytes)
16/12/20 01:54:20 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 8, localhost, partition 1, ANY, 5231 bytes)
16/12/20 01:54:20 INFO Executor: Running task 0.0 in stage 6.0 (TID 7)
16/12/20 01:54:20 INFO Executor: Running task 1.0 in stage 6.0 (TID 8)
16/12/20 01:54:20 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/12/20 01:54:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/12/20 01:54:20 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/12/20 01:54:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
16/12/20 01:54:20 INFO PythonRunner: Times: total = 56, boot = -543, init = 585, finish = 14
16/12/20 01:54:20 INFO Executor: Finished task 0.0 in stage 6.0 (TID 7). 2252 bytes result sent to driver
16/12/20 01:54:20 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 7) in 107 ms on localhost (1/2)
16/12/20 01:54:20 INFO PythonRunner: Times: total = 67, boot = -543, init = 590, finish = 20
16/12/20 01:54:20 INFO Executor: Finished task 1.0 in stage 6.0 (TID 8). 2165 bytes result sent to driver
16/12/20 01:54:20 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 8) in 115 ms on localhost (2/2)
16/12/20 01:54:20 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
16/12/20 01:54:20 INFO DAGScheduler: ShuffleMapStage 6 (sortByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:44) finished in 0,119 s
16/12/20 01:54:20 INFO DAGScheduler: looking for newly runnable stages
16/12/20 01:54:20 INFO DAGScheduler: running: Set()
16/12/20 01:54:20 INFO DAGScheduler: waiting: Set(ShuffleMapStage 9, ResultStage 10, ShuffleMapStage 7, ShuffleMapStage 8)
16/12/20 01:54:20 INFO DAGScheduler: failed: Set()
16/12/20 01:54:20 INFO DAGScheduler: Submitting ShuffleMapStage 7 (PairwiseRDD[19] at subtractByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:58), which has no missing parents
16/12/20 01:54:20 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 14.5 KB, free 365.5 MB)
16/12/20 01:54:20 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 7.7 KB, free 365.5 MB)
16/12/20 01:54:20 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 192.168.1.109:40171 (size: 7.7 KB, free: 366.2 MB)
16/12/20 01:54:20 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1012
16/12/20 01:54:20 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 7 (PairwiseRDD[19] at subtractByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:58)
16/12/20 01:54:20 INFO TaskSchedulerImpl: Adding task set 7.0 with 4 tasks
16/12/20 01:54:20 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 9, localhost, partition 0, PROCESS_LOCAL, 5607 bytes)
16/12/20 01:54:20 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 10, localhost, partition 1, PROCESS_LOCAL, 5607 bytes)
16/12/20 01:54:20 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 11, localhost, partition 2, ANY, 5340 bytes)
16/12/20 01:54:20 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 12, localhost, partition 3, ANY, 5340 bytes)
16/12/20 01:54:20 INFO Executor: Running task 0.0 in stage 7.0 (TID 9)
16/12/20 01:54:20 INFO Executor: Running task 1.0 in stage 7.0 (TID 10)
16/12/20 01:54:20 INFO Executor: Running task 2.0 in stage 7.0 (TID 11)
16/12/20 01:54:20 INFO HadoopRDD: Input split: file:/home/moises/Tema5-Spark-notebook/datos/apat63_99-seq/part-00000:0+234177
16/12/20 01:54:20 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/12/20 01:54:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/12/20 01:54:20 INFO HadoopRDD: Input split: file:/home/moises/Tema5-Spark-notebook/datos/apat63_99-seq/part-00001:0+232120
16/12/20 01:54:20 INFO Executor: Running task 3.0 in stage 7.0 (TID 12)
16/12/20 01:54:20 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/12/20 01:54:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/12/20 01:54:20 INFO PythonRunner: Times: total = 62, boot = -76, init = 114, finish = 24
16/12/20 01:54:20 INFO PythonRunner: Times: total = 69, boot = -79, init = 130, finish = 18
16/12/20 01:54:20 INFO PythonRunner: Times: total = 76, boot = 15, init = 11, finish = 50
16/12/20 01:54:20 INFO Executor: Finished task 2.0 in stage 7.0 (TID 11). 2167 bytes result sent to driver
16/12/20 01:54:20 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 11) in 207 ms on localhost (1/4)
16/12/20 01:54:21 INFO PythonRunner: Times: total = 111, boot = -20, init = 66, finish = 65
16/12/20 01:54:21 INFO Executor: Finished task 3.0 in stage 7.0 (TID 12). 2240 bytes result sent to driver
16/12/20 01:54:21 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 192.168.1.109:40171 in memory (size: 5.8 KB, free: 366.2 MB)
16/12/20 01:54:21 INFO MemoryStore: Block rdd_14_1 stored as bytes in memory (estimated size 242.2 KB, free 365.2 MB)
16/12/20 01:54:21 INFO BlockManagerInfo: Added rdd_14_1 in memory on 192.168.1.109:40171 (size: 242.2 KB, free: 366.0 MB)
16/12/20 01:54:21 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 12) in 297 ms on localhost (2/4)
16/12/20 01:54:21 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 192.168.1.109:40171 in memory (size: 4.3 KB, free: 366.0 MB)
16/12/20 01:54:21 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 192.168.1.109:40171 in memory (size: 4.4 KB, free: 366.0 MB)
16/12/20 01:54:21 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 192.168.1.109:40171 in memory (size: 1996.0 B, free: 366.0 MB)
16/12/20 01:54:21 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 192.168.1.109:40171 in memory (size: 4.9 KB, free: 366.0 MB)
16/12/20 01:54:21 INFO MemoryStore: Block rdd_14_0 stored as bytes in memory (estimated size 240.4 KB, free 365.0 MB)
16/12/20 01:54:21 INFO BlockManagerInfo: Added rdd_14_0 in memory on 192.168.1.109:40171 (size: 240.4 KB, free: 365.8 MB)
16/12/20 01:54:21 INFO PythonRunner: Times: total = 151, boot = -200, init = 216, finish = 135
16/12/20 01:54:21 INFO PythonRunner: Times: total = 235, boot = -170, init = 184, finish = 221
16/12/20 01:54:21 INFO PythonRunner: Times: total = 213, boot = -168, init = 242, finish = 139
16/12/20 01:54:21 INFO Executor: Finished task 1.0 in stage 7.0 (TID 10). 2533 bytes result sent to driver
16/12/20 01:54:21 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 10) in 634 ms on localhost (3/4)
16/12/20 01:54:21 INFO PythonRunner: Times: total = 179, boot = 3, init = 78, finish = 98
16/12/20 01:54:21 INFO Executor: Finished task 0.0 in stage 7.0 (TID 9). 2533 bytes result sent to driver
16/12/20 01:54:21 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 9) in 688 ms on localhost (4/4)
16/12/20 01:54:21 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
16/12/20 01:54:21 INFO DAGScheduler: ShuffleMapStage 7 (subtractByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:58) finished in 0,689 s
16/12/20 01:54:21 INFO DAGScheduler: looking for newly runnable stages
16/12/20 01:54:21 INFO DAGScheduler: running: Set()
16/12/20 01:54:21 INFO DAGScheduler: waiting: Set(ShuffleMapStage 9, ResultStage 10, ShuffleMapStage 8)
16/12/20 01:54:21 INFO DAGScheduler: failed: Set()
16/12/20 01:54:21 INFO DAGScheduler: Submitting ShuffleMapStage 8 (PairwiseRDD[26] at subtractByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:63), which has no missing parents
16/12/20 01:54:21 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 16.8 KB, free 365.0 MB)
16/12/20 01:54:21 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 8.9 KB, free 365.0 MB)
16/12/20 01:54:21 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 192.168.1.109:40171 (size: 8.9 KB, free: 365.7 MB)
16/12/20 01:54:21 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1012
16/12/20 01:54:21 INFO DAGScheduler: Submitting 6 missing tasks from ShuffleMapStage 8 (PairwiseRDD[26] at subtractByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:63)
16/12/20 01:54:21 INFO TaskSchedulerImpl: Adding task set 8.0 with 6 tasks
16/12/20 01:54:21 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 13, localhost, partition 0, PROCESS_LOCAL, 5607 bytes)
16/12/20 01:54:21 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 14, localhost, partition 1, PROCESS_LOCAL, 5607 bytes)
16/12/20 01:54:21 INFO TaskSetManager: Starting task 2.0 in stage 8.0 (TID 15, localhost, partition 2, ANY, 5340 bytes)
16/12/20 01:54:21 INFO TaskSetManager: Starting task 3.0 in stage 8.0 (TID 16, localhost, partition 3, ANY, 5340 bytes)
16/12/20 01:54:21 INFO Executor: Running task 0.0 in stage 8.0 (TID 13)
16/12/20 01:54:21 INFO Executor: Running task 1.0 in stage 8.0 (TID 14)
16/12/20 01:54:21 INFO Executor: Running task 2.0 in stage 8.0 (TID 15)
16/12/20 01:54:21 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
16/12/20 01:54:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/12/20 01:54:21 INFO BlockManager: Found block rdd_14_1 locally
16/12/20 01:54:21 INFO BlockManager: Found block rdd_14_0 locally
16/12/20 01:54:21 INFO Executor: Running task 3.0 in stage 8.0 (TID 16)
16/12/20 01:54:21 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
16/12/20 01:54:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/12/20 01:54:21 INFO PythonRunner: Times: total = 169, boot = -83, init = 103, finish = 149
16/12/20 01:54:21 INFO PythonRunner: Times: total = 150, boot = -124, init = 140, finish = 134
16/12/20 01:54:21 INFO PythonRunner: Times: total = 166, boot = 11, init = 3, finish = 152
16/12/20 01:54:21 INFO PythonRunner: Times: total = 63, boot = 15, init = 19, finish = 29
16/12/20 01:54:21 INFO Executor: Finished task 2.0 in stage 8.0 (TID 15). 2169 bytes result sent to driver
16/12/20 01:54:21 INFO TaskSetManager: Starting task 4.0 in stage 8.0 (TID 17, localhost, partition 4, ANY, 5340 bytes)
16/12/20 01:54:21 INFO TaskSetManager: Finished task 2.0 in stage 8.0 (TID 15) in 269 ms on localhost (1/6)
16/12/20 01:54:21 INFO Executor: Running task 4.0 in stage 8.0 (TID 17)
16/12/20 01:54:21 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
16/12/20 01:54:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/12/20 01:54:21 INFO PythonRunner: Times: total = 248, boot = -58, init = 70, finish = 236
16/12/20 01:54:21 INFO PythonRunner: Times: total = 48, boot = -13, init = 38, finish = 23
16/12/20 01:54:21 INFO Executor: Finished task 3.0 in stage 8.0 (TID 16). 2169 bytes result sent to driver
16/12/20 01:54:21 INFO TaskSetManager: Starting task 5.0 in stage 8.0 (TID 18, localhost, partition 5, ANY, 5340 bytes)
16/12/20 01:54:21 INFO TaskSetManager: Finished task 3.0 in stage 8.0 (TID 16) in 314 ms on localhost (2/6)
16/12/20 01:54:21 INFO Executor: Running task 5.0 in stage 8.0 (TID 18)
16/12/20 01:54:21 INFO PythonRunner: Times: total = 183, boot = 7, init = 79, finish = 97
16/12/20 01:54:21 INFO Executor: Finished task 1.0 in stage 8.0 (TID 14). 1777 bytes result sent to driver
16/12/20 01:54:21 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
16/12/20 01:54:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/12/20 01:54:21 INFO TaskSetManager: Finished task 1.0 in stage 8.0 (TID 14) in 345 ms on localhost (3/6)
16/12/20 01:54:21 INFO PythonRunner: Times: total = 234, boot = 23, init = 99, finish = 112
16/12/20 01:54:21 INFO Executor: Finished task 0.0 in stage 8.0 (TID 13). 1777 bytes result sent to driver
16/12/20 01:54:21 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 13) in 411 ms on localhost (4/6)
16/12/20 01:54:21 INFO PythonRunner: Times: total = 154, boot = -122, init = 128, finish = 148
16/12/20 01:54:21 INFO PythonRunner: Times: total = 127, boot = -97, init = 106, finish = 118
16/12/20 01:54:21 INFO PythonRunner: Times: total = 16, boot = -149, init = 150, finish = 15
16/12/20 01:54:21 INFO Executor: Finished task 5.0 in stage 8.0 (TID 18). 2169 bytes result sent to driver
16/12/20 01:54:21 INFO TaskSetManager: Finished task 5.0 in stage 8.0 (TID 18) in 201 ms on localhost (5/6)
16/12/20 01:54:21 INFO PythonRunner: Times: total = 62, boot = -195, init = 236, finish = 21
16/12/20 01:54:21 INFO Executor: Finished task 4.0 in stage 8.0 (TID 17). 2169 bytes result sent to driver
16/12/20 01:54:21 INFO TaskSetManager: Finished task 4.0 in stage 8.0 (TID 17) in 266 ms on localhost (6/6)
16/12/20 01:54:21 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
16/12/20 01:54:21 INFO DAGScheduler: ShuffleMapStage 8 (subtractByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:63) finished in 0,538 s
16/12/20 01:54:21 INFO DAGScheduler: looking for newly runnable stages
16/12/20 01:54:21 INFO DAGScheduler: running: Set()
16/12/20 01:54:21 INFO DAGScheduler: waiting: Set(ShuffleMapStage 9, ResultStage 10)
16/12/20 01:54:21 INFO DAGScheduler: failed: Set()
16/12/20 01:54:21 INFO DAGScheduler: Submitting ShuffleMapStage 9 (PairwiseRDD[33] at fullOuterJoin at /home/moises/Tema5-Spark-notebook/sparkpractica.py:69), which has no missing parents
16/12/20 01:54:21 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 14.8 KB, free 365.0 MB)
16/12/20 01:54:21 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 7.8 KB, free 365.0 MB)
16/12/20 01:54:21 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 192.168.1.109:40171 (size: 7.8 KB, free: 365.7 MB)
16/12/20 01:54:21 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1012
16/12/20 01:54:21 INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 9 (PairwiseRDD[33] at fullOuterJoin at /home/moises/Tema5-Spark-notebook/sparkpractica.py:69)
16/12/20 01:54:21 INFO TaskSchedulerImpl: Adding task set 9.0 with 8 tasks
16/12/20 01:54:21 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 19, localhost, partition 0, ANY, 5340 bytes)
16/12/20 01:54:21 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 20, localhost, partition 1, ANY, 5340 bytes)
16/12/20 01:54:21 INFO TaskSetManager: Starting task 2.0 in stage 9.0 (TID 21, localhost, partition 2, ANY, 5340 bytes)
16/12/20 01:54:21 INFO TaskSetManager: Starting task 3.0 in stage 9.0 (TID 22, localhost, partition 3, ANY, 5340 bytes)
16/12/20 01:54:21 INFO Executor: Running task 0.0 in stage 9.0 (TID 19)
16/12/20 01:54:21 INFO Executor: Running task 3.0 in stage 9.0 (TID 22)
16/12/20 01:54:21 INFO Executor: Running task 1.0 in stage 9.0 (TID 20)
16/12/20 01:54:21 INFO Executor: Running task 2.0 in stage 9.0 (TID 21)
16/12/20 01:54:21 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 6 blocks
16/12/20 01:54:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/12/20 01:54:21 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 6 blocks
16/12/20 01:54:21 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 6 blocks
16/12/20 01:54:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
16/12/20 01:54:22 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 6 blocks
16/12/20 01:54:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
16/12/20 01:54:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/12/20 01:54:22 INFO PythonRunner: Times: total = 88, boot = -246, init = 252, finish = 82
16/12/20 01:54:22 INFO PythonRunner: Times: total = 80, boot = -115, init = 123, finish = 72
16/12/20 01:54:22 INFO PythonRunner: Times: total = 103, boot = -148, init = 151, finish = 100
16/12/20 01:54:22 INFO PythonRunner: Times: total = 26, boot = -167, init = 185, finish = 8
16/12/20 01:54:22 INFO PythonRunner: Times: total = 65, boot = -159, init = 213, finish = 11
16/12/20 01:54:22 INFO Executor: Finished task 2.0 in stage 9.0 (TID 21). 2171 bytes result sent to driver
16/12/20 01:54:22 INFO TaskSetManager: Starting task 4.0 in stage 9.0 (TID 23, localhost, partition 4, ANY, 5340 bytes)
16/12/20 01:54:22 INFO TaskSetManager: Finished task 2.0 in stage 9.0 (TID 21) in 195 ms on localhost (1/8)
16/12/20 01:54:22 INFO Executor: Running task 4.0 in stage 9.0 (TID 23)
16/12/20 01:54:22 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 6 blocks
16/12/20 01:54:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/12/20 01:54:22 INFO PythonRunner: Times: total = 69, boot = -144, init = 203, finish = 10
16/12/20 01:54:22 INFO PythonRunner: Times: total = 159, boot = -268, init = 294, finish = 133
16/12/20 01:54:22 INFO Executor: Finished task 0.0 in stage 9.0 (TID 19). 2171 bytes result sent to driver
16/12/20 01:54:22 INFO TaskSetManager: Starting task 5.0 in stage 9.0 (TID 24, localhost, partition 5, ANY, 5340 bytes)
16/12/20 01:54:22 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 19) in 228 ms on localhost (2/8)
16/12/20 01:54:22 INFO Executor: Running task 5.0 in stage 9.0 (TID 24)
16/12/20 01:54:22 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 6 blocks
16/12/20 01:54:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/12/20 01:54:22 INFO PythonRunner: Times: total = 47, boot = -63, init = 100, finish = 10
16/12/20 01:54:22 INFO Executor: Finished task 3.0 in stage 9.0 (TID 22). 2171 bytes result sent to driver
16/12/20 01:54:22 INFO TaskSetManager: Starting task 6.0 in stage 9.0 (TID 25, localhost, partition 6, ANY, 5340 bytes)
16/12/20 01:54:22 INFO TaskSetManager: Finished task 3.0 in stage 9.0 (TID 22) in 257 ms on localhost (3/8)
16/12/20 01:54:22 INFO Executor: Running task 6.0 in stage 9.0 (TID 25)
16/12/20 01:54:22 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/12/20 01:54:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/12/20 01:54:22 INFO Executor: Finished task 1.0 in stage 9.0 (TID 20). 2258 bytes result sent to driver
16/12/20 01:54:22 INFO TaskSetManager: Starting task 7.0 in stage 9.0 (TID 26, localhost, partition 7, ANY, 5340 bytes)
16/12/20 01:54:22 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 20) in 268 ms on localhost (4/8)
16/12/20 01:54:22 INFO Executor: Running task 7.0 in stage 9.0 (TID 26)
16/12/20 01:54:22 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/12/20 01:54:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/12/20 01:54:22 INFO PythonRunner: Times: total = 95, boot = -114, init = 159, finish = 50
16/12/20 01:54:22 INFO PythonRunner: Times: total = 164, boot = -84, init = 87, finish = 161
16/12/20 01:54:22 INFO PythonRunner: Times: total = 106, boot = -94, init = 147, finish = 53
16/12/20 01:54:22 INFO PythonRunner: Times: total = 193, boot = -80, init = 96, finish = 177
16/12/20 01:54:22 INFO PythonRunner: Times: total = 32, boot = -175, init = 193, finish = 14
16/12/20 01:54:22 INFO PythonRunner: Times: total = 40, boot = -24, init = 47, finish = 17
16/12/20 01:54:22 INFO Executor: Finished task 4.0 in stage 9.0 (TID 23). 2171 bytes result sent to driver
16/12/20 01:54:22 INFO Executor: Finished task 5.0 in stage 9.0 (TID 24). 2171 bytes result sent to driver
16/12/20 01:54:22 INFO TaskSetManager: Finished task 5.0 in stage 9.0 (TID 24) in 284 ms on localhost (5/8)
16/12/20 01:54:22 INFO TaskSetManager: Finished task 4.0 in stage 9.0 (TID 23) in 315 ms on localhost (6/8)
16/12/20 01:54:22 INFO PythonRunner: Times: total = 67, boot = -115, init = 124, finish = 58
16/12/20 01:54:22 INFO Executor: Finished task 6.0 in stage 9.0 (TID 25). 2171 bytes result sent to driver
16/12/20 01:54:22 INFO TaskSetManager: Finished task 6.0 in stage 9.0 (TID 25) in 273 ms on localhost (7/8)
16/12/20 01:54:22 INFO PythonRunner: Times: total = 141, boot = -134, init = 174, finish = 101
16/12/20 01:54:22 INFO Executor: Finished task 7.0 in stage 9.0 (TID 26). 2258 bytes result sent to driver
16/12/20 01:54:22 INFO TaskSetManager: Finished task 7.0 in stage 9.0 (TID 26) in 296 ms on localhost (8/8)
16/12/20 01:54:22 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
16/12/20 01:54:22 INFO DAGScheduler: ShuffleMapStage 9 (fullOuterJoin at /home/moises/Tema5-Spark-notebook/sparkpractica.py:69) finished in 0,563 s
16/12/20 01:54:22 INFO DAGScheduler: looking for newly runnable stages
16/12/20 01:54:22 INFO DAGScheduler: running: Set()
16/12/20 01:54:22 INFO DAGScheduler: waiting: Set(ResultStage 10)
16/12/20 01:54:22 INFO DAGScheduler: failed: Set()
16/12/20 01:54:22 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[38] at saveAsTextFile at NativeMethodAccessorImpl.java:-2), which has no missing parents
16/12/20 01:54:22 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 79.2 KB, free 364.9 MB)
16/12/20 01:54:22 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 30.4 KB, free 364.9 MB)
16/12/20 01:54:22 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 192.168.1.109:40171 (size: 30.4 KB, free: 365.7 MB)
16/12/20 01:54:22 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1012
16/12/20 01:54:22 INFO DAGScheduler: Submitting 8 missing tasks from ResultStage 10 (MapPartitionsRDD[38] at saveAsTextFile at NativeMethodAccessorImpl.java:-2)
16/12/20 01:54:22 INFO TaskSchedulerImpl: Adding task set 10.0 with 8 tasks
16/12/20 01:54:22 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 27, localhost, partition 0, ANY, 5242 bytes)
16/12/20 01:54:22 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 28, localhost, partition 1, ANY, 5242 bytes)
16/12/20 01:54:22 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 29, localhost, partition 2, ANY, 5242 bytes)
16/12/20 01:54:22 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 30, localhost, partition 3, ANY, 5242 bytes)
16/12/20 01:54:22 INFO Executor: Running task 0.0 in stage 10.0 (TID 27)
16/12/20 01:54:22 INFO Executor: Running task 1.0 in stage 10.0 (TID 28)
16/12/20 01:54:22 INFO Executor: Running task 2.0 in stage 10.0 (TID 29)
16/12/20 01:54:22 INFO Executor: Running task 3.0 in stage 10.0 (TID 30)
16/12/20 01:54:22 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 8 blocks
16/12/20 01:54:22 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 8 blocks
16/12/20 01:54:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
16/12/20 01:54:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
16/12/20 01:54:22 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 8 blocks
16/12/20 01:54:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/12/20 01:54:22 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 8 blocks
16/12/20 01:54:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/12/20 01:54:22 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
16/12/20 01:54:22 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
16/12/20 01:54:22 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
16/12/20 01:54:22 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
16/12/20 01:54:22 INFO PythonRunner: Times: total = 78, boot = -271, init = 309, finish = 40
16/12/20 01:54:22 INFO PythonRunner: Times: total = 96, boot = -261, init = 315, finish = 42
16/12/20 01:54:22 INFO PythonRunner: Times: total = 56, boot = -295, init = 301, finish = 50
16/12/20 01:54:22 INFO PythonRunner: Times: total = 54, boot = -232, init = 257, finish = 29
16/12/20 01:54:22 INFO FileOutputCommitter: Saved output of task 'attempt_201612200154_0010_m_000001_28' to file:/home/moises/Tema5-Spark-notebook/outdir1/_temporary/0/task_201612200154_0010_m_000001
16/12/20 01:54:22 INFO SparkHadoopMapRedUtil: attempt_201612200154_0010_m_000001_28: Committed
16/12/20 01:54:22 INFO FileOutputCommitter: Saved output of task 'attempt_201612200154_0010_m_000002_29' to file:/home/moises/Tema5-Spark-notebook/outdir1/_temporary/0/task_201612200154_0010_m_000002
16/12/20 01:54:22 INFO FileOutputCommitter: Saved output of task 'attempt_201612200154_0010_m_000000_27' to file:/home/moises/Tema5-Spark-notebook/outdir1/_temporary/0/task_201612200154_0010_m_000000
16/12/20 01:54:22 INFO SparkHadoopMapRedUtil: attempt_201612200154_0010_m_000002_29: Committed
16/12/20 01:54:22 INFO SparkHadoopMapRedUtil: attempt_201612200154_0010_m_000000_27: Committed
16/12/20 01:54:22 INFO Executor: Finished task 2.0 in stage 10.0 (TID 29). 2005 bytes result sent to driver
16/12/20 01:54:22 INFO Executor: Finished task 1.0 in stage 10.0 (TID 28). 2005 bytes result sent to driver
16/12/20 01:54:22 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 31, localhost, partition 4, ANY, 5242 bytes)
16/12/20 01:54:22 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 32, localhost, partition 5, ANY, 5242 bytes)
16/12/20 01:54:22 INFO Executor: Finished task 0.0 in stage 10.0 (TID 27). 2005 bytes result sent to driver
16/12/20 01:54:22 INFO Executor: Running task 4.0 in stage 10.0 (TID 31)
16/12/20 01:54:22 INFO Executor: Running task 5.0 in stage 10.0 (TID 32)
16/12/20 01:54:22 INFO FileOutputCommitter: Saved output of task 'attempt_201612200154_0010_m_000003_30' to file:/home/moises/Tema5-Spark-notebook/outdir1/_temporary/0/task_201612200154_0010_m_000003
16/12/20 01:54:22 INFO SparkHadoopMapRedUtil: attempt_201612200154_0010_m_000003_30: Committed
16/12/20 01:54:22 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 29) in 285 ms on localhost (1/8)
16/12/20 01:54:22 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 28) in 289 ms on localhost (2/8)
16/12/20 01:54:22 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 33, localhost, partition 6, ANY, 5242 bytes)
16/12/20 01:54:22 INFO Executor: Finished task 3.0 in stage 10.0 (TID 30). 2005 bytes result sent to driver
16/12/20 01:54:22 INFO Executor: Running task 6.0 in stage 10.0 (TID 33)
16/12/20 01:54:22 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 34, localhost, partition 7, ANY, 5242 bytes)
16/12/20 01:54:22 INFO Executor: Running task 7.0 in stage 10.0 (TID 34)
16/12/20 01:54:22 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 30) in 293 ms on localhost (3/8)
16/12/20 01:54:22 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 27) in 297 ms on localhost (4/8)
16/12/20 01:54:22 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 8 blocks
16/12/20 01:54:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/12/20 01:54:22 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 8 blocks
16/12/20 01:54:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/12/20 01:54:22 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 8 blocks
16/12/20 01:54:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
16/12/20 01:54:22 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 8 blocks
16/12/20 01:54:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/12/20 01:54:22 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
16/12/20 01:54:22 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
16/12/20 01:54:22 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
16/12/20 01:54:23 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
16/12/20 01:54:23 INFO PythonRunner: Times: total = 38, boot = -489, init = 499, finish = 28
16/12/20 01:54:23 INFO PythonRunner: Times: total = 39, boot = -387, init = 393, finish = 33
16/12/20 01:54:23 INFO FileOutputCommitter: Saved output of task 'attempt_201612200154_0010_m_000007_34' to file:/home/moises/Tema5-Spark-notebook/outdir1/_temporary/0/task_201612200154_0010_m_000007
16/12/20 01:54:23 INFO SparkHadoopMapRedUtil: attempt_201612200154_0010_m_000007_34: Committed
16/12/20 01:54:23 INFO FileOutputCommitter: Saved output of task 'attempt_201612200154_0010_m_000005_32' to file:/home/moises/Tema5-Spark-notebook/outdir1/_temporary/0/task_201612200154_0010_m_000005
16/12/20 01:54:23 INFO SparkHadoopMapRedUtil: attempt_201612200154_0010_m_000005_32: Committed
16/12/20 01:54:23 INFO Executor: Finished task 7.0 in stage 10.0 (TID 34). 2005 bytes result sent to driver
16/12/20 01:54:23 INFO Executor: Finished task 5.0 in stage 10.0 (TID 32). 2005 bytes result sent to driver
16/12/20 01:54:23 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 34) in 158 ms on localhost (5/8)
16/12/20 01:54:23 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 32) in 169 ms on localhost (6/8)
16/12/20 01:54:23 INFO PythonRunner: Times: total = 87, boot = -155, init = 206, finish = 36
16/12/20 01:54:23 INFO FileOutputCommitter: Saved output of task 'attempt_201612200154_0010_m_000004_31' to file:/home/moises/Tema5-Spark-notebook/outdir1/_temporary/0/task_201612200154_0010_m_000004
16/12/20 01:54:23 INFO SparkHadoopMapRedUtil: attempt_201612200154_0010_m_000004_31: Committed
16/12/20 01:54:23 INFO Executor: Finished task 4.0 in stage 10.0 (TID 31). 2092 bytes result sent to driver
16/12/20 01:54:23 INFO PythonRunner: Times: total = 80, boot = -395, init = 433, finish = 42
16/12/20 01:54:23 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 31) in 213 ms on localhost (7/8)
16/12/20 01:54:23 INFO FileOutputCommitter: Saved output of task 'attempt_201612200154_0010_m_000006_33' to file:/home/moises/Tema5-Spark-notebook/outdir1/_temporary/0/task_201612200154_0010_m_000006
16/12/20 01:54:23 INFO SparkHadoopMapRedUtil: attempt_201612200154_0010_m_000006_33: Committed
16/12/20 01:54:23 INFO Executor: Finished task 6.0 in stage 10.0 (TID 33). 2005 bytes result sent to driver
16/12/20 01:54:23 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 33) in 204 ms on localhost (8/8)
16/12/20 01:54:23 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
16/12/20 01:54:23 INFO DAGScheduler: ResultStage 10 (saveAsTextFile at NativeMethodAccessorImpl.java:-2) finished in 0,500 s
16/12/20 01:54:23 INFO DAGScheduler: Job 3 finished: saveAsTextFile at NativeMethodAccessorImpl.java:-2, took 2,516882 s
16/12/20 01:54:23 INFO SparkContext: Starting job: sortByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:89
16/12/20 01:54:23 INFO DAGScheduler: Registering RDD 40 (reduceByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:89)
16/12/20 01:54:23 INFO DAGScheduler: Got job 4 (sortByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:89) with 2 output partitions
16/12/20 01:54:23 INFO DAGScheduler: Final stage: ResultStage 12 (sortByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:89)
16/12/20 01:54:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
16/12/20 01:54:23 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 11)
16/12/20 01:54:23 INFO DAGScheduler: Submitting ShuffleMapStage 11 (PairwiseRDD[40] at reduceByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:89), which has no missing parents
16/12/20 01:54:23 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 9.6 KB, free 364.9 MB)
16/12/20 01:54:23 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 6.0 KB, free 364.9 MB)
16/12/20 01:54:23 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 192.168.1.109:40171 (size: 6.0 KB, free: 365.7 MB)
16/12/20 01:54:23 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1012
16/12/20 01:54:23 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 11 (PairwiseRDD[40] at reduceByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:89)
16/12/20 01:54:23 INFO TaskSchedulerImpl: Adding task set 11.0 with 2 tasks
16/12/20 01:54:23 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 35, localhost, partition 0, PROCESS_LOCAL, 5577 bytes)
16/12/20 01:54:23 INFO TaskSetManager: Starting task 1.0 in stage 11.0 (TID 36, localhost, partition 1, PROCESS_LOCAL, 5577 bytes)
16/12/20 01:54:23 INFO Executor: Running task 0.0 in stage 11.0 (TID 35)
16/12/20 01:54:23 INFO Executor: Running task 1.0 in stage 11.0 (TID 36)
16/12/20 01:54:23 INFO BlockManager: Found block rdd_14_1 locally
16/12/20 01:54:23 INFO BlockManager: Found block rdd_14_0 locally
16/12/20 01:54:23 INFO PythonRunner: Times: total = 75, boot = -425, init = 431, finish = 69
16/12/20 01:54:23 INFO Executor: Finished task 0.0 in stage 11.0 (TID 35). 1773 bytes result sent to driver
16/12/20 01:54:23 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 35) in 101 ms on localhost (1/2)
16/12/20 01:54:23 INFO PythonRunner: Times: total = 87, boot = -394, init = 396, finish = 85
16/12/20 01:54:23 INFO Executor: Finished task 1.0 in stage 11.0 (TID 36). 1773 bytes result sent to driver
16/12/20 01:54:23 INFO TaskSetManager: Finished task 1.0 in stage 11.0 (TID 36) in 113 ms on localhost (2/2)
16/12/20 01:54:23 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
16/12/20 01:54:23 INFO DAGScheduler: ShuffleMapStage 11 (reduceByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:89) finished in 0,115 s
16/12/20 01:54:23 INFO DAGScheduler: looking for newly runnable stages
16/12/20 01:54:23 INFO DAGScheduler: running: Set()
16/12/20 01:54:23 INFO DAGScheduler: waiting: Set(ResultStage 12)
16/12/20 01:54:23 INFO DAGScheduler: failed: Set()
16/12/20 01:54:23 INFO DAGScheduler: Submitting ResultStage 12 (PythonRDD[43] at sortByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:89), which has no missing parents
16/12/20 01:54:23 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 7.1 KB, free 364.9 MB)
16/12/20 01:54:23 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 4.3 KB, free 364.9 MB)
16/12/20 01:54:23 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 192.168.1.109:40171 (size: 4.3 KB, free: 365.7 MB)
16/12/20 01:54:23 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1012
16/12/20 01:54:23 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 12 (PythonRDD[43] at sortByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:89)
16/12/20 01:54:23 INFO TaskSchedulerImpl: Adding task set 12.0 with 2 tasks
16/12/20 01:54:23 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 37, localhost, partition 0, ANY, 5321 bytes)
16/12/20 01:54:23 INFO TaskSetManager: Starting task 1.0 in stage 12.0 (TID 38, localhost, partition 1, ANY, 5321 bytes)
16/12/20 01:54:23 INFO Executor: Running task 0.0 in stage 12.0 (TID 37)
16/12/20 01:54:23 INFO Executor: Running task 1.0 in stage 12.0 (TID 38)
16/12/20 01:54:23 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/12/20 01:54:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
16/12/20 01:54:23 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/12/20 01:54:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
16/12/20 01:54:23 INFO PythonRunner: Times: total = 50, boot = -554, init = 603, finish = 1
16/12/20 01:54:23 INFO Executor: Finished task 0.0 in stage 12.0 (TID 37). 1854 bytes result sent to driver
16/12/20 01:54:23 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 37) in 66 ms on localhost (1/2)
16/12/20 01:54:23 INFO PythonRunner: Times: total = 61, boot = -335, init = 395, finish = 1
16/12/20 01:54:23 INFO Executor: Finished task 1.0 in stage 12.0 (TID 38). 1854 bytes result sent to driver
16/12/20 01:54:23 INFO TaskSetManager: Finished task 1.0 in stage 12.0 (TID 38) in 75 ms on localhost (2/2)
16/12/20 01:54:23 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
16/12/20 01:54:23 INFO DAGScheduler: ResultStage 12 (sortByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:89) finished in 0,072 s
16/12/20 01:54:23 INFO DAGScheduler: Job 4 finished: sortByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:89, took 0,217840 s
16/12/20 01:54:23 INFO SparkContext: Starting job: sortByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:89
16/12/20 01:54:23 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 5 is 159 bytes
16/12/20 01:54:23 INFO DAGScheduler: Got job 5 (sortByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:89) with 2 output partitions
16/12/20 01:54:23 INFO DAGScheduler: Final stage: ResultStage 14 (sortByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:89)
16/12/20 01:54:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
16/12/20 01:54:23 INFO DAGScheduler: Missing parents: List()
16/12/20 01:54:23 INFO DAGScheduler: Submitting ResultStage 14 (PythonRDD[44] at sortByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:89), which has no missing parents
16/12/20 01:54:23 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 7.2 KB, free 364.9 MB)
16/12/20 01:54:23 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 4.4 KB, free 364.9 MB)
16/12/20 01:54:23 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 192.168.1.109:40171 (size: 4.4 KB, free: 365.7 MB)
16/12/20 01:54:23 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1012
16/12/20 01:54:23 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 14 (PythonRDD[44] at sortByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:89)
16/12/20 01:54:23 INFO TaskSchedulerImpl: Adding task set 14.0 with 2 tasks
16/12/20 01:54:23 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 39, localhost, partition 0, ANY, 5321 bytes)
16/12/20 01:54:23 INFO TaskSetManager: Starting task 1.0 in stage 14.0 (TID 40, localhost, partition 1, ANY, 5321 bytes)
16/12/20 01:54:23 INFO Executor: Running task 0.0 in stage 14.0 (TID 39)
16/12/20 01:54:23 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/12/20 01:54:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/12/20 01:54:23 INFO Executor: Running task 1.0 in stage 14.0 (TID 40)
16/12/20 01:54:23 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/12/20 01:54:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/12/20 01:54:23 INFO PythonRunner: Times: total = 43, boot = -407, init = 448, finish = 2
16/12/20 01:54:23 INFO Executor: Finished task 1.0 in stage 14.0 (TID 40). 2262 bytes result sent to driver
16/12/20 01:54:23 INFO PythonRunner: Times: total = 50, boot = -448, init = 495, finish = 3
16/12/20 01:54:23 INFO TaskSetManager: Finished task 1.0 in stage 14.0 (TID 40) in 60 ms on localhost (1/2)
16/12/20 01:54:23 INFO Executor: Finished task 0.0 in stage 14.0 (TID 39). 2342 bytes result sent to driver
16/12/20 01:54:23 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 39) in 65 ms on localhost (2/2)
16/12/20 01:54:23 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
16/12/20 01:54:23 INFO DAGScheduler: ResultStage 14 (sortByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:89) finished in 0,066 s
16/12/20 01:54:23 INFO DAGScheduler: Job 5 finished: sortByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:89, took 0,081194 s
16/12/20 01:54:23 INFO SparkContext: Starting job: sortByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:101
16/12/20 01:54:23 INFO DAGScheduler: Registering RDD 46 (sortByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:89)
16/12/20 01:54:23 INFO DAGScheduler: Registering RDD 50 (reduceByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:101)
16/12/20 01:54:23 INFO DAGScheduler: Got job 6 (sortByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:101) with 2 output partitions
16/12/20 01:54:23 INFO DAGScheduler: Final stage: ResultStage 18 (sortByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:101)
16/12/20 01:54:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 17)
16/12/20 01:54:23 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 17)
16/12/20 01:54:23 INFO DAGScheduler: Submitting ShuffleMapStage 16 (PairwiseRDD[46] at sortByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:89), which has no missing parents
16/12/20 01:54:23 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 7.9 KB, free 364.8 MB)
16/12/20 01:54:23 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 4.9 KB, free 364.8 MB)
16/12/20 01:54:23 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 192.168.1.109:40171 (size: 4.9 KB, free: 365.7 MB)
16/12/20 01:54:23 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1012
16/12/20 01:54:23 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 16 (PairwiseRDD[46] at sortByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:89)
16/12/20 01:54:23 INFO TaskSchedulerImpl: Adding task set 16.0 with 2 tasks
16/12/20 01:54:23 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 41, localhost, partition 0, ANY, 5311 bytes)
16/12/20 01:54:23 INFO TaskSetManager: Starting task 1.0 in stage 16.0 (TID 42, localhost, partition 1, ANY, 5311 bytes)
16/12/20 01:54:23 INFO Executor: Running task 1.0 in stage 16.0 (TID 42)
16/12/20 01:54:23 INFO Executor: Running task 0.0 in stage 16.0 (TID 41)
16/12/20 01:54:23 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/12/20 01:54:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/12/20 01:54:23 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/12/20 01:54:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/12/20 01:54:23 INFO PythonRunner: Times: total = 10, boot = -594, init = 600, finish = 4
16/12/20 01:54:23 INFO Executor: Finished task 1.0 in stage 16.0 (TID 42). 2165 bytes result sent to driver
16/12/20 01:54:23 INFO TaskSetManager: Finished task 1.0 in stage 16.0 (TID 42) in 43 ms on localhost (1/2)
16/12/20 01:54:23 INFO PythonRunner: Times: total = 36, boot = -287, init = 318, finish = 5
16/12/20 01:54:23 INFO Executor: Finished task 0.0 in stage 16.0 (TID 41). 2165 bytes result sent to driver
16/12/20 01:54:23 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 41) in 62 ms on localhost (2/2)
16/12/20 01:54:23 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
16/12/20 01:54:23 INFO DAGScheduler: ShuffleMapStage 16 (sortByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:89) finished in 0,065 s
16/12/20 01:54:23 INFO DAGScheduler: looking for newly runnable stages
16/12/20 01:54:23 INFO DAGScheduler: running: Set()
16/12/20 01:54:23 INFO DAGScheduler: waiting: Set(ShuffleMapStage 17, ResultStage 18)
16/12/20 01:54:23 INFO DAGScheduler: failed: Set()
16/12/20 01:54:23 INFO DAGScheduler: Submitting ShuffleMapStage 17 (PairwiseRDD[50] at reduceByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:101), which has no missing parents
16/12/20 01:54:23 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 8.6 KB, free 364.8 MB)
16/12/20 01:54:23 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 5.4 KB, free 364.8 MB)
16/12/20 01:54:23 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 192.168.1.109:40171 (size: 5.4 KB, free: 365.7 MB)
16/12/20 01:54:23 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1012
16/12/20 01:54:23 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 17 (PairwiseRDD[50] at reduceByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:101)
16/12/20 01:54:23 INFO TaskSchedulerImpl: Adding task set 17.0 with 2 tasks
16/12/20 01:54:23 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 43, localhost, partition 0, ANY, 5311 bytes)
16/12/20 01:54:23 INFO TaskSetManager: Starting task 1.0 in stage 17.0 (TID 44, localhost, partition 1, ANY, 5311 bytes)
16/12/20 01:54:23 INFO Executor: Running task 0.0 in stage 17.0 (TID 43)
16/12/20 01:54:23 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/12/20 01:54:23 INFO Executor: Running task 1.0 in stage 17.0 (TID 44)
16/12/20 01:54:23 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/12/20 01:54:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
16/12/20 01:54:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
16/12/20 01:54:23 INFO PythonRunner: Times: total = 11, boot = -387, init = 391, finish = 7
16/12/20 01:54:23 INFO Executor: Finished task 1.0 in stage 17.0 (TID 44). 2165 bytes result sent to driver
16/12/20 01:54:23 INFO TaskSetManager: Finished task 1.0 in stage 17.0 (TID 44) in 40 ms on localhost (1/2)
16/12/20 01:54:23 INFO PythonRunner: Times: total = 50, boot = -318, init = 362, finish = 6
16/12/20 01:54:23 INFO Executor: Finished task 0.0 in stage 17.0 (TID 43). 2165 bytes result sent to driver
16/12/20 01:54:23 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 43) in 77 ms on localhost (2/2)
16/12/20 01:54:23 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
16/12/20 01:54:23 INFO DAGScheduler: ShuffleMapStage 17 (reduceByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:101) finished in 0,076 s
16/12/20 01:54:23 INFO DAGScheduler: looking for newly runnable stages
16/12/20 01:54:23 INFO DAGScheduler: running: Set()
16/12/20 01:54:23 INFO DAGScheduler: waiting: Set(ResultStage 18)
16/12/20 01:54:23 INFO DAGScheduler: failed: Set()
16/12/20 01:54:23 INFO DAGScheduler: Submitting ResultStage 18 (PythonRDD[53] at sortByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:101), which has no missing parents
16/12/20 01:54:23 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 7.1 KB, free 364.8 MB)
16/12/20 01:54:23 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 4.3 KB, free 364.8 MB)
16/12/20 01:54:23 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 192.168.1.109:40171 (size: 4.3 KB, free: 365.7 MB)
16/12/20 01:54:23 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1012
16/12/20 01:54:23 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 18 (PythonRDD[53] at sortByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:101)
16/12/20 01:54:23 INFO TaskSchedulerImpl: Adding task set 18.0 with 2 tasks
16/12/20 01:54:23 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 45, localhost, partition 0, ANY, 5322 bytes)
16/12/20 01:54:23 INFO TaskSetManager: Starting task 1.0 in stage 18.0 (TID 46, localhost, partition 1, ANY, 5322 bytes)
16/12/20 01:54:23 INFO Executor: Running task 0.0 in stage 18.0 (TID 45)
16/12/20 01:54:23 INFO Executor: Running task 1.0 in stage 18.0 (TID 46)
16/12/20 01:54:23 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/12/20 01:54:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/12/20 01:54:23 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/12/20 01:54:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/12/20 01:54:23 INFO PythonRunner: Times: total = 39, boot = -381, init = 419, finish = 1
16/12/20 01:54:23 INFO Executor: Finished task 1.0 in stage 18.0 (TID 46). 1853 bytes result sent to driver
16/12/20 01:54:23 INFO TaskSetManager: Finished task 1.0 in stage 18.0 (TID 46) in 52 ms on localhost (1/2)
16/12/20 01:54:23 INFO PythonRunner: Times: total = 42, boot = -262, init = 303, finish = 1
16/12/20 01:54:23 INFO Executor: Finished task 0.0 in stage 18.0 (TID 45). 1853 bytes result sent to driver
16/12/20 01:54:23 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 45) in 58 ms on localhost (2/2)
16/12/20 01:54:23 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
16/12/20 01:54:23 INFO DAGScheduler: ResultStage 18 (sortByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:101) finished in 0,059 s
16/12/20 01:54:23 INFO DAGScheduler: Job 6 finished: sortByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:101, took 0,234245 s
16/12/20 01:54:23 INFO SparkContext: Starting job: sortByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:101
16/12/20 01:54:23 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 5 is 159 bytes
16/12/20 01:54:23 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 7 is 157 bytes
16/12/20 01:54:23 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 6 is 160 bytes
16/12/20 01:54:23 INFO DAGScheduler: Got job 7 (sortByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:101) with 2 output partitions
16/12/20 01:54:23 INFO DAGScheduler: Final stage: ResultStage 22 (sortByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:101)
16/12/20 01:54:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 21)
16/12/20 01:54:23 INFO DAGScheduler: Missing parents: List()
16/12/20 01:54:23 INFO DAGScheduler: Submitting ResultStage 22 (PythonRDD[54] at sortByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:101), which has no missing parents
16/12/20 01:54:23 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 7.2 KB, free 364.8 MB)
16/12/20 01:54:23 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 4.4 KB, free 364.8 MB)
16/12/20 01:54:23 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 192.168.1.109:40171 (size: 4.4 KB, free: 365.7 MB)
16/12/20 01:54:23 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1012
16/12/20 01:54:23 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 22 (PythonRDD[54] at sortByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:101)
16/12/20 01:54:23 INFO TaskSchedulerImpl: Adding task set 22.0 with 2 tasks
16/12/20 01:54:23 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 47, localhost, partition 0, ANY, 5322 bytes)
16/12/20 01:54:23 INFO TaskSetManager: Starting task 1.0 in stage 22.0 (TID 48, localhost, partition 1, ANY, 5322 bytes)
16/12/20 01:54:23 INFO Executor: Running task 1.0 in stage 22.0 (TID 48)
16/12/20 01:54:23 INFO Executor: Running task 0.0 in stage 22.0 (TID 47)
16/12/20 01:54:23 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 192.168.1.109:40171 in memory (size: 4.3 KB, free: 365.7 MB)
16/12/20 01:54:23 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/12/20 01:54:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
16/12/20 01:54:23 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/12/20 01:54:23 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 192.168.1.109:40171 in memory (size: 7.7 KB, free: 365.7 MB)
16/12/20 01:54:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/12/20 01:54:23 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 192.168.1.109:40171 in memory (size: 8.9 KB, free: 365.7 MB)
16/12/20 01:54:23 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 192.168.1.109:40171 in memory (size: 7.8 KB, free: 365.7 MB)
16/12/20 01:54:23 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 192.168.1.109:40171 in memory (size: 30.4 KB, free: 365.7 MB)
16/12/20 01:54:23 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 192.168.1.109:40171 in memory (size: 6.0 KB, free: 365.7 MB)
16/12/20 01:54:23 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 192.168.1.109:40171 in memory (size: 4.3 KB, free: 365.7 MB)
16/12/20 01:54:23 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 192.168.1.109:40171 in memory (size: 4.4 KB, free: 365.7 MB)
16/12/20 01:54:23 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 192.168.1.109:40171 in memory (size: 4.9 KB, free: 365.8 MB)
16/12/20 01:54:23 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 192.168.1.109:40171 in memory (size: 5.4 KB, free: 365.8 MB)
16/12/20 01:54:23 INFO PythonRunner: Times: total = 47, boot = -231, init = 277, finish = 1
16/12/20 01:54:23 INFO Executor: Finished task 0.0 in stage 22.0 (TID 47). 2094 bytes result sent to driver
16/12/20 01:54:23 INFO PythonRunner: Times: total = 47, boot = -391, init = 437, finish = 1
16/12/20 01:54:23 INFO Executor: Finished task 1.0 in stage 22.0 (TID 48). 2025 bytes result sent to driver
16/12/20 01:54:23 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 47) in 69 ms on localhost (1/2)
16/12/20 01:54:23 INFO TaskSetManager: Finished task 1.0 in stage 22.0 (TID 48) in 69 ms on localhost (2/2)
16/12/20 01:54:23 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
16/12/20 01:54:23 INFO DAGScheduler: ResultStage 22 (sortByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:101) finished in 0,075 s
16/12/20 01:54:23 INFO DAGScheduler: Job 7 finished: sortByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:101, took 0,115675 s
16/12/20 01:54:24 INFO SparkContext: Starting job: sortByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:106
16/12/20 01:54:24 INFO DAGScheduler: Registering RDD 60 (reduceByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:106)
16/12/20 01:54:24 INFO DAGScheduler: Got job 8 (sortByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:106) with 2 output partitions
16/12/20 01:54:24 INFO DAGScheduler: Final stage: ResultStage 26 (sortByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:106)
16/12/20 01:54:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 25)
16/12/20 01:54:24 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 25)
16/12/20 01:54:24 INFO DAGScheduler: Submitting ShuffleMapStage 25 (PairwiseRDD[60] at reduceByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:106), which has no missing parents
16/12/20 01:54:24 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 8.7 KB, free 365.0 MB)
16/12/20 01:54:24 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 5.5 KB, free 365.0 MB)
16/12/20 01:54:24 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 192.168.1.109:40171 (size: 5.5 KB, free: 365.8 MB)
16/12/20 01:54:24 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1012
16/12/20 01:54:24 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 25 (PairwiseRDD[60] at reduceByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:106)
16/12/20 01:54:24 INFO TaskSchedulerImpl: Adding task set 25.0 with 2 tasks
16/12/20 01:54:24 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 49, localhost, partition 0, ANY, 5312 bytes)
16/12/20 01:54:24 INFO TaskSetManager: Starting task 1.0 in stage 25.0 (TID 50, localhost, partition 1, ANY, 5312 bytes)
16/12/20 01:54:24 INFO Executor: Running task 0.0 in stage 25.0 (TID 49)
16/12/20 01:54:24 INFO Executor: Running task 1.0 in stage 25.0 (TID 50)
16/12/20 01:54:24 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/12/20 01:54:24 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/12/20 01:54:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/12/20 01:54:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/12/20 01:54:24 INFO PythonRunner: Times: total = 47, boot = -336, init = 374, finish = 9
16/12/20 01:54:24 INFO PythonRunner: Times: total = 47, boot = -380, init = 422, finish = 5
16/12/20 01:54:24 INFO Executor: Finished task 0.0 in stage 25.0 (TID 49). 2165 bytes result sent to driver
16/12/20 01:54:24 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 49) in 63 ms on localhost (1/2)
16/12/20 01:54:24 INFO Executor: Finished task 1.0 in stage 25.0 (TID 50). 2165 bytes result sent to driver
16/12/20 01:54:24 INFO TaskSetManager: Finished task 1.0 in stage 25.0 (TID 50) in 64 ms on localhost (2/2)
16/12/20 01:54:24 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
16/12/20 01:54:24 INFO DAGScheduler: ShuffleMapStage 25 (reduceByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:106) finished in 0,062 s
16/12/20 01:54:24 INFO DAGScheduler: looking for newly runnable stages
16/12/20 01:54:24 INFO DAGScheduler: running: Set()
16/12/20 01:54:24 INFO DAGScheduler: waiting: Set(ResultStage 26)
16/12/20 01:54:24 INFO DAGScheduler: failed: Set()
16/12/20 01:54:24 INFO DAGScheduler: Submitting ResultStage 26 (PythonRDD[63] at sortByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:106), which has no missing parents
16/12/20 01:54:24 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 7.2 KB, free 365.0 MB)
16/12/20 01:54:24 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 4.4 KB, free 365.0 MB)
16/12/20 01:54:24 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 192.168.1.109:40171 (size: 4.4 KB, free: 365.7 MB)
16/12/20 01:54:24 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1012
16/12/20 01:54:24 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 26 (PythonRDD[63] at sortByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:106)
16/12/20 01:54:24 INFO TaskSchedulerImpl: Adding task set 26.0 with 2 tasks
16/12/20 01:54:24 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 51, localhost, partition 0, ANY, 5323 bytes)
16/12/20 01:54:24 INFO TaskSetManager: Starting task 1.0 in stage 26.0 (TID 52, localhost, partition 1, ANY, 5323 bytes)
16/12/20 01:54:24 INFO Executor: Running task 0.0 in stage 26.0 (TID 51)
16/12/20 01:54:24 INFO Executor: Running task 1.0 in stage 26.0 (TID 52)
16/12/20 01:54:24 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/12/20 01:54:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
16/12/20 01:54:24 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/12/20 01:54:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
16/12/20 01:54:24 INFO PythonRunner: Times: total = 44, boot = -366, init = 410, finish = 0
16/12/20 01:54:24 INFO Executor: Finished task 1.0 in stage 26.0 (TID 52). 1853 bytes result sent to driver
16/12/20 01:54:24 INFO TaskSetManager: Finished task 1.0 in stage 26.0 (TID 52) in 65 ms on localhost (1/2)
16/12/20 01:54:24 INFO PythonRunner: Times: total = 47, boot = -307, init = 354, finish = 0
16/12/20 01:54:24 INFO Executor: Finished task 0.0 in stage 26.0 (TID 51). 1853 bytes result sent to driver
16/12/20 01:54:24 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 51) in 67 ms on localhost (2/2)
16/12/20 01:54:24 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
16/12/20 01:54:24 INFO DAGScheduler: ResultStage 26 (sortByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:106) finished in 0,067 s
16/12/20 01:54:24 INFO DAGScheduler: Job 8 finished: sortByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:106, took 0,155426 s
16/12/20 01:54:24 INFO SparkContext: Starting job: sortByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:106
16/12/20 01:54:24 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 5 is 159 bytes
16/12/20 01:54:24 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 7 is 157 bytes
16/12/20 01:54:24 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 8 is 160 bytes
16/12/20 01:54:24 INFO DAGScheduler: Got job 9 (sortByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:106) with 2 output partitions
16/12/20 01:54:24 INFO DAGScheduler: Final stage: ResultStage 30 (sortByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:106)
16/12/20 01:54:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 29)
16/12/20 01:54:24 INFO DAGScheduler: Missing parents: List()
16/12/20 01:54:24 INFO DAGScheduler: Submitting ResultStage 30 (PythonRDD[64] at sortByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:106), which has no missing parents
16/12/20 01:54:24 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 7.3 KB, free 365.0 MB)
16/12/20 01:54:24 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 4.6 KB, free 365.0 MB)
16/12/20 01:54:24 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 192.168.1.109:40171 (size: 4.6 KB, free: 365.7 MB)
16/12/20 01:54:24 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1012
16/12/20 01:54:24 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 30 (PythonRDD[64] at sortByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:106)
16/12/20 01:54:24 INFO TaskSchedulerImpl: Adding task set 30.0 with 2 tasks
16/12/20 01:54:24 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 53, localhost, partition 0, ANY, 5323 bytes)
16/12/20 01:54:24 INFO TaskSetManager: Starting task 1.0 in stage 30.0 (TID 54, localhost, partition 1, ANY, 5323 bytes)
16/12/20 01:54:24 INFO Executor: Running task 0.0 in stage 30.0 (TID 53)
16/12/20 01:54:24 INFO Executor: Running task 1.0 in stage 30.0 (TID 54)
16/12/20 01:54:24 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/12/20 01:54:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/12/20 01:54:24 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/12/20 01:54:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/12/20 01:54:24 INFO PythonRunner: Times: total = 41, boot = -409, init = 449, finish = 1
16/12/20 01:54:24 INFO Executor: Finished task 1.0 in stage 30.0 (TID 54). 2025 bytes result sent to driver
16/12/20 01:54:24 INFO TaskSetManager: Finished task 1.0 in stage 30.0 (TID 54) in 49 ms on localhost (1/2)
16/12/20 01:54:24 INFO PythonRunner: Times: total = 43, boot = -273, init = 315, finish = 1
16/12/20 01:54:24 INFO Executor: Finished task 0.0 in stage 30.0 (TID 53). 2094 bytes result sent to driver
16/12/20 01:54:24 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 53) in 55 ms on localhost (2/2)
16/12/20 01:54:24 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
16/12/20 01:54:24 INFO DAGScheduler: ResultStage 30 (sortByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:106) finished in 0,055 s
16/12/20 01:54:24 INFO DAGScheduler: Job 9 finished: sortByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:106, took 0,067620 s
16/12/20 01:54:24 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
16/12/20 01:54:24 INFO SparkContext: Starting job: saveAsTextFile at NativeMethodAccessorImpl.java:-2
16/12/20 01:54:24 INFO DAGScheduler: Registering RDD 66 (sortByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:106)
16/12/20 01:54:24 INFO DAGScheduler: Got job 10 (saveAsTextFile at NativeMethodAccessorImpl.java:-2) with 2 output partitions
16/12/20 01:54:24 INFO DAGScheduler: Final stage: ResultStage 35 (saveAsTextFile at NativeMethodAccessorImpl.java:-2)
16/12/20 01:54:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 34)
16/12/20 01:54:24 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 34)
16/12/20 01:54:24 INFO DAGScheduler: Submitting ShuffleMapStage 34 (PairwiseRDD[66] at sortByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:106), which has no missing parents
16/12/20 01:54:24 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 8.0 KB, free 365.0 MB)
16/12/20 01:54:24 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 5.1 KB, free 365.0 MB)
16/12/20 01:54:24 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 192.168.1.109:40171 (size: 5.1 KB, free: 365.7 MB)
16/12/20 01:54:24 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1012
16/12/20 01:54:24 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 34 (PairwiseRDD[66] at sortByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:106)
16/12/20 01:54:24 INFO TaskSchedulerImpl: Adding task set 34.0 with 2 tasks
16/12/20 01:54:24 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 55, localhost, partition 0, ANY, 5232 bytes)
16/12/20 01:54:24 INFO TaskSetManager: Starting task 1.0 in stage 34.0 (TID 56, localhost, partition 1, ANY, 5232 bytes)
16/12/20 01:54:24 INFO Executor: Running task 1.0 in stage 34.0 (TID 56)
16/12/20 01:54:24 INFO Executor: Running task 0.0 in stage 34.0 (TID 55)
16/12/20 01:54:24 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/12/20 01:54:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/12/20 01:54:24 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/12/20 01:54:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/12/20 01:54:24 INFO PythonRunner: Times: total = 47, boot = -471, init = 518, finish = 0
16/12/20 01:54:24 INFO Executor: Finished task 0.0 in stage 34.0 (TID 55). 2165 bytes result sent to driver
16/12/20 01:54:24 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 55) in 82 ms on localhost (1/2)
16/12/20 01:54:24 INFO PythonRunner: Times: total = 55, boot = -304, init = 358, finish = 1
16/12/20 01:54:24 INFO Executor: Finished task 1.0 in stage 34.0 (TID 56). 2165 bytes result sent to driver
16/12/20 01:54:24 INFO TaskSetManager: Finished task 1.0 in stage 34.0 (TID 56) in 84 ms on localhost (2/2)
16/12/20 01:54:24 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool 
16/12/20 01:54:24 INFO DAGScheduler: ShuffleMapStage 34 (sortByKey at /home/moises/Tema5-Spark-notebook/sparkpractica.py:106) finished in 0,091 s
16/12/20 01:54:24 INFO DAGScheduler: looking for newly runnable stages
16/12/20 01:54:24 INFO DAGScheduler: running: Set()
16/12/20 01:54:24 INFO DAGScheduler: waiting: Set(ResultStage 35)
16/12/20 01:54:24 INFO DAGScheduler: failed: Set()
16/12/20 01:54:24 INFO DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[71] at saveAsTextFile at NativeMethodAccessorImpl.java:-2), which has no missing parents
16/12/20 01:54:24 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 76.7 KB, free 364.9 MB)
16/12/20 01:54:24 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 28.9 KB, free 364.9 MB)
16/12/20 01:54:24 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 192.168.1.109:40171 (size: 28.9 KB, free: 365.7 MB)
16/12/20 01:54:24 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1012
16/12/20 01:54:24 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 35 (MapPartitionsRDD[71] at saveAsTextFile at NativeMethodAccessorImpl.java:-2)
16/12/20 01:54:24 INFO TaskSchedulerImpl: Adding task set 35.0 with 2 tasks
16/12/20 01:54:24 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 57, localhost, partition 0, ANY, 5243 bytes)
16/12/20 01:54:24 INFO TaskSetManager: Starting task 1.0 in stage 35.0 (TID 58, localhost, partition 1, ANY, 5243 bytes)
16/12/20 01:54:24 INFO Executor: Running task 1.0 in stage 35.0 (TID 58)
16/12/20 01:54:24 INFO Executor: Running task 0.0 in stage 35.0 (TID 57)
16/12/20 01:54:24 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/12/20 01:54:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
16/12/20 01:54:24 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
16/12/20 01:54:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
16/12/20 01:54:24 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
16/12/20 01:54:24 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
16/12/20 01:54:24 INFO PythonRunner: Times: total = 51, boot = -443, init = 493, finish = 1
16/12/20 01:54:24 INFO FileOutputCommitter: Saved output of task 'attempt_201612200154_0035_m_000000_57' to file:/home/moises/Tema5-Spark-notebook/outdir2/_temporary/0/task_201612200154_0035_m_000000
16/12/20 01:54:24 INFO SparkHadoopMapRedUtil: attempt_201612200154_0035_m_000000_57: Committed
16/12/20 01:54:24 INFO Executor: Finished task 0.0 in stage 35.0 (TID 57). 2005 bytes result sent to driver
16/12/20 01:54:24 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 57) in 148 ms on localhost (1/2)
16/12/20 01:54:24 INFO PythonRunner: Times: total = 42, boot = -378, init = 419, finish = 1
16/12/20 01:54:24 INFO FileOutputCommitter: Saved output of task 'attempt_201612200154_0035_m_000001_58' to file:/home/moises/Tema5-Spark-notebook/outdir2/_temporary/0/task_201612200154_0035_m_000001
16/12/20 01:54:24 INFO SparkHadoopMapRedUtil: attempt_201612200154_0035_m_000001_58: Committed
16/12/20 01:54:24 INFO Executor: Finished task 1.0 in stage 35.0 (TID 58). 2005 bytes result sent to driver
16/12/20 01:54:24 INFO TaskSetManager: Finished task 1.0 in stage 35.0 (TID 58) in 154 ms on localhost (2/2)
16/12/20 01:54:24 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
16/12/20 01:54:24 INFO DAGScheduler: ResultStage 35 (saveAsTextFile at NativeMethodAccessorImpl.java:-2) finished in 0,134 s
16/12/20 01:54:24 INFO DAGScheduler: Job 10 finished: saveAsTextFile at NativeMethodAccessorImpl.java:-2, took 0,312699 s
16/12/20 01:54:25 INFO SparkContext: Invoking stop() from shutdown hook
16/12/20 01:54:25 INFO SparkUI: Stopped Spark web UI at http://192.168.1.109:4046
16/12/20 01:54:25 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
16/12/20 01:54:25 INFO MemoryStore: MemoryStore cleared
16/12/20 01:54:25 INFO BlockManager: BlockManager stopped
16/12/20 01:54:25 INFO BlockManagerMaster: BlockManagerMaster stopped
16/12/20 01:54:25 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
16/12/20 01:54:25 INFO SparkContext: Successfully stopped SparkContext
16/12/20 01:54:25 INFO ShutdownHookManager: Shutdown hook called
16/12/20 01:54:25 INFO ShutdownHookManager: Deleting directory /tmp/spark-b2d27e6a-bcb4-4d5f-9d5c-4a28dc16341f/pyspark-b1403040-516f-4633-8d3a-e176afc39abd
16/12/20 01:54:25 INFO ShutdownHookManager: Deleting directory /tmp/spark-b2d27e6a-bcb4-4d5f-9d5c-4a28dc16341f
