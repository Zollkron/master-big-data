{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests Boletines 1 y 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(x: 0, y: 0, z: 0)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "class Punto:\n",
    "    \n",
    "    def __init__(self, x,y,z):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.z = z\n",
    "        \n",
    "    def imprimirPunto(self):\n",
    "        print \"(x: \" + str(self.x) + \", y: \" + str(self.y) + \", z: \" + str(self.z) + \")\"\n",
    "\n",
    "def distanciaEuclides(punto1, punto2):\n",
    "    distancia = math.sqrt((punto2.x-punto1.x)**2+(punto2.y-punto1.y)**2+(punto2.z-punto1.z)**2)\n",
    "    return distancia\n",
    "\n",
    "puntoOrigen = Punto(0,0,0)\n",
    "puntoOrigen.imprimirPunto()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apartado a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.60555127546\n",
      "3.16227766017\n",
      "3.16227766017\n",
      "3.16227766017\n",
      "2.44948974278\n",
      "2.44948974278\n"
     ]
    }
   ],
   "source": [
    "puntos = []\n",
    "puntos.append(Punto(0,3,2))\n",
    "puntos.append(Punto(3,0,1))\n",
    "puntos.append(Punto(0,3,-1))\n",
    "puntos.append(Punto(3,0,-1))\n",
    "puntos.append(Punto(1,2,1))\n",
    "puntos.append(Punto(2,1,1))\n",
    "for punto in puntos:\n",
    "    print distanciaEuclides(puntoOrigen,punto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apartado b "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para K=1 la predicción sería del 50% de probabilidad de que el punto elegido sea Punto(1,2,1) y otro 50% de probabilidad de que el punto elegido sea Punto(2,1,1), ya que ambos puntos son los vecinos más próximos al punto de test Punto(0,0,0), ya que ambos se encuentran a la misma distancia euclídea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apartado c "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para K=3 la predicción sería el Punto(1,2,1) y Punto(2,1,1) de forma segura al ser los dos vecinos más próximos en distancia euclídea, y el tercer vecino más próximo sería con un 1/3 de probabilidad o bien Punto(3,0,1), o bien Punto(0,3,-1), o bien Punto(3,0,-1) ya que dichos 3 puntos serían los siguientes más próximos y están a la misma distancia euclídea los tres del punto de test Punto(0,0,0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apartado a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cuatro variables de entrada numéricas -> Recency (months),Frequency (times), Monetary (c.c. blood), y Time (months)\n",
    "- Una de salida booleana diciendo si sí o si no donó sangre en Marzo de 2007 -> \"whether he/she donated blood in March 2007\"\n",
    "- Hay 748 instancias.\n",
    "- Dos clases: Los que sí donaron en Marzo de 2007 y los que no. La distribución es 0 ó 1.\n",
    "- Se eliminan como valores perdidos los NaN (Not a Number), ya que las variables tienen que contener números válidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(748, 5)\n",
      "xRaw, y [[  2.00000000e+00   5.00000000e+01   1.25000000e+04   9.80000000e+01]\n",
      " [  0.00000000e+00   1.30000000e+01   3.25000000e+03   2.80000000e+01]\n",
      " [  1.00000000e+00   1.60000000e+01   4.00000000e+03   3.50000000e+01]\n",
      " ..., \n",
      " [  2.30000000e+01   3.00000000e+00   7.50000000e+02   6.20000000e+01]\n",
      " [  3.90000000e+01   1.00000000e+00   2.50000000e+02   3.90000000e+01]\n",
      " [  7.20000000e+01   1.00000000e+00   2.50000000e+02   7.20000000e+01]] [ 1.  1.  1.  1.  0.  0.  1.  0.  1.  1.  0.  0.  1.  0.  1.  1.  1.  1.\n",
      "  1.  1.  1.  0.  1.  1.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  0.  1.\n",
      "  1.  1.  1.  1.  1.  0.  1.  0.  1.  1.  0.  0.  0.  0.  0.  1.  0.  0.\n",
      "  1.  1.  1.  1.  0.  0.  0.  1.  0.  1.  1.  0.  1.  0.  0.  0.  0.  0.\n",
      "  1.  0.  1.  1.  1.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  1.\n",
      "  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  0.  0.\n",
      "  1.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  1.  0.  0.  1.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.\n",
      "  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.\n",
      "  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  0.  0.  0.  0.  1.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.\n",
      "  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.\n",
      "  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.\n",
      "  1.  1.  1.  0.  1.  1.  1.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  0.  0.  1.  0.  0.  1.  1.  1.  0.  0.  0.  1.  1.  1.  1.  1.\n",
      "  1.  0.  1.  1.  0.  1.  0.  0.  1.  1.  0.  1.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  1.\n",
      "  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.\n",
      "  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "mean, std [    9.50668449     5.51470588  1378.67647059    34.28208556] [    8.08998246     5.83540254  1458.85063437    24.36041432]\n",
      "Eliminate missing values: mean, std [    9.50668449     5.51470588  1378.67647059    34.28208556] [    8.08998246     5.83540254  1458.85063437    24.36041432]\n",
      "Data after x standardizing [[-0.92789873  7.62334626  7.62334626  2.61563344]\n",
      " [-1.17511806  1.28273826  1.28273826 -0.2578809 ]\n",
      " [-1.0515084   1.79684161  1.79684161  0.02947053]\n",
      " ..., \n",
      " [ 1.66790417 -0.43093957 -0.43093957  1.13782607]\n",
      " [ 3.64565877 -0.77367514 -0.77367514  0.19367135]\n",
      " [ 7.72477762 -0.77367514 -0.77367514  1.54832812]]\n",
      "mean, std [    9.50668449     5.51470588  1378.67647059    34.28208556] [    8.08998246     5.83540254  1458.85063437    24.36041432]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing, cross_validation, neighbors\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.externals import joblib\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "datasetName = 'bloodTransfusion.data'\n",
    "datasetDelimiter = ','\n",
    "\n",
    "# load the CSV file as a numpy matrix\n",
    "dataset = np.loadtxt(datasetName, delimiter=datasetDelimiter)\n",
    "print dataset.shape\n",
    "# separate the data from the target attributes\n",
    "xRaw = dataset[:,0:dataset.shape[1]-1]\n",
    "y = dataset[:,dataset.shape[1]-1]\n",
    "print \"xRaw, y\", xRaw, y\n",
    "print \"mean, std\", xRaw.mean(axis=0), xRaw.std(axis=0)\n",
    "# missing values\n",
    "imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "xPrep = imp.fit_transform(xRaw)\n",
    "print \"Eliminate missing values: mean, std\", xPrep.mean(axis=0), xPrep.std(axis=0)\n",
    "#Standardize data\n",
    "scaler = preprocessing.StandardScaler().fit(xPrep)\n",
    "x=scaler.transform(xPrep)\n",
    "print \"Data after x standardizing\", x\n",
    "print \"mean, std\", scaler.mean_, scaler.scale_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apartado b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la página web de la documentación oficial de Scikit-Learn para esta clase http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html podemos ver\n",
    "\n",
    "- Parámetros\n",
    "\n",
    "n_neighbors : int, optional (default = 5)\n",
    "\n",
    "    Number of neighbors to use by default for k_neighbors queries.\n",
    "\n",
    "weights : str or callable, optional (default = ‘uniform’)\n",
    "\n",
    "    weight function used in prediction. Possible values:\n",
    "\n",
    "        ‘uniform’ : uniform weights. All points in each neighborhood are weighted equally.\n",
    "        ‘distance’ : weight points by the inverse of their distance. in this case, closer neighbors of a query point will have a greater influence than neighbors which are further away.\n",
    "        [callable] : a user-defined function which accepts an array of distances, and returns an array of the same shape containing the weights.\n",
    "\n",
    "algorithm : {‘auto’, ‘ball_tree’, ‘kd_tree’, ‘brute’}, optional\n",
    "\n",
    "    Algorithm used to compute the nearest neighbors:\n",
    "\n",
    "        ‘ball_tree’ will use BallTree\n",
    "        ‘kd_tree’ will use KDTree\n",
    "        ‘brute’ will use a brute-force search.\n",
    "        ‘auto’ will attempt to decide the most appropriate algorithm based on the values passed to fit method.\n",
    "\n",
    "    Note: fitting on sparse input will override the setting of this parameter, using brute force.\n",
    "\n",
    "leaf_size : int, optional (default = 30)\n",
    "\n",
    "    Leaf size passed to BallTree or KDTree. This can affect the speed of the construction and query, as well as the memory required to store the tree. The optimal value depends on the nature of the problem.\n",
    "\n",
    "metric : string or DistanceMetric object (default = ‘minkowski’)\n",
    "\n",
    "    the distance metric to use for the tree. The default metric is minkowski, and with p=2 is equivalent to the standard Euclidean metric. See the documentation of the DistanceMetric class for a list of available metrics.\n",
    "\n",
    "p : integer, optional (default = 2)\n",
    "\n",
    "    Power parameter for the Minkowski metric. When p = 1, this is equivalent to using manhattan_distance (l1), and euclidean_distance (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.\n",
    "\n",
    "metric_params : dict, optional (default = None)\n",
    "\n",
    "    Additional keyword arguments for the metric function.\n",
    "\n",
    "n_jobs : int, optional (default = 1)\n",
    "\n",
    "    The number of parallel jobs to run for neighbors search. If -1, then the number of jobs is set to the number of CPU cores. Doesn’t affect fit method.\n",
    "\n",
    "- Métodos\n",
    "\n",
    "    - fit(X, y) \tFit the model using X as training data and y as target values\n",
    "    - get_params([deep]) \tGet parameters for this estimator.\n",
    "    - kneighbors([X, n_neighbors, return_distance]) \tFinds the K-neighbors of a point.\n",
    "    - kneighbors_graph([X, n_neighbors, mode]) \tComputes the (weighted) graph of k-Neighbors for points in X\n",
    "    - predict(X) \tPredict the class labels for the provided data\n",
    "    - predict_proba(X) \tReturn probability estimates for the test data X.\n",
    "    - score(X, y[, sample_weight]) \tReturns the mean accuracy on the given test data and labels.\n",
    "    - set_params(\\*\\*params) \tSet the parameters of this estimator.\n",
    "    - __init__(n_neighbors=5, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=1, **kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apartado c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xTrain [[-0.68067941  0.59726713  0.59726713  0.15262115]\n",
      " [-0.80428907 -0.08820401 -0.08820401 -0.91468418]\n",
      " [-0.92789873 -0.77367514 -0.77367514 -1.32518623]\n",
      " ..., \n",
      " [-0.30985042  0.9400027   0.9400027   2.2461816 ]\n",
      " [-0.80428907  0.42589934  0.42589934  0.64522361]\n",
      " [ 0.80263654 -0.25957179 -0.25957179 -0.05262988]] \n",
      "xTest [[-0.68067941 -0.43093957 -0.43093957 -0.2578809 ]\n",
      " [-0.92789873  0.9400027   0.9400027   0.27577176]\n",
      " [-0.92789873  0.08316378  0.08316378 -0.79153356]\n",
      " [-0.68067941  0.76863491  0.76863491 -0.2578809 ]\n",
      " [-0.92789873  6.08103621  6.08103621  2.61563344]\n",
      " [-0.92789873 -0.60230736 -0.60230736 -1.24308582]\n",
      " [ 0.55541721 -0.77367514 -0.77367514 -0.83258377]\n",
      " [-0.92789873 -0.60230736 -0.60230736 -1.24308582]\n",
      " [ 1.66790417 -0.43093957 -0.43093957  0.23472156]\n",
      " [-0.68067941  1.11137048  1.11137048 -0.01157967]\n",
      " [ 0.18458823  0.08316378  0.08316378  0.27577176]\n",
      " [ 0.55541721 -0.25957179 -0.25957179  0.15262115]\n",
      " [-0.92789873 -0.77367514 -0.77367514 -1.32518623]\n",
      " [-0.68067941  1.28273826  1.28273826  0.19367135]\n",
      " [-0.92789873  1.28273826  1.28273826  0.76837422]\n",
      " [ 1.66790417  0.42589934  0.42589934  1.4251775 ]\n",
      " [-0.18624076 -0.60230736 -0.60230736 -0.75048336]\n",
      " [ 1.42068485 -0.77367514 -0.77367514 -0.54523233]\n",
      " [ 0.55541721  0.25453156  0.25453156  1.54832812]\n",
      " [-0.68067941  0.42589934  0.42589934  0.23472156]\n",
      " [ 0.18458823  0.25453156  0.25453156  1.21992648]\n",
      " [ 0.18458823 -0.60230736 -0.60230736 -0.95573438]\n",
      " [ 0.18458823 -0.77367514 -0.77367514 -0.95573438]\n",
      " [-0.68067941 -0.77367514 -0.77367514 -1.24308582]\n",
      " [-0.43346009 -0.43093957 -0.43093957 -0.33998131]\n",
      " [ 0.55541721  0.42589934  0.42589934 -0.33998131]\n",
      " [-0.92789873 -0.77367514 -0.77367514 -1.32518623]\n",
      " [-0.68067941  2.31094497  2.31094497  1.4251775 ]\n",
      " [ 1.04985586 -0.60230736 -0.60230736 -0.46313192]\n",
      " [ 0.18458823  0.25453156  0.25453156  1.13782607]\n",
      " [-0.92789873  0.59726713  0.59726713 -0.50418213]\n",
      " [-0.68067941 -0.60230736 -0.60230736 -0.13473028]\n",
      " [ 3.52204911 -0.77367514 -0.77367514  0.15262115]\n",
      " [-0.68067941  0.08316378  0.08316378  0.02947053]\n",
      " [-0.92789873 -0.43093957 -0.43093957  1.75357914]\n",
      " [-0.68067941 -0.77367514 -0.77367514 -1.24308582]\n",
      " [ 0.80263654 -0.77367514 -0.77367514 -0.75048336]\n",
      " [-0.68067941  1.45410605  1.45410605  2.12303099]\n",
      " [-0.30985042 -0.60230736 -0.60230736 -0.75048336]\n",
      " [ 0.80263654 -0.77367514 -0.77367514 -0.75048336]\n",
      " [ 0.18458823 -0.60230736 -0.60230736 -0.95573438]\n",
      " [ 0.06097856 -0.08820401 -0.08820401  0.15262115]\n",
      " [-0.68067941 -0.77367514 -0.77367514 -1.24308582]\n",
      " [-1.17511806  1.28273826  1.28273826 -0.2578809 ]\n",
      " [ 0.18458823 -0.25957179 -0.25957179  0.97362525]\n",
      " [ 0.55541721 -0.08820401 -0.08820401  1.63042853]\n",
      " [-0.68067941  0.08316378  0.08316378  0.48102279]\n",
      " [ 0.55541721 -0.60230736 -0.60230736 -0.83258377]\n",
      " [-0.80428907  1.45410605  1.45410605  0.02947053]\n",
      " [ 0.18458823  0.42589934  0.42589934  0.27577176]\n",
      " [ 1.42068485 -0.43093957 -0.43093957 -0.33998131]\n",
      " [-0.0626311   0.42589934  0.42589934  0.15262115]\n",
      " [ 0.18458823 -0.60230736 -0.60230736 -0.83258377]\n",
      " [ 0.18458823 -0.77367514 -0.77367514 -0.95573438]\n",
      " [ 0.80263654 -0.08820401 -0.08820401  0.23472156]\n",
      " [-0.92789873  0.42589934  0.42589934  0.15262115]\n",
      " [-0.68067941 -0.60230736 -0.60230736  0.48102279]\n",
      " [ 0.18458823 -0.08820401 -0.08820401 -0.66838295]\n",
      " [ 0.18458823 -0.08820401 -0.08820401  0.64522361]\n",
      " [ 0.55541721 -0.60230736 -0.60230736 -0.83258377]\n",
      " [-0.68067941 -0.08820401 -0.08820401  0.97362525]\n",
      " [-0.92789873 -0.77367514 -0.77367514 -1.32518623]\n",
      " [-0.92789873  0.08316378  0.08316378 -0.2578809 ]\n",
      " [-0.92789873  1.11137048  1.11137048  1.46622771]\n",
      " [-0.68067941 -0.77367514 -0.77367514 -1.24308582]\n",
      " [-0.68067941 -0.77367514 -0.77367514 -1.24308582]\n",
      " [ 0.55541721 -0.60230736 -0.60230736 -0.83258377]\n",
      " [ 0.55541721 -0.60230736 -0.60230736 -0.83258377]\n",
      " [ 1.66790417 -0.60230736 -0.60230736  2.16408119]\n",
      " [-1.17511806  3.51051945  3.51051945  1.71252894]\n",
      " [ 1.66790417  1.62547383  1.62547383  0.93257504]\n",
      " [ 0.18458823  0.59726713  0.59726713  1.54832812]\n",
      " [-0.92789873 -0.77367514 -0.77367514 -1.32518623]\n",
      " [-0.92789873  0.08316378  0.08316378  0.43997258]\n",
      " [-0.68067941 -0.60230736 -0.60230736  0.27577176]\n",
      " [-0.68067941 -0.77367514 -0.77367514 -1.24308582]\n",
      " [ 0.55541721 -0.08820401 -0.08820401 -0.83258377]\n",
      " [ 0.80263654 -0.60230736 -0.60230736 -0.75048336]\n",
      " [-0.92789873  1.62547383  1.62547383  1.21992648]\n",
      " [-0.92789873  0.08316378  0.08316378 -0.33998131]\n",
      " [-0.92789873  0.08316378  0.08316378 -0.79153356]\n",
      " [ 0.18458823  1.9682094   1.9682094   1.83567955]\n",
      " [-0.92789873 -0.08820401 -0.08820401 -0.33998131]\n",
      " [-0.92789873 -0.43093957 -0.43093957  0.72732402]\n",
      " [-0.92789873 -0.08820401 -0.08820401 -0.75048336]\n",
      " [-0.92789873  0.9400027   0.9400027   0.48102279]\n",
      " [-0.68067941 -0.77367514 -0.77367514 -1.24308582]\n",
      " [-0.92789873  0.08316378  0.08316378 -0.2578809 ]\n",
      " [ 1.66790417 -0.43093957 -0.43093957 -0.2578809 ]\n",
      " [ 7.97199695 -0.77367514 -0.77367514  1.63042853]\n",
      " [ 0.80263654 -0.25957179 -0.25957179 -0.2578809 ]\n",
      " [ 3.15122012 -0.43093957 -0.43093957  1.21992648]\n",
      " [-0.68067941  2.9964161   2.9964161   0.97362525]\n",
      " [-0.68067941  0.25453156  0.25453156 -0.38103151]\n",
      " [-0.92789873  6.42377178  6.42377178  2.12303099]\n",
      " [-0.92789873  0.9400027   0.9400027   0.23472156]\n",
      " [-0.92789873  0.9400027   0.9400027  -0.33998131]\n",
      " [ 1.66790417  0.25453156  0.25453156  2.2051314 ]\n",
      " [-0.30985042  1.45410605  1.45410605  0.5631232 ]\n",
      " [-0.92789873 -0.77367514 -0.77367514 -1.32518623]\n",
      " [-0.68067941 -0.08820401 -0.08820401 -0.75048336]\n",
      " [ 0.55541721  2.13957718  2.13957718  1.79462935]\n",
      " [-0.80428907 -0.60230736 -0.60230736 -0.46313192]\n",
      " [-0.43346009 -0.60230736 -0.60230736 -0.95573438]\n",
      " [ 0.55541721 -0.77367514 -0.77367514 -0.83258377]\n",
      " [ 0.18458823 -0.25957179 -0.25957179  1.01467545]\n",
      " [ 1.66790417 -0.77367514 -0.77367514 -0.46313192]\n",
      " [-0.92789873 -0.60230736 -0.60230736 -0.95573438]\n",
      " [-0.68067941  0.25453156  0.25453156 -0.09368008]\n",
      " [ 1.9151235   0.08316378  0.08316378  0.64522361]\n",
      " [-0.92789873 -0.77367514 -0.77367514 -1.32518623]\n",
      " [ 1.42068485 -0.77367514 -0.77367514 -0.54523233]\n",
      " [ 0.55541721  0.08316378  0.08316378  0.68627381]\n",
      " [ 0.55541721 -0.77367514 -0.77367514 -0.83258377]\n",
      " [ 0.18458823  0.9400027   0.9400027   0.15262115]\n",
      " [ 1.42068485 -0.08820401 -0.08820401  1.05572566]\n",
      " [-0.92789873 -0.25957179 -0.25957179 -0.75048336]\n",
      " [-0.92789873 -0.60230736 -0.60230736 -1.32518623]\n",
      " [ 1.42068485 -0.77367514 -0.77367514 -0.54523233]\n",
      " [ 1.66790417 -0.43093957 -0.43093957  2.2461816 ]\n",
      " [-0.92789873  0.08316378  0.08316378  0.27577176]\n",
      " [-0.68067941  0.59726713  0.59726713  0.72732402]\n",
      " [ 0.43180755 -0.43093957 -0.43093957 -0.83258377]\n",
      " [ 1.66790417 -0.25957179 -0.25957179  0.43997258]\n",
      " [-0.68067941  0.08316378  0.08316378 -0.75048336]\n",
      " [ 0.18458823 -0.60230736 -0.60230736 -0.54523233]\n",
      " [-0.92789873 -0.60230736 -0.60230736 -1.32518623]\n",
      " [-0.68067941 -0.77367514 -0.77367514 -1.24308582]\n",
      " [ 0.80263654  1.79684161  1.79684161  1.75357914]\n",
      " [ 0.80263654  0.25453156  0.25453156 -0.2578809 ]\n",
      " [ 0.18458823  0.9400027   0.9400027   0.31682197]\n",
      " [-0.68067941 -0.43093957 -0.43093957 -0.75048336]\n",
      " [-0.92789873 -0.25957179 -0.25957179 -0.75048336]\n",
      " [-0.92789873 -0.43093957 -0.43093957 -1.03783479]\n",
      " [ 0.18458823  0.42589934  0.42589934  0.72732402]\n",
      " [-0.92789873  0.08316378  0.08316378 -0.50418213]\n",
      " [ 1.66790417 -0.43093957 -0.43093957  0.5631232 ]\n",
      " [ 1.42068485 -0.43093957 -0.43093957 -0.33998131]\n",
      " [ 1.66790417 -0.60230736 -0.60230736 -0.2578809 ]\n",
      " [-0.0626311  -0.77367514 -0.77367514 -1.03783479]\n",
      " [-0.30985042  0.76863491  0.76863491  0.52207299]\n",
      " [ 0.55541721 -0.25957179 -0.25957179 -0.33998131]\n",
      " [ 0.06097856 -0.25957179 -0.25957179 -0.75048336]\n",
      " [ 0.18458823  0.59726713  0.59726713  0.15262115]\n",
      " [-1.0515084   0.25453156  0.25453156  0.93257504]\n",
      " [-0.68067941 -0.77367514 -0.77367514 -1.24308582]\n",
      " [-0.68067941 -0.25957179 -0.25957179 -0.33998131]\n",
      " [ 1.42068485 -0.43093957 -0.43093957  0.02947053]\n",
      " [ 0.18458823 -0.08820401 -0.08820401  0.02947053]\n",
      " [ 0.80263654 -0.77367514 -0.77367514 -0.75048336]] \n",
      "yTrain [ 1.  1.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.  0.  0.\n",
      "  1.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  0.  1.  1.  0.  0.  1.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.\n",
      "  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  0.\n",
      "  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  1.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  1.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.\n",
      "  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.\n",
      "  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.\n",
      "  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  0.  0.  0.  1.\n",
      "  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.\n",
      "  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  0.  1.  0.  1.  1.  0.\n",
      "  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  1.  0.  1.  0.  1.  1.  0.  0.  1.  0.  1.  1.  1.  0.  0.\n",
      "  0.  1.  1.  0.  1.  0.  0.  1.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  0.  1.  0.  1.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.\n",
      "  1.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.  0.\n",
      "  0.  1.  0.  1.  0.  1.  1.  1.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  0.  1.\n",
      "  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.\n",
      "  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  0.\n",
      "  0.  1.  0.  1.  0.  1.  1.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.\n",
      "  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.\n",
      "  0.  0.  0.  0.] \n",
      "yTest [ 0.  1.  1.  1.  1.  0.  0.  1.  0.  1.  0.  0.  0.  1.  1.  0.  0.  0.\n",
      "  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  1.  0.  1.\n",
      "  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.\n",
      "  1.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  1.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  0.  1.  0.  0.\n",
      "  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  1.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.\n",
      "  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "#Divide in training and test, shuffling the examples and keeping the proportion of examples of each class\n",
    "xTrain, xTest, yTrain, yTest = cross_validation.train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "print 'xTrain', xTrain, \"\\nxTest\", xTest, \"\\nyTrain\", yTrain, \"\\nyTest\", yTest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apartado d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"one standard error rule\" is applied when selecting models through cross-validation (or more generally through any randomization-based procedure).\n",
    "\n",
    "Assume we consider models Mτ\n",
    "indexed by a complexity parameter τ∈ℝ, such that Mτ is \"more complex\" than Mτ′ exactly when τ>τ′. Assume further that we assess the quality of a model M by some randomization process, e.g., cross-validation. Let q(M) denote the \"average\" quality of M\n",
    "\n",
    ", e.g., the mean out-of-bag prediction error across many cross-validation runs. We wish to minimize this quantity.\n",
    "\n",
    "However, since our quality measure comes from some randomization procedure, it comes with variability. Let s(M)\n",
    "denote the standard error of the quality of M across the randomization runs, e.g., the standard deviation of the out-of-bag prediction error of M\n",
    "\n",
    "over cross-validation runs.\n",
    "\n",
    "Then we choose the model Mτ\n",
    ", where τ is the smallest τ\n",
    "\n",
    "such that\n",
    "\n",
    "q(Mτ)≤q(Mτ′)+s(Mτ′),\n",
    "\n",
    "where τ′\n",
    "indexes the (on average) best model, q(Mτ′)=minτq(Mτ)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters Cross-Validation {'n_neighbors': 29, 'weights': 'uniform'}\n",
      "0.719 (+/-0.026) for {'n_neighbors': 1, 'weights': 'uniform'}\n",
      "()\n",
      "0.719 (+/-0.026) for {'n_neighbors': 1, 'weights': 'distance'}\n",
      "()\n",
      "0.768 (+/-0.021) for {'n_neighbors': 2, 'weights': 'uniform'}\n",
      "()\n",
      "0.729 (+/-0.034) for {'n_neighbors': 2, 'weights': 'distance'}\n",
      "()\n",
      "0.751 (+/-0.018) for {'n_neighbors': 3, 'weights': 'uniform'}\n",
      "()\n",
      "0.739 (+/-0.020) for {'n_neighbors': 3, 'weights': 'distance'}\n",
      "()\n",
      "0.771 (+/-0.031) for {'n_neighbors': 4, 'weights': 'uniform'}\n",
      "()\n",
      "0.746 (+/-0.028) for {'n_neighbors': 4, 'weights': 'distance'}\n",
      "()\n",
      "0.749 (+/-0.030) for {'n_neighbors': 5, 'weights': 'uniform'}\n",
      "()\n",
      "0.727 (+/-0.025) for {'n_neighbors': 5, 'weights': 'distance'}\n",
      "()\n",
      "0.773 (+/-0.022) for {'n_neighbors': 6, 'weights': 'uniform'}\n",
      "()\n",
      "0.756 (+/-0.032) for {'n_neighbors': 6, 'weights': 'distance'}\n",
      "()\n",
      "0.769 (+/-0.039) for {'n_neighbors': 7, 'weights': 'uniform'}\n",
      "()\n",
      "0.753 (+/-0.039) for {'n_neighbors': 7, 'weights': 'distance'}\n",
      "()\n",
      "0.769 (+/-0.025) for {'n_neighbors': 8, 'weights': 'uniform'}\n",
      "()\n",
      "0.756 (+/-0.028) for {'n_neighbors': 8, 'weights': 'distance'}\n",
      "()\n",
      "0.771 (+/-0.034) for {'n_neighbors': 9, 'weights': 'uniform'}\n",
      "()\n",
      "0.759 (+/-0.038) for {'n_neighbors': 9, 'weights': 'distance'}\n",
      "()\n",
      "0.776 (+/-0.023) for {'n_neighbors': 10, 'weights': 'uniform'}\n",
      "()\n",
      "0.766 (+/-0.035) for {'n_neighbors': 10, 'weights': 'distance'}\n",
      "()\n",
      "0.781 (+/-0.031) for {'n_neighbors': 11, 'weights': 'uniform'}\n",
      "()\n",
      "0.763 (+/-0.036) for {'n_neighbors': 11, 'weights': 'distance'}\n",
      "()\n",
      "0.786 (+/-0.022) for {'n_neighbors': 12, 'weights': 'uniform'}\n",
      "()\n",
      "0.766 (+/-0.030) for {'n_neighbors': 12, 'weights': 'distance'}\n",
      "()\n",
      "0.781 (+/-0.030) for {'n_neighbors': 13, 'weights': 'uniform'}\n",
      "()\n",
      "0.763 (+/-0.032) for {'n_neighbors': 13, 'weights': 'distance'}\n",
      "()\n",
      "0.779 (+/-0.026) for {'n_neighbors': 14, 'weights': 'uniform'}\n",
      "()\n",
      "0.763 (+/-0.028) for {'n_neighbors': 14, 'weights': 'distance'}\n",
      "()\n",
      "0.779 (+/-0.030) for {'n_neighbors': 15, 'weights': 'uniform'}\n",
      "()\n",
      "0.761 (+/-0.029) for {'n_neighbors': 15, 'weights': 'distance'}\n",
      "()\n",
      "0.771 (+/-0.033) for {'n_neighbors': 16, 'weights': 'uniform'}\n",
      "()\n",
      "0.766 (+/-0.026) for {'n_neighbors': 16, 'weights': 'distance'}\n",
      "()\n",
      "0.783 (+/-0.032) for {'n_neighbors': 17, 'weights': 'uniform'}\n",
      "()\n",
      "0.768 (+/-0.024) for {'n_neighbors': 17, 'weights': 'distance'}\n",
      "()\n",
      "0.774 (+/-0.025) for {'n_neighbors': 18, 'weights': 'uniform'}\n",
      "()\n",
      "0.766 (+/-0.022) for {'n_neighbors': 18, 'weights': 'distance'}\n",
      "()\n",
      "0.784 (+/-0.030) for {'n_neighbors': 19, 'weights': 'uniform'}\n",
      "()\n",
      "0.768 (+/-0.025) for {'n_neighbors': 19, 'weights': 'distance'}\n",
      "()\n",
      "0.774 (+/-0.025) for {'n_neighbors': 20, 'weights': 'uniform'}\n",
      "()\n",
      "0.769 (+/-0.026) for {'n_neighbors': 20, 'weights': 'distance'}\n",
      "()\n",
      "0.783 (+/-0.030) for {'n_neighbors': 21, 'weights': 'uniform'}\n",
      "()\n",
      "0.768 (+/-0.029) for {'n_neighbors': 21, 'weights': 'distance'}\n",
      "()\n",
      "0.778 (+/-0.027) for {'n_neighbors': 22, 'weights': 'uniform'}\n",
      "()\n",
      "0.769 (+/-0.026) for {'n_neighbors': 22, 'weights': 'distance'}\n",
      "()\n",
      "0.781 (+/-0.027) for {'n_neighbors': 23, 'weights': 'uniform'}\n",
      "()\n",
      "0.764 (+/-0.028) for {'n_neighbors': 23, 'weights': 'distance'}\n",
      "()\n",
      "0.774 (+/-0.025) for {'n_neighbors': 24, 'weights': 'uniform'}\n",
      "()\n",
      "0.769 (+/-0.030) for {'n_neighbors': 24, 'weights': 'distance'}\n",
      "()\n",
      "0.784 (+/-0.022) for {'n_neighbors': 25, 'weights': 'uniform'}\n",
      "()\n",
      "0.768 (+/-0.033) for {'n_neighbors': 25, 'weights': 'distance'}\n",
      "()\n",
      "0.779 (+/-0.022) for {'n_neighbors': 26, 'weights': 'uniform'}\n",
      "()\n",
      "0.771 (+/-0.024) for {'n_neighbors': 26, 'weights': 'distance'}\n",
      "()\n",
      "0.788 (+/-0.025) for {'n_neighbors': 27, 'weights': 'uniform'}\n",
      "()\n",
      "0.768 (+/-0.022) for {'n_neighbors': 27, 'weights': 'distance'}\n",
      "()\n",
      "0.786 (+/-0.016) for {'n_neighbors': 28, 'weights': 'uniform'}\n",
      "()\n",
      "0.769 (+/-0.025) for {'n_neighbors': 28, 'weights': 'distance'}\n",
      "()\n",
      "0.794 (+/-0.024) for {'n_neighbors': 29, 'weights': 'uniform'}\n",
      "()\n",
      "0.773 (+/-0.026) for {'n_neighbors': 29, 'weights': 'distance'}\n",
      "()\n",
      "0.789 (+/-0.020) for {'n_neighbors': 30, 'weights': 'uniform'}\n",
      "()\n",
      "0.769 (+/-0.023) for {'n_neighbors': 30, 'weights': 'distance'}\n",
      "()\n",
      "0.788 (+/-0.025) for {'n_neighbors': 31, 'weights': 'uniform'}\n",
      "()\n",
      "0.774 (+/-0.027) for {'n_neighbors': 31, 'weights': 'distance'}\n",
      "()\n",
      "0.783 (+/-0.026) for {'n_neighbors': 32, 'weights': 'uniform'}\n",
      "()\n",
      "0.769 (+/-0.025) for {'n_neighbors': 32, 'weights': 'distance'}\n",
      "()\n",
      "0.788 (+/-0.026) for {'n_neighbors': 33, 'weights': 'uniform'}\n",
      "()\n",
      "0.773 (+/-0.026) for {'n_neighbors': 33, 'weights': 'distance'}\n",
      "()\n",
      "0.783 (+/-0.024) for {'n_neighbors': 34, 'weights': 'uniform'}\n",
      "()\n",
      "0.768 (+/-0.022) for {'n_neighbors': 34, 'weights': 'distance'}\n",
      "()\n",
      "0.788 (+/-0.027) for {'n_neighbors': 35, 'weights': 'uniform'}\n",
      "()\n",
      "0.771 (+/-0.024) for {'n_neighbors': 35, 'weights': 'distance'}\n",
      "()\n",
      "0.778 (+/-0.026) for {'n_neighbors': 36, 'weights': 'uniform'}\n",
      "()\n",
      "0.766 (+/-0.021) for {'n_neighbors': 36, 'weights': 'distance'}\n",
      "()\n",
      "0.781 (+/-0.023) for {'n_neighbors': 37, 'weights': 'uniform'}\n",
      "()\n",
      "0.764 (+/-0.025) for {'n_neighbors': 37, 'weights': 'distance'}\n",
      "()\n",
      "0.778 (+/-0.024) for {'n_neighbors': 38, 'weights': 'uniform'}\n",
      "()\n",
      "0.766 (+/-0.025) for {'n_neighbors': 38, 'weights': 'distance'}\n",
      "()\n",
      "0.784 (+/-0.024) for {'n_neighbors': 39, 'weights': 'uniform'}\n",
      "()\n",
      "0.768 (+/-0.026) for {'n_neighbors': 39, 'weights': 'distance'}\n",
      "()\n",
      "0.781 (+/-0.017) for {'n_neighbors': 40, 'weights': 'uniform'}\n",
      "()\n",
      "0.764 (+/-0.024) for {'n_neighbors': 40, 'weights': 'distance'}\n",
      "()\n",
      "0.779 (+/-0.020) for {'n_neighbors': 41, 'weights': 'uniform'}\n",
      "()\n",
      "0.766 (+/-0.022) for {'n_neighbors': 41, 'weights': 'distance'}\n",
      "()\n",
      "0.778 (+/-0.017) for {'n_neighbors': 42, 'weights': 'uniform'}\n",
      "()\n",
      "0.766 (+/-0.021) for {'n_neighbors': 42, 'weights': 'distance'}\n",
      "()\n",
      "0.778 (+/-0.026) for {'n_neighbors': 43, 'weights': 'uniform'}\n",
      "()\n",
      "0.768 (+/-0.022) for {'n_neighbors': 43, 'weights': 'distance'}\n",
      "()\n",
      "0.774 (+/-0.021) for {'n_neighbors': 44, 'weights': 'uniform'}\n",
      "()\n",
      "0.764 (+/-0.020) for {'n_neighbors': 44, 'weights': 'distance'}\n",
      "()\n",
      "0.773 (+/-0.027) for {'n_neighbors': 45, 'weights': 'uniform'}\n",
      "()\n",
      "0.761 (+/-0.019) for {'n_neighbors': 45, 'weights': 'distance'}\n",
      "()\n",
      "0.781 (+/-0.014) for {'n_neighbors': 46, 'weights': 'uniform'}\n",
      "()\n",
      "0.763 (+/-0.019) for {'n_neighbors': 46, 'weights': 'distance'}\n",
      "()\n",
      "0.783 (+/-0.015) for {'n_neighbors': 47, 'weights': 'uniform'}\n",
      "()\n",
      "0.763 (+/-0.020) for {'n_neighbors': 47, 'weights': 'distance'}\n",
      "()\n",
      "0.781 (+/-0.017) for {'n_neighbors': 48, 'weights': 'uniform'}\n",
      "()\n",
      "0.763 (+/-0.019) for {'n_neighbors': 48, 'weights': 'distance'}\n",
      "()\n",
      "0.781 (+/-0.017) for {'n_neighbors': 49, 'weights': 'uniform'}\n",
      "()\n",
      "0.764 (+/-0.020) for {'n_neighbors': 49, 'weights': 'distance'}\n",
      "()\n",
      "0.774 (+/-0.014) for {'n_neighbors': 50, 'weights': 'uniform'}\n",
      "()\n",
      "0.763 (+/-0.019) for {'n_neighbors': 50, 'weights': 'distance'}\n",
      "()\n",
      "0.774 (+/-0.018) for {'n_neighbors': 51, 'weights': 'uniform'}\n",
      "()\n",
      "0.766 (+/-0.017) for {'n_neighbors': 51, 'weights': 'distance'}\n",
      "()\n",
      "0.778 (+/-0.009) for {'n_neighbors': 52, 'weights': 'uniform'}\n",
      "()\n",
      "0.764 (+/-0.020) for {'n_neighbors': 52, 'weights': 'distance'}\n",
      "()\n",
      "0.776 (+/-0.015) for {'n_neighbors': 53, 'weights': 'uniform'}\n",
      "()\n",
      "0.763 (+/-0.019) for {'n_neighbors': 53, 'weights': 'distance'}\n",
      "()\n",
      "0.768 (+/-0.014) for {'n_neighbors': 54, 'weights': 'uniform'}\n",
      "()\n",
      "0.761 (+/-0.019) for {'n_neighbors': 54, 'weights': 'distance'}\n",
      "()\n",
      "0.768 (+/-0.018) for {'n_neighbors': 55, 'weights': 'uniform'}\n",
      "()\n",
      "0.764 (+/-0.020) for {'n_neighbors': 55, 'weights': 'distance'}\n",
      "()\n",
      "0.769 (+/-0.005) for {'n_neighbors': 56, 'weights': 'uniform'}\n",
      "()\n",
      "0.761 (+/-0.019) for {'n_neighbors': 56, 'weights': 'distance'}\n",
      "()\n",
      "0.769 (+/-0.011) for {'n_neighbors': 57, 'weights': 'uniform'}\n",
      "()\n",
      "0.764 (+/-0.020) for {'n_neighbors': 57, 'weights': 'distance'}\n",
      "()\n",
      "0.769 (+/-0.010) for {'n_neighbors': 58, 'weights': 'uniform'}\n",
      "()\n",
      "0.759 (+/-0.018) for {'n_neighbors': 58, 'weights': 'distance'}\n",
      "()\n",
      "0.769 (+/-0.013) for {'n_neighbors': 59, 'weights': 'uniform'}\n",
      "()\n",
      "0.761 (+/-0.020) for {'n_neighbors': 59, 'weights': 'distance'}\n",
      "()\n",
      "0.768 (+/-0.014) for {'n_neighbors': 60, 'weights': 'uniform'}\n",
      "()\n",
      "0.761 (+/-0.020) for {'n_neighbors': 60, 'weights': 'distance'}\n",
      "()\n",
      "0.768 (+/-0.014) for {'n_neighbors': 61, 'weights': 'uniform'}\n",
      "()\n",
      "0.761 (+/-0.020) for {'n_neighbors': 61, 'weights': 'distance'}\n",
      "()\n",
      "0.764 (+/-0.019) for {'n_neighbors': 62, 'weights': 'uniform'}\n",
      "()\n",
      "0.761 (+/-0.016) for {'n_neighbors': 62, 'weights': 'distance'}\n",
      "()\n",
      "0.766 (+/-0.009) for {'n_neighbors': 63, 'weights': 'uniform'}\n",
      "()\n",
      "0.759 (+/-0.019) for {'n_neighbors': 63, 'weights': 'distance'}\n",
      "()\n",
      "0.769 (+/-0.016) for {'n_neighbors': 64, 'weights': 'uniform'}\n",
      "()\n",
      "0.754 (+/-0.020) for {'n_neighbors': 64, 'weights': 'distance'}\n",
      "()\n",
      "0.769 (+/-0.014) for {'n_neighbors': 65, 'weights': 'uniform'}\n",
      "()\n",
      "0.756 (+/-0.020) for {'n_neighbors': 65, 'weights': 'distance'}\n",
      "()\n",
      "0.771 (+/-0.017) for {'n_neighbors': 66, 'weights': 'uniform'}\n",
      "()\n",
      "0.754 (+/-0.020) for {'n_neighbors': 66, 'weights': 'distance'}\n",
      "()\n",
      "0.769 (+/-0.020) for {'n_neighbors': 67, 'weights': 'uniform'}\n",
      "()\n",
      "0.756 (+/-0.021) for {'n_neighbors': 67, 'weights': 'distance'}\n",
      "()\n",
      "0.773 (+/-0.011) for {'n_neighbors': 68, 'weights': 'uniform'}\n",
      "()\n",
      "0.759 (+/-0.019) for {'n_neighbors': 68, 'weights': 'distance'}\n",
      "()\n",
      "0.773 (+/-0.011) for {'n_neighbors': 69, 'weights': 'uniform'}\n",
      "()\n",
      "0.759 (+/-0.019) for {'n_neighbors': 69, 'weights': 'distance'}\n",
      "()\n",
      "0.776 (+/-0.009) for {'n_neighbors': 70, 'weights': 'uniform'}\n",
      "()\n",
      "0.758 (+/-0.018) for {'n_neighbors': 70, 'weights': 'distance'}\n",
      "()\n",
      "0.776 (+/-0.009) for {'n_neighbors': 71, 'weights': 'uniform'}\n",
      "()\n",
      "0.758 (+/-0.018) for {'n_neighbors': 71, 'weights': 'distance'}\n",
      "()\n",
      "0.774 (+/-0.010) for {'n_neighbors': 72, 'weights': 'uniform'}\n",
      "()\n",
      "0.759 (+/-0.016) for {'n_neighbors': 72, 'weights': 'distance'}\n",
      "()\n",
      "0.774 (+/-0.010) for {'n_neighbors': 73, 'weights': 'uniform'}\n",
      "()\n",
      "0.758 (+/-0.015) for {'n_neighbors': 73, 'weights': 'distance'}\n",
      "()\n",
      "0.773 (+/-0.011) for {'n_neighbors': 74, 'weights': 'uniform'}\n",
      "()\n",
      "0.761 (+/-0.013) for {'n_neighbors': 74, 'weights': 'distance'}\n",
      "()\n",
      "0.773 (+/-0.011) for {'n_neighbors': 75, 'weights': 'uniform'}\n",
      "()\n",
      "0.761 (+/-0.013) for {'n_neighbors': 75, 'weights': 'distance'}\n",
      "()\n",
      "0.771 (+/-0.011) for {'n_neighbors': 76, 'weights': 'uniform'}\n",
      "()\n",
      "0.759 (+/-0.010) for {'n_neighbors': 76, 'weights': 'distance'}\n",
      "()\n",
      "0.773 (+/-0.011) for {'n_neighbors': 77, 'weights': 'uniform'}\n",
      "()\n",
      "0.759 (+/-0.013) for {'n_neighbors': 77, 'weights': 'distance'}\n",
      "()\n",
      "0.771 (+/-0.006) for {'n_neighbors': 78, 'weights': 'uniform'}\n",
      "()\n",
      "0.761 (+/-0.013) for {'n_neighbors': 78, 'weights': 'distance'}\n",
      "()\n",
      "0.771 (+/-0.006) for {'n_neighbors': 79, 'weights': 'uniform'}\n",
      "()\n",
      "0.759 (+/-0.013) for {'n_neighbors': 79, 'weights': 'distance'}\n",
      "()\n",
      "0.769 (+/-0.003) for {'n_neighbors': 80, 'weights': 'uniform'}\n",
      "()\n",
      "0.759 (+/-0.010) for {'n_neighbors': 80, 'weights': 'distance'}\n",
      "()\n",
      "0.771 (+/-0.006) for {'n_neighbors': 81, 'weights': 'uniform'}\n",
      "()\n",
      "0.766 (+/-0.010) for {'n_neighbors': 81, 'weights': 'distance'}\n",
      "()\n",
      "0.771 (+/-0.004) for {'n_neighbors': 82, 'weights': 'uniform'}\n",
      "()\n",
      "0.764 (+/-0.007) for {'n_neighbors': 82, 'weights': 'distance'}\n",
      "()\n",
      "0.769 (+/-0.003) for {'n_neighbors': 83, 'weights': 'uniform'}\n",
      "()\n",
      "0.766 (+/-0.010) for {'n_neighbors': 83, 'weights': 'distance'}\n",
      "()\n",
      "0.769 (+/-0.003) for {'n_neighbors': 84, 'weights': 'uniform'}\n",
      "()\n",
      "0.769 (+/-0.007) for {'n_neighbors': 84, 'weights': 'distance'}\n",
      "()\n",
      "0.771 (+/-0.004) for {'n_neighbors': 85, 'weights': 'uniform'}\n",
      "()\n",
      "0.766 (+/-0.010) for {'n_neighbors': 85, 'weights': 'distance'}\n",
      "()\n",
      "0.771 (+/-0.003) for {'n_neighbors': 86, 'weights': 'uniform'}\n",
      "()\n",
      "0.766 (+/-0.008) for {'n_neighbors': 86, 'weights': 'distance'}\n",
      "()\n",
      "0.771 (+/-0.003) for {'n_neighbors': 87, 'weights': 'uniform'}\n",
      "()\n",
      "0.764 (+/-0.008) for {'n_neighbors': 87, 'weights': 'distance'}\n",
      "()\n",
      "0.771 (+/-0.003) for {'n_neighbors': 88, 'weights': 'uniform'}\n",
      "()\n",
      "0.768 (+/-0.010) for {'n_neighbors': 88, 'weights': 'distance'}\n",
      "()\n",
      "0.771 (+/-0.003) for {'n_neighbors': 89, 'weights': 'uniform'}\n",
      "()\n",
      "0.764 (+/-0.015) for {'n_neighbors': 89, 'weights': 'distance'}\n",
      "()\n",
      "0.771 (+/-0.003) for {'n_neighbors': 90, 'weights': 'uniform'}\n",
      "()\n",
      "0.768 (+/-0.011) for {'n_neighbors': 90, 'weights': 'distance'}\n",
      "()\n",
      "0.771 (+/-0.003) for {'n_neighbors': 91, 'weights': 'uniform'}\n",
      "()\n",
      "0.764 (+/-0.015) for {'n_neighbors': 91, 'weights': 'distance'}\n",
      "()\n",
      "0.771 (+/-0.003) for {'n_neighbors': 92, 'weights': 'uniform'}\n",
      "()\n",
      "0.768 (+/-0.011) for {'n_neighbors': 92, 'weights': 'distance'}\n",
      "()\n",
      "0.771 (+/-0.003) for {'n_neighbors': 93, 'weights': 'uniform'}\n",
      "()\n",
      "0.766 (+/-0.013) for {'n_neighbors': 93, 'weights': 'distance'}\n",
      "()\n",
      "0.771 (+/-0.003) for {'n_neighbors': 94, 'weights': 'uniform'}\n",
      "()\n",
      "0.766 (+/-0.009) for {'n_neighbors': 94, 'weights': 'distance'}\n",
      "()\n",
      "0.771 (+/-0.003) for {'n_neighbors': 95, 'weights': 'uniform'}\n",
      "()\n",
      "0.764 (+/-0.011) for {'n_neighbors': 95, 'weights': 'distance'}\n",
      "()\n",
      "0.771 (+/-0.003) for {'n_neighbors': 96, 'weights': 'uniform'}\n",
      "()\n",
      "0.764 (+/-0.011) for {'n_neighbors': 96, 'weights': 'distance'}\n",
      "()\n",
      "0.771 (+/-0.003) for {'n_neighbors': 97, 'weights': 'uniform'}\n",
      "()\n",
      "0.761 (+/-0.012) for {'n_neighbors': 97, 'weights': 'distance'}\n",
      "()\n",
      "0.771 (+/-0.003) for {'n_neighbors': 98, 'weights': 'uniform'}\n",
      "()\n",
      "0.764 (+/-0.011) for {'n_neighbors': 98, 'weights': 'distance'}\n",
      "()\n",
      "0.771 (+/-0.003) for {'n_neighbors': 99, 'weights': 'uniform'}\n",
      "()\n",
      "0.764 (+/-0.012) for {'n_neighbors': 99, 'weights': 'distance'}\n",
      "()\n",
      "Para los scores de test del CV [197, 197, 102, 195, 191, 194, 57, 193, 192, 196, 48, 184, 83, 190, 83, 184, 57, 171, 35, 118, 17, 151, 7, 118, 17, 151, 25, 151, 25, 159, 57, 118, 12, 102, 39, 118, 9, 102, 39, 83, 12, 102, 29, 83, 17, 134, 39, 83, 9, 102, 25, 57, 3, 102, 7, 83, 1, 48, 2, 83, 3, 39, 12, 83, 3, 48, 12, 102, 3, 57, 29, 118, 17, 134, 29, 118, 9, 102, 17, 134, 25, 118, 29, 118, 29, 102, 39, 134, 48, 159, 17, 151, 12, 151, 17, 151, 17, 134, 39, 151, 39, 118, 29, 134, 35, 151, 102, 159, 102, 134, 83, 159, 83, 134, 83, 171, 83, 159, 102, 159, 102, 159, 134, 159, 118, 171, 83, 188, 83, 184, 57, 188, 83, 184, 48, 171, 48, 171, 35, 181, 35, 181, 39, 171, 39, 181, 48, 159, 48, 159, 57, 171, 48, 171, 57, 159, 57, 171, 83, 171, 57, 118, 57, 134, 83, 118, 83, 83, 57, 118, 57, 118, 57, 134, 57, 102, 57, 134, 57, 102, 57, 134, 57, 102, 57, 118, 57, 118, 57, 134, 57, 134, 57, 159, 57, 134, 57, 134] el mejor ranking es 1 y pertenece al pliegue cuyo n_vecinos es 29 y su peso uniform\n",
      "0.770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moises/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "/home/moises/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "/home/moises/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAFdCAYAAABfMCThAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f51c8f4c1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAFdCAYAAABfMCThAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzf8HtfaDVlu2ylMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f51c8c5b490>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La estimacion de CV-5 era 0.770 y el resultado del test es 0.773\n"
     ]
    }
   ],
   "source": [
    "hyperParams = {'n_neighbors': range(1,100),\n",
    "               'weights': ['uniform', 'distance']}\n",
    "\n",
    "#Create an instance of Neighbors Classifier and fit the data for the grid parameters\n",
    "modelCV = GridSearchCV(neighbors.KNeighborsClassifier(), \n",
    "                     hyperParams, cv=5, scoring='accuracy')\n",
    "modelCV.fit(xTrain, yTrain)\n",
    "print \"Best hyperparameters Cross-Validation\", modelCV.best_params_\n",
    "neighList, errList, devList = [], [], []\n",
    "i = 0\n",
    "for hyperP, mean_score, scores in modelCV.grid_scores_:\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean_score, scores.std(), hyperP))\n",
    "    if hyperP['weights'] == modelCV.best_params_['weights']:\n",
    "        neighList.append(hyperP['n_neighbors'])\n",
    "        errList.append(mean_score)\n",
    "        devList.append(scores.std())\n",
    "    print()    \n",
    "\n",
    "#Ahora comprobamos con los demás resultados entre los que se haya el vector de ranking (scikit-learn v0.18.1)\n",
    "\n",
    "#print \"Resultados:\", modelCV.cv_results_\n",
    "oserList = list(modelCV.cv_results_['rank_test_score'])\n",
    "#Escogemos el que mejor ranking que normalmente será 1\n",
    "regla_un_error_estandar = min(oserList)\n",
    "#Nos quedamos con el primer índice que cumpla la regla\n",
    "indice = [i for i,x in enumerate(oserList) if x == regla_un_error_estandar][0] \n",
    "vecinos = modelCV.grid_scores_[indice][0]['n_neighbors']\n",
    "#print(vecinos)\n",
    "peso = modelCV.grid_scores_[indice][0]['weights']\n",
    "#print(peso)\n",
    "print(\"Para los scores de test del CV %r el mejor ranking es %i y pertenece al pliegue cuyo n_vecinos es %i y su peso %s\" \n",
    "      % (oserList, regla_un_error_estandar, vecinos, peso))\n",
    "#Según la teoría vista en clase (transparencias 23 y 25 del tema 1) debería de escoger el pliegue que \n",
    "#cumpla con la regla 'one-standar-error-rule'. Scikit-Learn ya nos facilita un vector con el ranking de los\n",
    "#mejores test scores.\n",
    "\n",
    "#Aplicamos la regla para quedarnos el mínimo t (esa será nuestra estimación del error de test del CV)\n",
    "estimacionCV = list(modelCV.cv_results_['mean_test_score'])[indice]-list(modelCV.cv_results_['std_test_score'])[indice]\n",
    "print(\"%0.3f\" % estimacionCV)\n",
    "\n",
    "#De entre todos los pliegues de la validación cruzada, elige como mejores hiperparámetros el pliegue\n",
    "#cuyo número de vecinos es 4 y su peso es uniforme con el score 0.771, y desviación estándar de +/- 0.031,\n",
    "#el cual como hemos podido ver es el que mejor ranking de test scores tiene.\n",
    "plt.errorbar(neighList, errList, yerr = devList)\n",
    "plt.xlim(neighList[0]-1, neighList[len(neighList)-1]+1)\n",
    "plt.ylim(errList[0]-0.1, errList[len(errList)-1]+0.1)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "model = neighbors.KNeighborsClassifier(n_neighbors = modelCV.best_params_['n_neighbors'], \n",
    "                                       weights = modelCV.best_params_['weights'])\n",
    "model.fit(xTrain, yTrain)\n",
    "precision_media = model.score(xTest,yTest)\n",
    "\n",
    "plt.errorbar(neighList, errList, yerr = devList)\n",
    "plt.xlim(neighList[0]-1, neighList[len(neighList)-1]+1)\n",
    "plt.ylim(errList[0]-0.1, errList[len(errList)-1]+0.1)\n",
    "plt.plot(modelCV.best_params_['n_neighbors'], precision_media, 'ro')\n",
    "plt.show()\n",
    "print(\"La estimacion de CV-5 era %0.3f y el resultado del test es %0.3f\" % (estimacionCV, precision_media))\n",
    "#Podemos observar que la estimación de la Validación Cruzada de 5 pliegues ha sido realmente buena \n",
    "#ya que acierta de pleno, aparte de estar dentro del rango (0.740,0.802)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apartado a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('N. de vecinos ', 29, ' y N. de Variables ', 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[2017-06-08 05:00:31] Features: 1/4 -- score: 0.770917887816\n",
      "[2017-06-08 05:00:31] Features: 1/4 -- score: 0.770917887816\n",
      "[2017-06-08 05:00:32] Features: 1/4 -- score: 0.770917887816\n",
      "[2017-06-08 05:00:32] Features: 2/4 -- score: 0.770917887816\n",
      "[2017-06-08 05:00:32] Features: 3/4 -- score: 0.767528532074\n",
      "[2017-06-08 05:00:32] Features: 4/4 -- score: 0.794266847235"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.771 (+/-0.003) para 1 variables seleccionadas en (0,)\n",
      "0.771 (+/-0.003) para 2 variables seleccionadas en (1, 2)\n",
      "0.768 (+/-0.012) para 3 variables seleccionadas en (1, 2, 3)\n",
      "0.794 (+/-0.024) para 4 variables seleccionadas en (0, 1, 2, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiIAAAFdCAYAAAA+KAajAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f51c8f72dd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "\n",
    "#Tal y como nos pide el ejercicio escogemos el mejor parámetro de número de vecinos del ejercicio 2\n",
    "vecinos = modelCV.best_params_['n_neighbors'] \n",
    "variables = 4\n",
    "#Cuatro variables de entrada numéricas -> Recency (months),Frequency (times), Monetary (c.c. blood), y Time (months)\n",
    "print(\"N. de vecinos \", vecinos, \" y N. de Variables \", variables)\n",
    "\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=vecinos)\n",
    "\n",
    "sfs1 = SFS(knn, \n",
    "           k_features=variables, \n",
    "           forward=True, \n",
    "           floating=True, \n",
    "           verbose=2,\n",
    "           scoring='accuracy',\n",
    "           cv=5)\n",
    "\n",
    "sfs1 = sfs1.fit(xTrain, yTrain)\n",
    "diccionario_metricas = sfs1.get_metric_dict(confidence_interval=0.95)\n",
    "varList, errList, devList = [], [], []\n",
    "for i in range(1,len(diccionario_metricas)+1):\n",
    "    puntuacion_media = diccionario_metricas[i]['avg_score']\n",
    "    desviacion_estandar = diccionario_metricas[i]['std_dev']\n",
    "    num_variables_usadas = len(diccionario_metricas[i]['feature_idx'])\n",
    "    print(\"%0.3f (+/-%0.03f) para %i variables seleccionadas en %r\"\n",
    "              % (puntuacion_media, desviacion_estandar, num_variables_usadas, diccionario_metricas[i]['feature_idx']))\n",
    "    varList.append(num_variables_usadas)\n",
    "    errList.append(puntuacion_media)\n",
    "    devList.append(desviacion_estandar)\n",
    "    #marcamos el error de test del ejercicio 2 en este paso (Así aprovechamos la misma figura de plot)\n",
    "    plt.plot(num_variables_usadas, precision_media, 'ro')\n",
    "    plt.text(num_variables_usadas, precision_media, str(precision_media))\n",
    "#El paso que cumple la regla 'one-standar-error-rule' es el de 4 variables, porque coincide con lo visto en el\n",
    "#ejercicio anterior al respecto.\n",
    "plt.errorbar(varList, errList, yerr = devList)\n",
    "plt.xlim(varList[0]-1, varList[len(varList)-1]+1)\n",
    "plt.ylim(errList[0]-0.1, errList[len(errList)-1]+0.1)\n",
    "plt.show()\n",
    "#Podemos observar que efectivamente para 4 variables seleccionadas, tanto la estimación como la desviación estándar \n",
    "#son exctamente las mismas que en la Validación Cruzada de 5 pliegues del ejercicio anterior que nos daba como\n",
    "#mejor pliegue el de 4 Vecinos y peso Uniforme del ejercicio y que finalmente fue elegida como la mejor estimación \n",
    "#del error. Es decir, score 0.771 y desviación +/- 0.031 que con la regla del mínimo t sería 0.740.\n",
    "\n",
    "#NOTA: Al poner como marcadores la estimación del error del test hecho en el ejercicio anterior no hace falta \n",
    "#'plottear' de nuevo una nueva figura, en la misma figura se puede hacer la comparativa. Podemos ver que el punto\n",
    "#está exactamente en el 0.740 estimado.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apartado b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[2017-06-08 06:53:58] Features: 1/4 -- score: 0.770917887816\n",
      "[2017-06-08 06:53:58] Features: 2/4 -- score: 0.759195661736\n",
      "[2017-06-08 06:53:58] Features: 3/4 -- score: 0.777585480473\n",
      "[2017-06-08 06:53:58] Features: 4/4 -- score: 0.794266847235"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('La ultima clave es ', 4, ' y ?hay solo un paso? ', False)\n",
      "0.794 (+/-0.024) para 4 variables seleccionadas en (0, 1, 2, 3)\n",
      "0.778 (+/-0.024) para 3 variables seleccionadas en (0, 1, 3)\n",
      "0.759 (+/-0.029) para 2 variables seleccionadas en (0, 3)\n",
      "0.771 (+/-0.003) para 1 variables seleccionadas en (0,)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABf0AAAFdCAYAAAC5CcfkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nADpC6A8AAAAAAB0h9AcAAAAAgI74fwd76C3xDxRbAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f51c8eeed90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mlxtend.feature_selection import SequentialFeatureSelector as SBS\n",
    "\n",
    "sbs = SBS(knn, \n",
    "           k_features=variables, \n",
    "           forward=True,   \n",
    "           floating=False, \n",
    "           verbose=2,\n",
    "           scoring='accuracy',\n",
    "           cv=5)\n",
    "\n",
    "sbs = sbs.fit(xTrain, yTrain)\n",
    "diccionario_metricas = sbs.get_metric_dict(confidence_interval=0.95)\n",
    "\n",
    "claves = diccionario_metricas.keys()\n",
    "un_solo_paso = False\n",
    "if(len(claves)==1):\n",
    "    ultima_clave = claves[0]\n",
    "    un_solo_paso = True\n",
    "else:\n",
    "    ultima_clave = claves[len(claves)-1]\n",
    "print(\"La ultima clave es \", ultima_clave, \" y ?hay solo un paso? \", un_solo_paso)\n",
    "\n",
    "varList, errList, devList = [], [], []\n",
    "#Ahora vamos hacia atrás, pero como ya sabemos de antemano que ya se va a quedar con el de 4 variables como la \n",
    "#mejor estimación, el algoritmo ya se paró en el primer paso, por lo que sólo tenemos un paso y con el fin \n",
    "#de evitar el error 'KeyError' se hace un control de excepciones\n",
    "for i in range(ultima_clave,0,-1):\n",
    "    try:\n",
    "        puntuacion_media = diccionario_metricas[i]['avg_score']\n",
    "        desviacion_estandar = diccionario_metricas[i]['std_dev']\n",
    "        num_variables_usadas = len(diccionario_metricas[i]['feature_idx'])\n",
    "        print(\"%0.3f (+/-%0.03f) para %i variables seleccionadas en %r\"\n",
    "                  % (puntuacion_media, desviacion_estandar, num_variables_usadas, diccionario_metricas[i]['feature_idx']))\n",
    "        varList.append(num_variables_usadas)\n",
    "        errList.append(puntuacion_media)\n",
    "        devList.append(desviacion_estandar)\n",
    "        #marcamos el error de test del ejercicio 2 en este paso (Así aprovechamos la misma figura de plot)\n",
    "        plt.plot(num_variables_usadas, precision_media, 'ro')\n",
    "        plt.text(num_variables_usadas, precision_media, str(precision_media))\n",
    "    except KeyError:\n",
    "        print(\"No hay paso \", i, \" en la seleccion hacia atras porque el algoritmo de seleccion ya habia parado.\")\n",
    "plt.errorbar(varList, errList, yerr = devList)\n",
    "plt.xlim(varList[0]-1, varList[len(varList)-1]+1)\n",
    "plt.ylim(errList[0]-0.1, errList[len(errList)-1]+0.1)\n",
    "plt.show()\n",
    "#Lo primero que podemos apreciar es que efectivamente el algoritmo de selección hacia atrás ya toma como mejor\n",
    "#estimación la de 4 variables, para y ya no sigue, porque no tiene sentido de que lo haga, ya que tanto la \n",
    "#estimación como la desviación estándar son exctamente las mismas que las del Apartado a) de este ejercicio\n",
    "#y, además, las mimas que en la Validación Cruzada de 5 pliegues del ejercicio anterior que nos daba como\n",
    "#mejor pliegue el de 4 Vecinos y peso Uniforme, y que finalmente fue elegida como la mejor estimación \n",
    "#del error con t mínimo de 0.740. Es decir, score 0.771 y desviación +/- 0.031. Y cómo ya sabíamos que \n",
    "#éste era el modelo seleccionado porque era el que cumplía con la regla 'one-standard-error-rule', \n",
    "#podemos concluir que la estimación nuevamente ha sido muy buena, ya que acierta.\n",
    "\n",
    "#Cabe reseñar que al ir hacia atrás sólo ha habido un paso. Como ya sabemos scikit-learn internamente hace un\n",
    "#rank para cada combinación, si el rank que tiene ésta ya es 1, es que ya el mejor rank de todos, de modo que\n",
    "#ya no hace falta que siga ejecutándose el algoritmo de selección.\n",
    "\n",
    "#NOTA: Al poner como marcador la estimción del error del test hecho en el ejercicio anterior no hace falta \n",
    "#'plottear' de nuevo una nueva figura, en la misma figura se puede hacer la comparativa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apartado a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ocho variables de entrada numéricas -> X1,X2,X3,X4,X5,X6,X7,X8\n",
    "- Una de salida de valor real -> Y2\n",
    "- Hay 768 instancias.\n",
    "- No hay clases ya que es un problema de regresión y NO de clasificación.\n",
    "- Se eliminan como valores perdidos los NaN (Not a Number), ya que las variables tienen que contener números válidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n",
      "xRaw, y [[  9.80000000e-01   5.14500000e+02   2.94000000e+02 ...,   2.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  9.80000000e-01   5.14500000e+02   2.94000000e+02 ...,   3.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  9.80000000e-01   5.14500000e+02   2.94000000e+02 ...,   4.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " ..., \n",
      " [  6.20000000e-01   8.08500000e+02   3.67500000e+02 ...,   3.00000000e+00\n",
      "    4.00000000e-01   5.00000000e+00]\n",
      " [  6.20000000e-01   8.08500000e+02   3.67500000e+02 ...,   4.00000000e+00\n",
      "    4.00000000e-01   5.00000000e+00]\n",
      " [  6.20000000e-01   8.08500000e+02   3.67500000e+02 ...,   5.00000000e+00\n",
      "    4.00000000e-01   5.00000000e+00]] [ 21.33  21.33  21.33  21.33  28.28  25.38  25.16  29.6   27.3   21.97\n",
      "  23.49  27.87  23.77  21.46  21.16  24.93  37.73  31.27  30.93  39.44\n",
      "  29.79  29.68  29.79  29.4   10.9   11.19  10.94  11.17  11.27  11.72\n",
      "  11.29  11.67  11.74  12.05  11.73  11.93  12.4   12.23  12.4   12.14\n",
      "  16.78  16.8   16.75  16.67  12.07  12.22  12.08  12.04  26.47  26.37\n",
      "  26.44  26.29  32.92  29.87  29.58  34.33  30.89  25.6   27.03  31.73\n",
      "  27.31  24.91  24.61  28.51  41.68  35.28  34.43  43.33  33.87  34.07\n",
      "  34.14  33.67  13.43  13.71  13.48  13.7   13.8   14.28  13.87  14.27\n",
      "  14.28  14.61  14.3   14.45  13.9   13.72  13.88  13.65  19.37  19.43\n",
      "  19.34  19.32  14.34  14.5   14.33  14.27  25.95  25.63  26.13  25.89\n",
      "  32.54  29.44  29.36  34.2   30.91  25.63  27.36  31.9   27.38  25.02\n",
      "  24.8   28.79  41.07  34.62  33.87  42.86  33.91  34.07  34.17  33.78\n",
      "  13.39  13.72  13.57  13.79  13.67  14.11  13.8   14.21  13.2   13.54\n",
      "  13.32  13.51  14.86  14.75  15.    14.74  19.23  19.34  19.32  19.3\n",
      "  14.37  14.57  14.27  14.24  25.68  26.02  25.84  26.14  34.14  32.85\n",
      "  30.08  29.67  31.73  31.01  25.9   27.4   28.68  27.54  25.35  24.93\n",
      "  43.12  41.22  35.1   34.29  33.85  34.11  34.48  34.5   13.6   13.36\n",
      "  13.65  13.49  14.14  13.77  14.3   13.87  14.44  14.27  14.67  14.4\n",
      "  13.46  13.7   13.59  13.83  19.14  19.18  19.37  19.29  14.09  14.23\n",
      "  14.14  13.89  25.91  25.72  26.18  25.87  29.34  33.91  32.83  29.92\n",
      "  27.17  31.76  31.06  25.81  24.61  28.61  27.57  25.16  34.25  43.3\n",
      "  41.86  35.29  34.11  33.62  33.89  34.05  13.2   13.36  13.21  13.53\n",
      "  13.67  14.12  13.79  14.2   14.29  14.49  14.42  14.73  14.86  14.67  15.\n",
      "  14.83  19.24  19.25  19.42  19.48  14.37  14.34  14.28  14.47  25.64\n",
      "  25.98  25.88  26.18  29.82  29.52  34.45  33.01  25.82  27.33  32.04\n",
      "  31.28  25.11  24.77  28.88  27.69  34.99  34.18  43.14  41.26  34.25\n",
      "  34.35  33.64  33.88  13.65  13.44  13.72  13.5   14.18  13.75  14.26\n",
      "  13.89  14.55  14.28  14.46  14.39  14.54  14.81  14.65  14.87  19.24\n",
      "  19.18  19.26  19.29  14.24  13.97  13.99  14.15  29.79  29.79  29.28\n",
      "  29.49  36.12  33.17  32.71  37.58  33.98  28.61  30.12  34.73  30.17\n",
      "  27.84  27.25  31.39  43.8   37.81  36.85  45.52  36.85  37.58  37.45\n",
      "  36.62  15.19  15.5   15.28  15.5   15.42  15.85  15.44  15.81  15.21\n",
      "  15.63  15.48  15.78  16.39  16.27  16.39  16.19  21.13  21.19  21.09\n",
      "  21.08  15.77  15.95  15.77  15.76  29.62  29.69  30.18  30.02  35.56\n",
      "  32.64  32.77  37.72  33.37  27.89  29.9   34.52  28.27  26.96  26.72\n",
      "  29.88  43.86  37.41  36.77  45.97  36.87  37.35  37.28  36.81  14.73\n",
      "  15.1   15.18  15.44  14.91  15.4   14.94  15.32  15.52  15.85  15.66\n",
      "  15.99  15.89  15.85  16.22  15.87  20.47  20.56  20.48  20.43  15.32\n",
      "  15.64  15.14  15.3   29.43  29.78  30.1   30.19  36.35  35.1   32.83\n",
      "  32.46  33.52  32.93  28.38  29.82  28.77  27.76  26.95  26.41  45.13\n",
      "  43.66  37.76  36.87  36.07  36.44  37.28  37.29  14.49  13.79  14.72\n",
      "  14.76  14.92  14.74  15.57  14.94  14.92  14.38  15.44  15.17  15.53\n",
      "  15.8   16.14  16.26  19.87  20.03  20.46  20.28  14.89  14.96  14.89\n",
      "  14.35  29.61  29.59  30.19  30.12  32.12  37.12  36.16  33.16  29.45\n",
      "  34.19  33.93  28.31  26.3   29.43  28.76  27.34  36.26  45.48  44.16\n",
      "  37.26  37.2   36.76  37.05  37.51  14.92  15.24  15.03  15.35  14.67\n",
      "  15.09  15.2   15.64  15.37  15.73  15.83  16.13  15.95  15.59  16.17\n",
      "  16.14  19.65  19.76  20.37  19.9   15.41  15.56  15.07  15.38  29.53\n",
      "  29.77  30.    30.2   32.25  32.    37.19  35.62  28.02  29.43  34.15\n",
      "  33.47  26.53  26.08  29.31  28.14  37.54  36.66  45.28  43.73  36.93\n",
      "  37.01  35.73  36.15  14.48  14.58  14.81  14.03  15.27  14.71  15.23\n",
      "  14.97  15.14  14.97  15.22  14.6   15.83  16.03  15.8   16.06  20.13\n",
      "  20.01  20.19  20.29  15.19  14.61  14.61  14.75  33.37  33.34  32.83\n",
      "  33.04  39.28  36.38  35.92  40.99  35.99  30.66  31.7   36.73  31.71\n",
      "  29.13  28.99  33.54  45.29  39.07  38.35  46.94  39.55  40.85  40.63\n",
      "  39.48  16.94  17.25  17.03  17.25  17.1   17.51  17.12  17.47  16.5   17.\n",
      "  16.87  17.2   18.14  18.03  18.14  17.95  22.72  22.73  22.72  22.53\n",
      "  17.2   17.21  17.15  17.2   32.96  33.13  33.94  33.78  38.35  35.39\n",
      "  34.94  40.66  35.48  30.53  32.28  36.86  30.34  27.93  28.95  32.92\n",
      "  45.59  39.41  38.84  48.03  39.48  40.4   40.47  39.7   16.43  16.93\n",
      "  16.99  17.03  16.77  17.37  17.27  17.51  16.44  17.01  17.23  17.22\n",
      "  17.85  17.89  18.36  18.15  21.72  22.07  22.09  21.93  17.36  17.38\n",
      "  16.86  16.99  32.78  33.24  33.86  34.    37.26  35.04  33.82  33.31\n",
      "  35.22  34.7   30.11  31.6   32.43  30.65  29.77  29.64  46.44  44.18\n",
      "  38.81  38.23  38.17  38.48  39.66  40.1   16.08  15.39  16.57  16.6\n",
      "  16.11  15.47  16.7   16.1   16.35  15.84  16.99  17.02  17.04  17.63\n",
      "  18.1   18.22  20.78  20.72  21.54  21.53  16.9   17.14  16.56  16.    32.95\n",
      "  33.06  33.95  33.88  33.98  39.92  39.22  36.1   31.53  36.2   36.21  31.\n",
      "  28.2   32.35  31.14  28.43  38.33  47.59  46.23  39.56  40.36  39.67\n",
      "  39.85  40.77  16.61  16.74  16.9   17.32  16.85  17.2   17.23  17.74\n",
      "  16.81  16.88  16.9   17.39  17.86  17.82  18.36  18.24  21.68  21.54\n",
      "  22.25  22.49  17.1   16.79  16.58  16.79  32.88  33.23  33.76  34.01\n",
      "  33.94  33.14  38.79  37.27  29.69  31.2   36.26  35.71  29.93  29.56\n",
      "  33.84  32.54  38.56  37.7   47.01  44.87  39.37  39.8   37.79  38.18\n",
      "  16.69  16.62  16.94  16.7   15.59  14.58  15.33  15.31  16.63  15.87\n",
      "  16.54  16.74  17.64  17.79  17.55  18.06  20.82  20.21  20.71  21.4\n",
      "  16.88  17.11  16.61  16.03]\n",
      "mean, std [  7.64166667e-01   6.71708333e+02   3.18500000e+02   1.76604167e+02\n",
      "   5.25000000e+00   3.50000000e+00   2.34375000e-01   2.81250000e+00] [  0.10570859  88.02874964  43.59806953  45.13653573   1.75         1.11803399\n",
      "   0.1331338    1.5499496 ]\n",
      "Eliminate missing values: mean, std [  7.64166667e-01   6.71708333e+02   3.18500000e+02   1.76604167e+02\n",
      "   5.25000000e+00   3.50000000e+00   2.34375000e-01   2.81250000e+00] [  0.10570859  88.02874964  43.59806953  45.13653573   1.75         1.11803399\n",
      "   0.1331338    1.5499496 ]\n",
      "Data after x standardizing [[ 2.04177671 -1.78587489 -0.56195149 ..., -1.34164079 -1.76044698\n",
      "  -1.81457514]\n",
      " [ 2.04177671 -1.78587489 -0.56195149 ..., -0.4472136  -1.76044698\n",
      "  -1.81457514]\n",
      " [ 2.04177671 -1.78587489 -0.56195149 ...,  0.4472136  -1.76044698\n",
      "  -1.81457514]\n",
      " ..., \n",
      " [-1.36381225  1.55394308  1.12390297 ..., -0.4472136   1.2440492\n",
      "   1.41133622]\n",
      " [-1.36381225  1.55394308  1.12390297 ...,  0.4472136   1.2440492\n",
      "   1.41133622]\n",
      " [-1.36381225  1.55394308  1.12390297 ...,  1.34164079  1.2440492\n",
      "   1.41133622]]\n",
      "mean, std [  7.64166667e-01   6.71708333e+02   3.18500000e+02   1.76604167e+02\n",
      "   5.25000000e+00   3.50000000e+00   2.34375000e-01   2.81250000e+00] [  0.10570859  88.02874964  43.59806953  45.13653573   1.75         1.11803399\n",
      "   0.1331338    1.5499496 ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing, cross_validation, neighbors\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.externals import joblib\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "datasetName = 'EnergyEfficiency.data'\n",
    "datasetDelimiter = ','\n",
    "\n",
    "# load the CSV file as a numpy matrix\n",
    "dataset = np.loadtxt(datasetName, delimiter=datasetDelimiter, skiprows=1) #Nos saltamos la cabecera\n",
    "print dataset.shape\n",
    "# separate the data from the target attributes\n",
    "xRaw = dataset[:,0:dataset.shape[1]-1]\n",
    "y = dataset[:,dataset.shape[1]-1]\n",
    "print \"xRaw, y\", xRaw, y\n",
    "print \"mean, std\", xRaw.mean(axis=0), xRaw.std(axis=0)\n",
    "# missing values\n",
    "imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "xPrep = imp.fit_transform(xRaw)\n",
    "print \"Eliminate missing values: mean, std\", xPrep.mean(axis=0), xPrep.std(axis=0)\n",
    "#Standardize data\n",
    "scaler = preprocessing.StandardScaler().fit(xPrep)\n",
    "x=scaler.transform(xPrep)\n",
    "print \"Data after x standardizing\", x\n",
    "print \"mean, std\", scaler.mean_, scaler.scale_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apartado b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la página web de la documentación oficial de Scikit-Learn para esta clase http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html podemos ver\n",
    "\n",
    "- Parámetros\n",
    "\n",
    "n_neighbors : int, optional (default = 5)\n",
    "\n",
    "    Number of neighbors to use by default for k_neighbors queries.\n",
    "\n",
    "weights : str or callable\n",
    "\n",
    "    weight function used in prediction. Possible values:\n",
    "\n",
    "        ‘uniform’ : uniform weights. All points in each neighborhood are weighted equally.\n",
    "        ‘distance’ : weight points by the inverse of their distance. in this case, closer neighbors of a query point will have a greater influence than neighbors which are further away.\n",
    "        [callable] : a user-defined function which accepts an array of distances, and returns an array of the same shape containing the weights.\n",
    "\n",
    "    Uniform weights are used by default.\n",
    "\n",
    "algorithm : {‘auto’, ‘ball_tree’, ‘kd_tree’, ‘brute’}, optional\n",
    "\n",
    "    Algorithm used to compute the nearest neighbors:\n",
    "\n",
    "        ‘ball_tree’ will use BallTree\n",
    "        ‘kd_tree’ will use KDtree\n",
    "        ‘brute’ will use a brute-force search.\n",
    "        ‘auto’ will attempt to decide the most appropriate algorithm based on the values passed to fit method.\n",
    "\n",
    "    Note: fitting on sparse input will override the setting of this parameter, using brute force.\n",
    "\n",
    "leaf_size : int, optional (default = 30)\n",
    "\n",
    "    Leaf size passed to BallTree or KDTree. This can affect the speed of the construction and query, as well as the memory required to store the tree. The optimal value depends on the nature of the problem.\n",
    "\n",
    "metric : string or DistanceMetric object (default=’minkowski’)\n",
    "\n",
    "    the distance metric to use for the tree. The default metric is minkowski, and with p=2 is equivalent to the standard Euclidean metric. See the documentation of the DistanceMetric class for a list of available metrics.\n",
    "\n",
    "p : integer, optional (default = 2)\n",
    "\n",
    "    Power parameter for the Minkowski metric. When p = 1, this is equivalent to using manhattan_distance (l1), and euclidean_distance (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.\n",
    "\n",
    "metric_params : dict, optional (default = None)\n",
    "\n",
    "    Additional keyword arguments for the metric function.\n",
    "\n",
    "n_jobs : int, optional (default = 1)\n",
    "\n",
    "    The number of parallel jobs to run for neighbors search. If -1, then the number of jobs is set to the number of CPU cores. Doesn’t affect fit method.\n",
    "\n",
    "\n",
    "- Métodos\n",
    "\n",
    "    - fit(X, y) \tFit the model using X as training data and y as target values\n",
    "    - get_params([deep]) \tGet parameters for this estimator.\n",
    "    - kneighbors([X, n_neighbors, return_distance]) \tFinds the K-neighbors of a point.\n",
    "    - kneighbors_graph([X, n_neighbors, mode]) \tComputes the (weighted) graph of k-Neighbors for points in X\n",
    "    - predict(X) \tPredict the target for the provided data\n",
    "    - score(X, y[, sample_weight]) \tReturns the coefficient of determination R^2 of the prediction.\n",
    "    - set_params(\\*\\*params) \tSet the parameters of this estimator.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apartado c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xTrain [[-0.22861593  0.16235226 -1.68585446 ...,  1.34164079  1.2440492\n",
      "  -0.5242106 ]\n",
      " [-0.03941654 -0.1159659   2.24780595 ...,  0.4472136  -1.00932293\n",
      "  -0.5242106 ]\n",
      " [ 1.28497917 -1.22923856  0.         ...,  1.34164079 -1.00932293\n",
      "   1.41133622]\n",
      " ..., \n",
      " [ 1.28497917 -1.22923856  0.         ..., -0.4472136   1.2440492\n",
      "   0.12097168]\n",
      " [-0.51241501  0.44067043 -1.12390297 ...,  1.34164079  1.2440492\n",
      "  -1.16939287]\n",
      " [ 0.52818162 -0.67260223  0.         ..., -1.34164079  1.2440492\n",
      "   0.76615395]] \n",
      "xTest [[-0.98541347  0.99730676  0.         ..., -0.4472136   1.2440492\n",
      "   0.12097168]\n",
      " [-0.22861593  0.16235226 -1.68585446 ...,  0.4472136  -1.00932293\n",
      "  -0.5242106 ]\n",
      " [ 0.24438254 -0.39428407  0.56195149 ..., -0.4472136  -1.00932293\n",
      "  -0.5242106 ]\n",
      " ..., \n",
      " [-0.98541347  0.99730676  0.         ...,  0.4472136  -1.00932293\n",
      "   0.76615395]\n",
      " [-1.36381225  1.55394308  1.12390297 ...,  1.34164079  0.11736313\n",
      "   1.41133622]\n",
      " [-1.36381225  1.55394308  1.12390297 ..., -1.34164079  0.11736313\n",
      "  -0.5242106 ]] \n",
      "yTrain [ 17.03  34.17  33.01  27.54  15.95  25.72  36.85  15.81  25.63  32.83\n",
      "  16.19  21.93  15.8   35.22  15.19  35.99  40.4   15.2   31.27  44.87\n",
      "  33.88  25.98  33.37  27.25  16.81  25.64  13.65  39.56  34.15  12.22\n",
      "  15.33  24.61  13.87  14.94  27.84  15.14  14.37  15.64  20.71  14.21\n",
      "  18.14  15.87  18.22  25.68  14.18  29.68  17.01  14.97  11.93  19.76\n",
      "  27.69  35.92  14.28  18.14  15.19  15.73  25.02  17.25  34.73  29.44\n",
      "  15.5   14.34  26.18  27.76  32.71  14.48  45.13  15.32  16.74  14.83\n",
      "  35.29  32.12  34.11  14.09  15.77  17.55  11.73  38.35  15.44  16.88\n",
      "  15.44  17.79  32.43  27.4   32.83  20.21  37.28  40.99  27.17  34.43\n",
      "  17.95  31.71  33.24  23.77  41.22  18.36  33.04  21.54  25.11  33.17\n",
      "  17.89  24.93  18.24  16.62  27.34  14.67  36.38  30.53  16.13  16.85\n",
      "  28.95  31.53  24.93  29.52  29.69  25.16  20.19  20.13  30.91  36.76\n",
      "  37.76  17.2   19.34  39.22  43.66  14.58  13.21  16.61  16.11  28.61\n",
      "  35.1   14.14  29.31  30.2   26.18  32.25  14.86  19.25  13.77  14.67\n",
      "  39.8   33.78  27.57  34.19  25.95  15.84  15.95  14.58  19.43  37.29\n",
      "  14.4   21.33  12.08  13.49  36.26  29.61  31.9   14.75  17.38  14.2\n",
      "  15.56  29.36  27.38  33.62  29.43  36.87  34.45  15.07  15.83  14.11\n",
      "  37.05  40.85  14.92  17.36  14.29  10.94  14.73  18.36  38.18  29.9\n",
      "  21.33  15.    16.27  30.19  19.37  26.53  37.58  44.18  14.89  16.77\n",
      "  47.59  14.49  37.26  21.09  20.03  15.77  15.85  40.77  20.01  35.71\n",
      "  36.66  15.83  32.    33.52  32.96  41.07  15.59  33.06  29.79  35.28\n",
      "  30.12  13.8   41.26  22.73  16.63  30.02  38.81  19.34  37.01  29.6\n",
      "  32.77  17.23  37.58  30.65  39.28  19.18  20.29  37.41  14.67  31.01\n",
      "  29.58  11.29  19.87  36.21  32.54  36.1   33.31  33.94  14.34  20.72\n",
      "  30.89  27.31  35.73  33.64  30.12  13.65  21.68  15.03  34.25  32.46\n",
      "  14.81  45.48  34.5   12.4   31.6   31.14  34.    30.17  33.76  28.14\n",
      "  16.57  34.29  13.67  25.9   29.62  31.73  26.08  43.8   17.1   16.93\n",
      "  37.72  45.59  36.62  20.28  20.37  25.35  26.29  22.49  16.03  16.03\n",
      "  15.1   15.24  16.99  13.53  18.15  36.85  13.48  19.26  17.    28.27\n",
      "  16.06  28.28  21.72  37.12  39.48  35.62  33.95  25.38  14.57  17.12\n",
      "  14.74  33.82  20.48  32.35  29.79  40.36  14.54  14.24  14.26  20.46\n",
      "  29.93  19.18  15.53  13.67  39.67  15.21  33.16  15.89  13.39  14.61\n",
      "  15.31  21.46  29.77  37.51  37.79  33.84  43.12  16.7   14.28  20.43\n",
      "  14.97  31.7   29.45  39.07  22.53  25.87  13.89  33.91  35.48  17.11\n",
      "  33.85  27.36  37.73  28.51  16.17  29.43  17.86  25.63  28.99  33.47\n",
      "  16.79  21.19  19.9   29.53  45.28  27.89  16.9   36.44  22.72  14.5\n",
      "  29.59  14.45  40.1   16.35  15.57  16.61  17.51  17.32  15.48  37.35\n",
      "  34.07  15.22  14.71  35.56  14.12  21.54  25.84  29.79  11.72  33.87\n",
      "  15.27  22.09  14.44  13.6   34.52  20.47  36.2   17.14  16.7   36.86\n",
      "  14.23  19.23  28.76  38.17  28.88  33.98  29.28  33.23  15.39  19.24\n",
      "  12.05  19.37  12.07  32.64  24.91  29.56  29.92  14.96  17.21  28.38\n",
      "  28.61  13.71  32.93  46.94  29.13  16.1   46.23  38.48  13.36  36.73\n",
      "  30.11  15.8   19.32  34.11  39.66  38.23  20.78  17.74  19.42  43.33\n",
      "  10.9   15.64  13.2   13.54  26.96  28.79  34.48  25.16  36.16  16.94\n",
      "  14.46  16.6   32.92  17.85  14.61  14.15  15.59  16.39  13.72  14.03\n",
      "  14.86  48.03  29.43  34.07  15.37  11.19  24.8   32.85  31.73  33.37\n",
      "  15.09  40.47  19.3   34.25  15.78  38.33  25.82  44.16  14.72  17.51\n",
      "  39.44  21.13  33.98  13.75  14.42  14.33  14.6   19.24  13.99  27.93\n",
      "  38.79  26.3   19.14  15.99  16.56  16.94  14.39  16.79  13.59  11.74\n",
      "  14.28  45.52  27.87  16.67  13.88  12.4   27.03  16.8   14.76  16.87\n",
      "  43.3   34.14  38.84  13.79  17.15  26.13  20.56  13.32  29.4   21.53\n",
      "  17.25  15.66  15.14  15.3   31.76  15.52  17.03  17.23  30.19  36.12\n",
      "  34.99  17.27  33.91  14.27  47.01  18.06  13.36  35.39  37.81  16.5\n",
      "  15.85  14.73  17.04  14.24  13.46  13.51  31.2   12.04  16.39  25.81\n",
      "  13.9   34.7   18.03  17.22  26.95  19.32  14.3   14.89  33.78  29.49\n",
      "  25.6   15.63  34.18  37.27  33.93  16.75  22.07  36.35  15.76  14.28\n",
      "  28.02  40.63  29.87  16.58  13.2   11.27  13.83  15.35  15.23  33.88\n",
      "  29.67  29.82  22.25  33.54  45.29  29.64  16.74  13.44  29.79  16.26\n",
      "  26.14  17.02  14.27  25.89  36.26  14.35  17.82  42.86  13.43  30.66\n",
      "  39.92  15.87  14.3   13.65  39.48  37.19  16.88  15.28  28.77  16.43\n",
      "  19.65  34.14  39.7   16.54  14.81  34.01  21.97  36.81  17.39  21.4\n",
      "  25.91  35.04  17.47  28.2 ] \n",
      "yTest [ 17.63  13.57  34.62  21.16  33.34  34.2   30.18  30.34  29.82  24.61\n",
      "  11.67  38.35  14.65  39.41  37.7   31.06  13.87  34.33  15.38  15.4\n",
      "  14.38  33.13  14.14  43.86  11.17  17.37  14.47  16.69  14.27  37.54\n",
      "  13.97  16.14  46.44  16.22  29.78  36.07  16.08  36.93  17.2   16.78\n",
      "  13.7   36.77  17.2   26.41  27.3   26.02  13.89  15.17  32.83  31.    33.94\n",
      "  14.27  34.05  17.64  37.2   13.7   21.33  31.39  37.26  16.9   18.1\n",
      "  14.91  33.86  13.72  15.85  14.49  45.97  14.55  32.04  36.87  32.78\n",
      "  13.79  24.77  16.86  19.48  29.88  32.95  43.73  32.88  17.1   40.66\n",
      "  30.08  13.72  14.61  32.54  26.72  25.88  30.93  14.37  16.99  16.99\n",
      "  31.28  15.5   26.44  39.55  17.2   29.77  16.44  12.14  37.28  35.1\n",
      "  28.68  23.49  33.87  13.5   28.31  38.56  16.14  15.42  21.33  20.82\n",
      "  33.89  32.28  19.29  14.94  19.29  14.87  43.14  27.33  39.37  33.14\n",
      "  15.18  15.44  34.94  14.74  39.85  16.9   30.1   14.92  29.69  33.67\n",
      "  26.37  41.86  13.79  36.15  12.23  28.43  26.47  34.35  15.47  21.08\n",
      "  22.72  29.34  13.8   41.68  16.    32.92  37.45  14.92  15.41  30.    15.\n",
      "  14.75  15.32]\n"
     ]
    }
   ],
   "source": [
    "#Divide in training and test, shuffling the examples and keeping the proportion of examples of each class\n",
    "xTrain, xTest, yTrain, yTest = cross_validation.train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "print 'xTrain', xTrain, \"\\nxTest\", xTest, \"\\nyTrain\", yTrain, \"\\nyTest\", yTest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apartado d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters Cross-Validation {'n_neighbors': 3, 'weights': 'uniform'}\n",
      "0.8992 (+/-0.0352) for {'n_neighbors': 1, 'weights': 'uniform'}\n",
      "()\n",
      "0.8992 (+/-0.0352) for {'n_neighbors': 1, 'weights': 'distance'}\n",
      "()\n",
      "0.9171 (+/-0.0134) for {'n_neighbors': 2, 'weights': 'uniform'}\n",
      "()\n",
      "0.9171 (+/-0.0138) for {'n_neighbors': 2, 'weights': 'distance'}\n",
      "()\n",
      "0.9227 (+/-0.0114) for {'n_neighbors': 3, 'weights': 'uniform'}\n",
      "()\n",
      "0.9225 (+/-0.0121) for {'n_neighbors': 3, 'weights': 'distance'}\n",
      "()\n",
      "0.9184 (+/-0.0119) for {'n_neighbors': 4, 'weights': 'uniform'}\n",
      "()\n",
      "0.9198 (+/-0.0126) for {'n_neighbors': 4, 'weights': 'distance'}\n",
      "()\n",
      "0.9153 (+/-0.0138) for {'n_neighbors': 5, 'weights': 'uniform'}\n",
      "()\n",
      "0.9178 (+/-0.0130) for {'n_neighbors': 5, 'weights': 'distance'}\n",
      "()\n",
      "0.9144 (+/-0.0139) for {'n_neighbors': 6, 'weights': 'uniform'}\n",
      "()\n",
      "0.9172 (+/-0.0134) for {'n_neighbors': 6, 'weights': 'distance'}\n",
      "()\n",
      "0.9159 (+/-0.0140) for {'n_neighbors': 7, 'weights': 'uniform'}\n",
      "()\n",
      "0.9183 (+/-0.0133) for {'n_neighbors': 7, 'weights': 'distance'}\n",
      "()\n",
      "0.9146 (+/-0.0108) for {'n_neighbors': 8, 'weights': 'uniform'}\n",
      "()\n",
      "0.9173 (+/-0.0111) for {'n_neighbors': 8, 'weights': 'distance'}\n",
      "()\n",
      "0.9133 (+/-0.0115) for {'n_neighbors': 9, 'weights': 'uniform'}\n",
      "()\n",
      "0.9163 (+/-0.0119) for {'n_neighbors': 9, 'weights': 'distance'}\n",
      "()\n",
      "0.9135 (+/-0.0108) for {'n_neighbors': 10, 'weights': 'uniform'}\n",
      "()\n",
      "0.9164 (+/-0.0114) for {'n_neighbors': 10, 'weights': 'distance'}\n",
      "()\n",
      "0.9096 (+/-0.0109) for {'n_neighbors': 11, 'weights': 'uniform'}\n",
      "()\n",
      "0.9134 (+/-0.0115) for {'n_neighbors': 11, 'weights': 'distance'}\n",
      "()\n",
      "0.9049 (+/-0.0123) for {'n_neighbors': 12, 'weights': 'uniform'}\n",
      "()\n",
      "0.9098 (+/-0.0123) for {'n_neighbors': 12, 'weights': 'distance'}\n",
      "()\n",
      "0.9028 (+/-0.0135) for {'n_neighbors': 13, 'weights': 'uniform'}\n",
      "()\n",
      "0.9079 (+/-0.0131) for {'n_neighbors': 13, 'weights': 'distance'}\n",
      "()\n",
      "0.9000 (+/-0.0140) for {'n_neighbors': 14, 'weights': 'uniform'}\n",
      "()\n",
      "0.9056 (+/-0.0134) for {'n_neighbors': 14, 'weights': 'distance'}\n",
      "()\n",
      "0.8977 (+/-0.0149) for {'n_neighbors': 15, 'weights': 'uniform'}\n",
      "()\n",
      "0.9038 (+/-0.0141) for {'n_neighbors': 15, 'weights': 'distance'}\n",
      "()\n",
      "0.8977 (+/-0.0143) for {'n_neighbors': 16, 'weights': 'uniform'}\n",
      "()\n",
      "0.9035 (+/-0.0137) for {'n_neighbors': 16, 'weights': 'distance'}\n",
      "()\n",
      "0.8953 (+/-0.0123) for {'n_neighbors': 17, 'weights': 'uniform'}\n",
      "()\n",
      "0.9016 (+/-0.0123) for {'n_neighbors': 17, 'weights': 'distance'}\n",
      "()\n",
      "0.8924 (+/-0.0112) for {'n_neighbors': 18, 'weights': 'uniform'}\n",
      "()\n",
      "0.8994 (+/-0.0115) for {'n_neighbors': 18, 'weights': 'distance'}\n",
      "()\n",
      "0.8912 (+/-0.0113) for {'n_neighbors': 19, 'weights': 'uniform'}\n",
      "()\n",
      "0.8983 (+/-0.0115) for {'n_neighbors': 19, 'weights': 'distance'}\n",
      "()\n",
      "0.8888 (+/-0.0115) for {'n_neighbors': 20, 'weights': 'uniform'}\n",
      "()\n",
      "0.8962 (+/-0.0116) for {'n_neighbors': 20, 'weights': 'distance'}\n",
      "()\n",
      "0.8879 (+/-0.0123) for {'n_neighbors': 21, 'weights': 'uniform'}\n",
      "()\n",
      "0.8954 (+/-0.0121) for {'n_neighbors': 21, 'weights': 'distance'}\n",
      "()\n",
      "0.8865 (+/-0.0123) for {'n_neighbors': 22, 'weights': 'uniform'}\n",
      "()\n",
      "0.8941 (+/-0.0122) for {'n_neighbors': 22, 'weights': 'distance'}\n",
      "()\n",
      "0.8866 (+/-0.0122) for {'n_neighbors': 23, 'weights': 'uniform'}\n",
      "()\n",
      "0.8940 (+/-0.0121) for {'n_neighbors': 23, 'weights': 'distance'}\n",
      "()\n",
      "0.8854 (+/-0.0129) for {'n_neighbors': 24, 'weights': 'uniform'}\n",
      "()\n",
      "0.8930 (+/-0.0126) for {'n_neighbors': 24, 'weights': 'distance'}\n",
      "()\n",
      "0.8847 (+/-0.0127) for {'n_neighbors': 25, 'weights': 'uniform'}\n",
      "()\n",
      "0.8924 (+/-0.0124) for {'n_neighbors': 25, 'weights': 'distance'}\n",
      "()\n",
      "0.8840 (+/-0.0137) for {'n_neighbors': 26, 'weights': 'uniform'}\n",
      "()\n",
      "0.8918 (+/-0.0131) for {'n_neighbors': 26, 'weights': 'distance'}\n",
      "()\n",
      "0.8832 (+/-0.0134) for {'n_neighbors': 27, 'weights': 'uniform'}\n",
      "()\n",
      "0.8911 (+/-0.0128) for {'n_neighbors': 27, 'weights': 'distance'}\n",
      "()\n",
      "0.8824 (+/-0.0127) for {'n_neighbors': 28, 'weights': 'uniform'}\n",
      "()\n",
      "0.8903 (+/-0.0123) for {'n_neighbors': 28, 'weights': 'distance'}\n",
      "()\n",
      "0.8817 (+/-0.0137) for {'n_neighbors': 29, 'weights': 'uniform'}\n",
      "()\n",
      "0.8897 (+/-0.0129) for {'n_neighbors': 29, 'weights': 'distance'}\n",
      "()\n",
      "0.8812 (+/-0.0132) for {'n_neighbors': 30, 'weights': 'uniform'}\n",
      "()\n",
      "0.8893 (+/-0.0126) for {'n_neighbors': 30, 'weights': 'distance'}\n",
      "()\n",
      "0.8803 (+/-0.0134) for {'n_neighbors': 31, 'weights': 'uniform'}\n",
      "()\n",
      "0.8884 (+/-0.0129) for {'n_neighbors': 31, 'weights': 'distance'}\n",
      "()\n",
      "0.8790 (+/-0.0137) for {'n_neighbors': 32, 'weights': 'uniform'}\n",
      "()\n",
      "0.8873 (+/-0.0131) for {'n_neighbors': 32, 'weights': 'distance'}\n",
      "()\n",
      "0.8780 (+/-0.0139) for {'n_neighbors': 33, 'weights': 'uniform'}\n",
      "()\n",
      "0.8865 (+/-0.0133) for {'n_neighbors': 33, 'weights': 'distance'}\n",
      "()\n",
      "0.8778 (+/-0.0143) for {'n_neighbors': 34, 'weights': 'uniform'}\n",
      "()\n",
      "0.8863 (+/-0.0135) for {'n_neighbors': 34, 'weights': 'distance'}\n",
      "()\n",
      "0.8769 (+/-0.0143) for {'n_neighbors': 35, 'weights': 'uniform'}\n",
      "()\n",
      "0.8855 (+/-0.0135) for {'n_neighbors': 35, 'weights': 'distance'}\n",
      "()\n",
      "0.8765 (+/-0.0142) for {'n_neighbors': 36, 'weights': 'uniform'}\n",
      "()\n",
      "0.8850 (+/-0.0134) for {'n_neighbors': 36, 'weights': 'distance'}\n",
      "()\n",
      "0.8757 (+/-0.0144) for {'n_neighbors': 37, 'weights': 'uniform'}\n",
      "()\n",
      "0.8843 (+/-0.0136) for {'n_neighbors': 37, 'weights': 'distance'}\n",
      "()\n",
      "0.8752 (+/-0.0147) for {'n_neighbors': 38, 'weights': 'uniform'}\n",
      "()\n",
      "0.8839 (+/-0.0138) for {'n_neighbors': 38, 'weights': 'distance'}\n",
      "()\n",
      "0.8747 (+/-0.0149) for {'n_neighbors': 39, 'weights': 'uniform'}\n",
      "()\n",
      "0.8834 (+/-0.0139) for {'n_neighbors': 39, 'weights': 'distance'}\n",
      "()\n",
      "0.8747 (+/-0.0148) for {'n_neighbors': 40, 'weights': 'uniform'}\n",
      "()\n",
      "0.8832 (+/-0.0139) for {'n_neighbors': 40, 'weights': 'distance'}\n",
      "()\n",
      "0.8745 (+/-0.0146) for {'n_neighbors': 41, 'weights': 'uniform'}\n",
      "()\n",
      "0.8830 (+/-0.0138) for {'n_neighbors': 41, 'weights': 'distance'}\n",
      "()\n",
      "0.8741 (+/-0.0142) for {'n_neighbors': 42, 'weights': 'uniform'}\n",
      "()\n",
      "0.8826 (+/-0.0135) for {'n_neighbors': 42, 'weights': 'distance'}\n",
      "()\n",
      "0.8730 (+/-0.0140) for {'n_neighbors': 43, 'weights': 'uniform'}\n",
      "()\n",
      "0.8817 (+/-0.0133) for {'n_neighbors': 43, 'weights': 'distance'}\n",
      "()\n",
      "0.8727 (+/-0.0139) for {'n_neighbors': 44, 'weights': 'uniform'}\n",
      "()\n",
      "0.8815 (+/-0.0132) for {'n_neighbors': 44, 'weights': 'distance'}\n",
      "()\n",
      "0.8723 (+/-0.0137) for {'n_neighbors': 45, 'weights': 'uniform'}\n",
      "()\n",
      "0.8811 (+/-0.0130) for {'n_neighbors': 45, 'weights': 'distance'}\n",
      "()\n",
      "0.8719 (+/-0.0135) for {'n_neighbors': 46, 'weights': 'uniform'}\n",
      "()\n",
      "0.8807 (+/-0.0129) for {'n_neighbors': 46, 'weights': 'distance'}\n",
      "()\n",
      "0.8714 (+/-0.0140) for {'n_neighbors': 47, 'weights': 'uniform'}\n",
      "()\n",
      "0.8803 (+/-0.0131) for {'n_neighbors': 47, 'weights': 'distance'}\n",
      "()\n",
      "0.8707 (+/-0.0138) for {'n_neighbors': 48, 'weights': 'uniform'}\n",
      "()\n",
      "0.8797 (+/-0.0130) for {'n_neighbors': 48, 'weights': 'distance'}\n",
      "()\n",
      "0.8706 (+/-0.0140) for {'n_neighbors': 49, 'weights': 'uniform'}\n",
      "()\n",
      "0.8795 (+/-0.0131) for {'n_neighbors': 49, 'weights': 'distance'}\n",
      "()\n",
      "0.8702 (+/-0.0141) for {'n_neighbors': 50, 'weights': 'uniform'}\n",
      "()\n",
      "0.8791 (+/-0.0132) for {'n_neighbors': 50, 'weights': 'distance'}\n",
      "()\n",
      "0.8701 (+/-0.0141) for {'n_neighbors': 51, 'weights': 'uniform'}\n",
      "()\n",
      "0.8789 (+/-0.0132) for {'n_neighbors': 51, 'weights': 'distance'}\n",
      "()\n",
      "0.8699 (+/-0.0139) for {'n_neighbors': 52, 'weights': 'uniform'}\n",
      "()\n",
      "0.8787 (+/-0.0131) for {'n_neighbors': 52, 'weights': 'distance'}\n",
      "()\n",
      "0.8699 (+/-0.0142) for {'n_neighbors': 53, 'weights': 'uniform'}\n",
      "()\n",
      "0.8787 (+/-0.0134) for {'n_neighbors': 53, 'weights': 'distance'}\n",
      "()\n",
      "0.8698 (+/-0.0141) for {'n_neighbors': 54, 'weights': 'uniform'}\n",
      "()\n",
      "0.8786 (+/-0.0133) for {'n_neighbors': 54, 'weights': 'distance'}\n",
      "()\n",
      "0.8699 (+/-0.0141) for {'n_neighbors': 55, 'weights': 'uniform'}\n",
      "()\n",
      "0.8785 (+/-0.0134) for {'n_neighbors': 55, 'weights': 'distance'}\n",
      "()\n",
      "0.8696 (+/-0.0140) for {'n_neighbors': 56, 'weights': 'uniform'}\n",
      "()\n",
      "0.8782 (+/-0.0133) for {'n_neighbors': 56, 'weights': 'distance'}\n",
      "()\n",
      "0.8687 (+/-0.0142) for {'n_neighbors': 57, 'weights': 'uniform'}\n",
      "()\n",
      "0.8775 (+/-0.0134) for {'n_neighbors': 57, 'weights': 'distance'}\n",
      "()\n",
      "0.8684 (+/-0.0143) for {'n_neighbors': 58, 'weights': 'uniform'}\n",
      "()\n",
      "0.8772 (+/-0.0135) for {'n_neighbors': 58, 'weights': 'distance'}\n",
      "()\n",
      "0.8682 (+/-0.0140) for {'n_neighbors': 59, 'weights': 'uniform'}\n",
      "()\n",
      "0.8770 (+/-0.0133) for {'n_neighbors': 59, 'weights': 'distance'}\n",
      "()\n",
      "0.8676 (+/-0.0140) for {'n_neighbors': 60, 'weights': 'uniform'}\n",
      "()\n",
      "0.8765 (+/-0.0133) for {'n_neighbors': 60, 'weights': 'distance'}\n",
      "()\n",
      "0.8672 (+/-0.0140) for {'n_neighbors': 61, 'weights': 'uniform'}\n",
      "()\n",
      "0.8762 (+/-0.0132) for {'n_neighbors': 61, 'weights': 'distance'}\n",
      "()\n",
      "0.8668 (+/-0.0138) for {'n_neighbors': 62, 'weights': 'uniform'}\n",
      "()\n",
      "0.8759 (+/-0.0132) for {'n_neighbors': 62, 'weights': 'distance'}\n",
      "()\n",
      "0.8667 (+/-0.0137) for {'n_neighbors': 63, 'weights': 'uniform'}\n",
      "()\n",
      "0.8757 (+/-0.0131) for {'n_neighbors': 63, 'weights': 'distance'}\n",
      "()\n",
      "0.8662 (+/-0.0138) for {'n_neighbors': 64, 'weights': 'uniform'}\n",
      "()\n",
      "0.8753 (+/-0.0131) for {'n_neighbors': 64, 'weights': 'distance'}\n",
      "()\n",
      "0.8655 (+/-0.0142) for {'n_neighbors': 65, 'weights': 'uniform'}\n",
      "()\n",
      "0.8747 (+/-0.0134) for {'n_neighbors': 65, 'weights': 'distance'}\n",
      "()\n",
      "0.8652 (+/-0.0148) for {'n_neighbors': 66, 'weights': 'uniform'}\n",
      "()\n",
      "0.8745 (+/-0.0138) for {'n_neighbors': 66, 'weights': 'distance'}\n",
      "()\n",
      "0.8650 (+/-0.0146) for {'n_neighbors': 67, 'weights': 'uniform'}\n",
      "()\n",
      "0.8743 (+/-0.0137) for {'n_neighbors': 67, 'weights': 'distance'}\n",
      "()\n",
      "0.8653 (+/-0.0143) for {'n_neighbors': 68, 'weights': 'uniform'}\n",
      "()\n",
      "0.8744 (+/-0.0135) for {'n_neighbors': 68, 'weights': 'distance'}\n",
      "()\n",
      "0.8653 (+/-0.0143) for {'n_neighbors': 69, 'weights': 'uniform'}\n",
      "()\n",
      "0.8744 (+/-0.0135) for {'n_neighbors': 69, 'weights': 'distance'}\n",
      "()\n",
      "0.8650 (+/-0.0145) for {'n_neighbors': 70, 'weights': 'uniform'}\n",
      "()\n",
      "0.8741 (+/-0.0137) for {'n_neighbors': 70, 'weights': 'distance'}\n",
      "()\n",
      "0.8646 (+/-0.0146) for {'n_neighbors': 71, 'weights': 'uniform'}\n",
      "()\n",
      "0.8738 (+/-0.0137) for {'n_neighbors': 71, 'weights': 'distance'}\n",
      "()\n",
      "0.8642 (+/-0.0148) for {'n_neighbors': 72, 'weights': 'uniform'}\n",
      "()\n",
      "0.8734 (+/-0.0139) for {'n_neighbors': 72, 'weights': 'distance'}\n",
      "()\n",
      "0.8638 (+/-0.0145) for {'n_neighbors': 73, 'weights': 'uniform'}\n",
      "()\n",
      "0.8731 (+/-0.0136) for {'n_neighbors': 73, 'weights': 'distance'}\n",
      "()\n",
      "0.8634 (+/-0.0146) for {'n_neighbors': 74, 'weights': 'uniform'}\n",
      "()\n",
      "0.8728 (+/-0.0137) for {'n_neighbors': 74, 'weights': 'distance'}\n",
      "()\n",
      "0.8633 (+/-0.0144) for {'n_neighbors': 75, 'weights': 'uniform'}\n",
      "()\n",
      "0.8726 (+/-0.0135) for {'n_neighbors': 75, 'weights': 'distance'}\n",
      "()\n",
      "0.8628 (+/-0.0143) for {'n_neighbors': 76, 'weights': 'uniform'}\n",
      "()\n",
      "0.8722 (+/-0.0135) for {'n_neighbors': 76, 'weights': 'distance'}\n",
      "()\n",
      "0.8628 (+/-0.0141) for {'n_neighbors': 77, 'weights': 'uniform'}\n",
      "()\n",
      "0.8721 (+/-0.0134) for {'n_neighbors': 77, 'weights': 'distance'}\n",
      "()\n",
      "0.8626 (+/-0.0142) for {'n_neighbors': 78, 'weights': 'uniform'}\n",
      "()\n",
      "0.8719 (+/-0.0134) for {'n_neighbors': 78, 'weights': 'distance'}\n",
      "()\n",
      "0.8624 (+/-0.0143) for {'n_neighbors': 79, 'weights': 'uniform'}\n",
      "()\n",
      "0.8718 (+/-0.0135) for {'n_neighbors': 79, 'weights': 'distance'}\n",
      "()\n",
      "0.8621 (+/-0.0147) for {'n_neighbors': 80, 'weights': 'uniform'}\n",
      "()\n",
      "0.8715 (+/-0.0138) for {'n_neighbors': 80, 'weights': 'distance'}\n",
      "()\n",
      "0.8618 (+/-0.0149) for {'n_neighbors': 81, 'weights': 'uniform'}\n",
      "()\n",
      "0.8713 (+/-0.0140) for {'n_neighbors': 81, 'weights': 'distance'}\n",
      "()\n",
      "0.8614 (+/-0.0147) for {'n_neighbors': 82, 'weights': 'uniform'}\n",
      "()\n",
      "0.8709 (+/-0.0139) for {'n_neighbors': 82, 'weights': 'distance'}\n",
      "()\n",
      "0.8608 (+/-0.0146) for {'n_neighbors': 83, 'weights': 'uniform'}\n",
      "()\n",
      "0.8705 (+/-0.0138) for {'n_neighbors': 83, 'weights': 'distance'}\n",
      "()\n",
      "0.8605 (+/-0.0148) for {'n_neighbors': 84, 'weights': 'uniform'}\n",
      "()\n",
      "0.8702 (+/-0.0140) for {'n_neighbors': 84, 'weights': 'distance'}\n",
      "()\n",
      "0.8606 (+/-0.0148) for {'n_neighbors': 85, 'weights': 'uniform'}\n",
      "()\n",
      "0.8703 (+/-0.0139) for {'n_neighbors': 85, 'weights': 'distance'}\n",
      "()\n",
      "0.8604 (+/-0.0148) for {'n_neighbors': 86, 'weights': 'uniform'}\n",
      "()\n",
      "0.8701 (+/-0.0140) for {'n_neighbors': 86, 'weights': 'distance'}\n",
      "()\n",
      "0.8602 (+/-0.0147) for {'n_neighbors': 87, 'weights': 'uniform'}\n",
      "()\n",
      "0.8699 (+/-0.0139) for {'n_neighbors': 87, 'weights': 'distance'}\n",
      "()\n",
      "0.8597 (+/-0.0148) for {'n_neighbors': 88, 'weights': 'uniform'}\n",
      "()\n",
      "0.8695 (+/-0.0140) for {'n_neighbors': 88, 'weights': 'distance'}\n",
      "()\n",
      "0.8594 (+/-0.0150) for {'n_neighbors': 89, 'weights': 'uniform'}\n",
      "()\n",
      "0.8692 (+/-0.0141) for {'n_neighbors': 89, 'weights': 'distance'}\n",
      "()\n",
      "0.8591 (+/-0.0150) for {'n_neighbors': 90, 'weights': 'uniform'}\n",
      "()\n",
      "0.8690 (+/-0.0142) for {'n_neighbors': 90, 'weights': 'distance'}\n",
      "()\n",
      "0.8587 (+/-0.0154) for {'n_neighbors': 91, 'weights': 'uniform'}\n",
      "()\n",
      "0.8687 (+/-0.0144) for {'n_neighbors': 91, 'weights': 'distance'}\n",
      "()\n",
      "0.8586 (+/-0.0155) for {'n_neighbors': 92, 'weights': 'uniform'}\n",
      "()\n",
      "0.8686 (+/-0.0145) for {'n_neighbors': 92, 'weights': 'distance'}\n",
      "()\n",
      "0.8581 (+/-0.0154) for {'n_neighbors': 93, 'weights': 'uniform'}\n",
      "()\n",
      "0.8682 (+/-0.0144) for {'n_neighbors': 93, 'weights': 'distance'}\n",
      "()\n",
      "0.8578 (+/-0.0150) for {'n_neighbors': 94, 'weights': 'uniform'}\n",
      "()\n",
      "0.8680 (+/-0.0142) for {'n_neighbors': 94, 'weights': 'distance'}\n",
      "()\n",
      "0.8574 (+/-0.0151) for {'n_neighbors': 95, 'weights': 'uniform'}\n",
      "()\n",
      "0.8677 (+/-0.0142) for {'n_neighbors': 95, 'weights': 'distance'}\n",
      "()\n",
      "0.8571 (+/-0.0151) for {'n_neighbors': 96, 'weights': 'uniform'}\n",
      "()\n",
      "0.8674 (+/-0.0142) for {'n_neighbors': 96, 'weights': 'distance'}\n",
      "()\n",
      "0.8570 (+/-0.0149) for {'n_neighbors': 97, 'weights': 'uniform'}\n",
      "()\n",
      "0.8673 (+/-0.0141) for {'n_neighbors': 97, 'weights': 'distance'}\n",
      "()\n",
      "0.8565 (+/-0.0150) for {'n_neighbors': 98, 'weights': 'uniform'}\n",
      "()\n",
      "0.8670 (+/-0.0142) for {'n_neighbors': 98, 'weights': 'distance'}\n",
      "()\n",
      "0.8560 (+/-0.0150) for {'n_neighbors': 99, 'weights': 'uniform'}\n",
      "()\n",
      "0.8665 (+/-0.0142) for {'n_neighbors': 99, 'weights': 'distance'}\n",
      "()\n",
      "0.9112\n",
      "Para los scores de test del CV [31, 31, 10, 9, 1, 2, 4, 3, 14, 6, 16, 8, 13, 5, 15, 7, 19, 12, 17, 11, 21, 18, 24, 20, 27, 22, 29, 23, 34, 25, 35, 26, 38, 28, 43, 30, 45, 33, 50, 36, 52, 37, 55, 39, 54, 40, 59, 41, 61, 42, 63, 44, 66, 46, 70, 47, 71, 48, 74, 49, 77, 51, 82, 53, 89, 56, 90, 57, 94, 58, 96, 60, 99, 62, 102, 64, 103, 65, 105, 67, 106, 68, 112, 69, 116, 72, 118, 73, 120, 75, 124, 76, 127, 78, 130, 79, 131, 80, 135, 81, 136, 83, 139, 84, 138, 85, 142, 86, 140, 87, 143, 88, 148, 91, 150, 92, 152, 93, 155, 95, 158, 97, 160, 98, 161, 100, 163, 101, 164, 104, 167, 107, 168, 110, 165, 108, 166, 109, 169, 111, 170, 113, 171, 114, 172, 115, 173, 117, 174, 119, 175, 121, 176, 122, 177, 123, 178, 125, 179, 126, 180, 128, 181, 129, 182, 132, 184, 134, 183, 133, 185, 137, 186, 141, 187, 144, 188, 145, 189, 146, 190, 147, 191, 149, 192, 151, 193, 153, 194, 154, 195, 156, 196, 157, 197, 159, 198, 162] el mejor ranking es 1 y pertenece al pliegue cuyo n_vecinos es 3 y su peso uniform\n",
      "[0.035125161661899967, 0.035125161661899947, 0.01334714258002808, 0.013813461158532702, 0.011391887833230387, 0.012119557336485731, 0.011868306382685384, 0.012600078072999708, 0.013853791772043295, 0.013015769310163685, 0.013892485008592673, 0.013378220237315303, 0.013966487914261326, 0.013308411371305878, 0.010778220098444535, 0.011104966729037418, 0.011506769456926599, 0.011913892443955127, 0.010837467911150138, 0.01140529048220401, 0.010944068030817447, 0.011493942492412781, 0.01226717182534859, 0.012270213843644346, 0.013512410227363273, 0.013122090054926022, 0.013983501739857476, 0.013446636426605546, 0.01495424461768723, 0.014130595942833885, 0.014282167425035, 0.013669100517652494, 0.012339370387184268, 0.012306731916641061, 0.01121940959242961, 0.011517040997688372, 0.011334035250202131, 0.011453204359658168, 0.011533325737600216, 0.011619668370228087, 0.01225264666178826, 0.012124552619386043, 0.012331385990927268, 0.012203149919501151, 0.012211999232444083, 0.012052232300575672, 0.012945954867368804, 0.012570117133470742, 0.012707007410269949, 0.012404808108596226, 0.013710852196172163, 0.013055799153876391, 0.013362094260818138, 0.01279333298530849, 0.012678644143413688, 0.012281763986149856, 0.013673449459856294, 0.012926334348687148, 0.013205816312675884, 0.012584193524164558, 0.013423803452101465, 0.012878025507596737, 0.013657411983918328, 0.013071598949104582, 0.013915326323655714, 0.013297369149330645, 0.014289813748511102, 0.013528032255220467, 0.014322302011914098, 0.013520218277565365, 0.014246902081645545, 0.013437843909410312, 0.014348702295842895, 0.013588083357152588, 0.01465616376555748, 0.013795485550221736, 0.014868028124512043, 0.013940856292249986, 0.014773210364703838, 0.013883627890453141, 0.014576999446298786, 0.013749886591840458, 0.014224450257496057, 0.013495286789507566, 0.014022229335106912, 0.013297878392777055, 0.013909598577420603, 0.013161098525534865, 0.013712116902538929, 0.01303750176902712, 0.013503885857815786, 0.012858221156139554, 0.013961875148727192, 0.013128041120304178, 0.013823260645921563, 0.013041579891740797, 0.013956192329549774, 0.013101488721518477, 0.01407474290175852, 0.013175238128398003, 0.014085851902020902, 0.013229075017496936, 0.013888772399690602, 0.013131722187153545, 0.014217269731631444, 0.013396385970819982, 0.014099191713907952, 0.013344889629930193, 0.014094208611665361, 0.01336054379848259, 0.014028996390173113, 0.013289341333757683, 0.01414877890562854, 0.013364625605879296, 0.014249610486493924, 0.013452311642784457, 0.013988646251599401, 0.013271819016544548, 0.013995417470158499, 0.013267982608732977, 0.014002630696149848, 0.013245253055509087, 0.01383585254540687, 0.01315238388405174, 0.013719056185503502, 0.013091923069114947, 0.013796814753711754, 0.013082120969523917, 0.014219000902398859, 0.013394494181087834, 0.014752848276579503, 0.013792844958842497, 0.014574688011875656, 0.01365374946682477, 0.014302561826272603, 0.013503835189939417, 0.014290013277194003, 0.013486041666154785, 0.014543578102586127, 0.01365639629781233, 0.014602423100326225, 0.013692713303907032, 0.014842520014124496, 0.013853470173487046, 0.014486595230030744, 0.013589425964501757, 0.014643540772162988, 0.013700640593921428, 0.014362285333408359, 0.013510006548487273, 0.014336539335270636, 0.013519759404553855, 0.014129587448246378, 0.013382063912186945, 0.014174544767296094, 0.013440178009390267, 0.014266944036455134, 0.013533273198974618, 0.014692478181286602, 0.013824311461104079, 0.014848865326603082, 0.01396282228242369, 0.014720223951136466, 0.013919522381536842, 0.014579963812008363, 0.013798890160876648, 0.014799046435799761, 0.013955574576752682, 0.014755460417560861, 0.013932024614182937, 0.014784798884730404, 0.013991697803480571, 0.014677314340491061, 0.013899475369028896, 0.014787269802246402, 0.013983784371958994, 0.015009093396705187, 0.01414370793343709, 0.015023828061652159, 0.014164056657162308, 0.015346606242753543, 0.014371128530723939, 0.015479430843424923, 0.014473858920068921, 0.015387028077041493, 0.014425177164065875, 0.01502802332944341, 0.014190944379466079, 0.0150887775336075, 0.014228208024407735, 0.015118885497297048, 0.014238111885497352, 0.014907841486009746, 0.014129298930945217, 0.01499767887201043, 0.014196445611484565, 0.014959097613117749, 0.014172891020293569]\n",
      "0.9113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moises/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "/home/moises/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "/home/moises/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAFdCAYAAABfMCThAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nckO7btsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f51c8cb32d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAFdCAYAAABfMCThAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nk9UAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f51c9059bd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La estimacion de CV-5 era 0.9112 y el resultado del test es 0.9205\n"
     ]
    }
   ],
   "source": [
    "#NOTA IMPORTANTE: Le quito el redondeo a tres decimales y se lo dejo a 4 porque para este problema tenemos que ser \n",
    "#algo más precisos ya que la estimación que me da está en el mismo o muy cerca de uno de los puntos frontera\n",
    "\n",
    "hyperParams = {'n_neighbors': range(1,100),\n",
    "               'weights': ['uniform', 'distance']}\n",
    "\n",
    "#Create an instance of Neighbors Reggresor and fit the data for the grid parameters\n",
    "modelCV = GridSearchCV(neighbors.KNeighborsRegressor(), \n",
    "                     hyperParams, cv=5, scoring=None)\n",
    "modelCV.fit(xTrain, yTrain)\n",
    "print \"Best hyperparameters Cross-Validation\", modelCV.best_params_\n",
    "neighList, errList, devList = [], [], []\n",
    "i = 0\n",
    "estimacionCV1 = float(\"inf\")\n",
    "for hyperP, mean_score, scores in modelCV.grid_scores_:\n",
    "    print(\"%0.4f (+/-%0.4f) for %r\"\n",
    "              % (mean_score, scores.std(), hyperP))\n",
    "    if hyperP['weights'] == modelCV.best_params_['weights']:\n",
    "        neighList.append(hyperP['n_neighbors'])\n",
    "        errList.append(mean_score)\n",
    "        devList.append(scores.std())\n",
    "        if hyperP['n_neighbors'] == modelCV.best_params_['n_neighbors']:\n",
    "                estimacionCV1 = mean_score - scores.std()\n",
    "    print()    \n",
    "print(\"%0.4f\" % estimacionCV1)\n",
    "\n",
    "#Ahora comprobamos con los demás resultados entre los que se haya el vector de ranking (scikit-learn v0.18.1)\n",
    "\n",
    "#print \"Resultados:\", modelCV.cv_results_\n",
    "oserList = list(modelCV.cv_results_['rank_test_score'])\n",
    "#Escogemos el que mejor ranking que normalmente será 1\n",
    "regla_un_error_estandar = min(oserList)\n",
    "#Nos quedamos con el primer índice que cumpla la regla\n",
    "indice = [i for i,x in enumerate(oserList) if x == regla_un_error_estandar][0] \n",
    "vecinos = modelCV.grid_scores_[indice][0]['n_neighbors']\n",
    "#print(vecinos)\n",
    "peso = modelCV.grid_scores_[indice][0]['weights']\n",
    "#print(peso)\n",
    "print(\"Para los scores de test del CV %r el mejor ranking es %i y pertenece al pliegue cuyo n_vecinos es %i y su peso %s\" \n",
    "      % (oserList, regla_un_error_estandar, vecinos, peso))\n",
    "#Según la teoría vista en clase (transparencias 23 y 25 del tema 1) debería de escoger el pliegue que \n",
    "#cumpla con la regla 'one-standar-error-rule'. Scikit-Learn ya nos facilita un vector con el ranking de los\n",
    "#mejores test scores.\n",
    "\n",
    "#Aplicamos la regla para quedarnos el mínimo t (esa será nuestra estimación del error de test del CV)\n",
    "print(list(modelCV.cv_results_['std_test_score']))\n",
    "estimacionCV2 = list(modelCV.cv_results_['mean_test_score'])[indice]-list(modelCV.cv_results_['std_test_score'])[indice]\n",
    "print(\"%0.4f\" % estimacionCV2)\n",
    "\n",
    "#Por diferencias que desconozco entre los grid_scrores_ y los cv_results_ para este problema en concreto no coinciden\n",
    "#como las listas de datos para los plots se toman de los grid_scores por coherencia me quedaré con la estimación de éste.\n",
    "estimacionCV = estimacionCV1\n",
    "\n",
    "#De entre todos los pliegues de la validación cruzada, elige como mejores hiperparámetros el pliegue\n",
    "#cuyo número de vecinos es 3 y su peso es uniforme con el score 0.9227, y desviación estándar de +/- 0.0114,\n",
    "#el cual como hemos podido ver es el que mejor ranking de test scores tiene.\n",
    "plt.errorbar(neighList, errList, yerr = devList)\n",
    "plt.xlim(neighList[0]-1, neighList[len(neighList)-1]+1)\n",
    "plt.ylim(errList[0]-0.1, errList[len(errList)-1]+0.1)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "model = neighbors.KNeighborsRegressor(n_neighbors = modelCV.best_params_['n_neighbors'], \n",
    "                                       weights = modelCV.best_params_['weights'])\n",
    "model.fit(xTrain, yTrain)\n",
    "precision_media = model.score(xTest,yTest)\n",
    "\n",
    "plt.errorbar(neighList, errList, yerr = devList)\n",
    "plt.xlim(neighList[0]-1, neighList[len(neighList)-1]+1)\n",
    "plt.ylim(errList[0]-0.1, errList[len(errList)-1]+0.1)\n",
    "plt.plot(modelCV.best_params_['n_neighbors'], precision_media, 'ro')\n",
    "plt.show()\n",
    "print(\"La estimacion de CV-5 era %0.4f y el resultado del test es %0.4f\" % (estimacionCV, precision_media))\n",
    "#Podemos observar que la estimación de la Validación Cruzada de 5 pliegues ha sido bastante buena ya que se aproxima \n",
    "#mucho, estimaciónCV1 estimaba 0.9112 y estimaciónCV2 estimaba 0.9113, y al final ha sido 0.9205, \n",
    "#si tomamos la estimaciónCV2  está dentro del rango (0.9113,0.9341) si tomamos la estimaciónCV1 no por muy poco,\n",
    "#esto último puede deberse a temas de redondeos pero de un modo u otro o está justo en el punto frontera o\n",
    "#muy cerca de él."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    x = x.ravel()\n",
    "    return np.exp(-x ** 2) + 1.5 * np.exp(-(x - 2) ** 2)\n",
    "\n",
    "def calcular_bias_medio(xTest, yTest, prediccion):\n",
    "    bias = (f(xTest) - np.mean(yTest-prediccion)) ** 2\n",
    "    return np.mean(bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pregunta 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Dado el problema de problema de regresión Energy Efficiency con la variable de salida cooling load, ¿cuál es el mínimo error de test?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 18.81  13.64  33.84  23.67  33.05  30.31  29.66  36.58  31.79  28.84\n",
      "  11.65  35.63  16.18  37.06  41.39  28.41  14.27  30.3   16.44  15.3\n",
      "  15.79  33.01  13.93  39.07  11.9   17.15  14.11  16.27  14.18  33.15\n",
      "  15.84  17.36  38.78  17.51  29.57  36.89  16.38  36.01  20.54  13.76\n",
      "  16.2   37.34  17.55  29.6   24.67  25.73  14.28  16.13  32.76  34.51\n",
      "  33.28  15.93  34.29  17.43  36.74  13.83  25.    35.83  33.21  16.92\n",
      "  19.42  15.06  33.73  13.64  15.53  14.77  40.04  14.34  30.3   36.42\n",
      "  33.09  14.33  30.56  18.6   16.13  38.26  33.18  33.59  31.94  16.74\n",
      "  37.05  30.63  16.26  16.62  38.14  28.03  26.11  35.05  15.86  22.    16.96\n",
      "  28.84  15.19  26.02  40.24  18.76  32.97  16.54  13.67  36.92  33.48\n",
      "  34.08  25.    32.59  13.65  31.58  32.15  17.41  15.31  24.26  19.59\n",
      "  33.91  30.25  15.67  15.24  16.08  14.65  34.77  29.03  39.94  37.55\n",
      "  14.98  15.23  35.04  15.19  39.04  16.91  30.02  14.8   30.89  32.44\n",
      "  25.9   35.39  15.02  36.76  13.75  33.45  24.3   33.84  16.14  17.46\n",
      "  20.86  32.62  13.79  34.55  18.29  31.1   37.16  15.27  16.58  30.05\n",
      "  15.81  18.42  17.04]\n",
      "[ 17.63  13.57  34.62  21.16  33.34  34.2   30.18  30.34  29.82  24.61\n",
      "  11.67  38.35  14.65  39.41  37.7   31.06  13.87  34.33  15.38  15.4\n",
      "  14.38  33.13  14.14  43.86  11.17  17.37  14.47  16.69  14.27  37.54\n",
      "  13.97  16.14  46.44  16.22  29.78  36.07  16.08  36.93  17.2   16.78\n",
      "  13.7   36.77  17.2   26.41  27.3   26.02  13.89  15.17  32.83  31.    33.94\n",
      "  14.27  34.05  17.64  37.2   13.7   21.33  31.39  37.26  16.9   18.1\n",
      "  14.91  33.86  13.72  15.85  14.49  45.97  14.55  32.04  36.87  32.78\n",
      "  13.79  24.77  16.86  19.48  29.88  32.95  43.73  32.88  17.1   40.66\n",
      "  30.08  13.72  14.61  32.54  26.72  25.88  30.93  14.37  16.99  16.99\n",
      "  31.28  15.5   26.44  39.55  17.2   29.77  16.44  12.14  37.28  35.1\n",
      "  28.68  23.49  33.87  13.5   28.31  38.56  16.14  15.42  21.33  20.82\n",
      "  33.89  32.28  19.29  14.94  19.29  14.87  43.14  27.33  39.37  33.14\n",
      "  15.18  15.44  34.94  14.74  39.85  16.9   30.1   14.92  29.69  33.67\n",
      "  26.37  41.86  13.79  36.15  12.23  28.43  26.47  34.35  15.47  21.08\n",
      "  22.72  29.34  13.8   41.68  16.    32.92  37.45  14.92  15.41  30.    15.\n",
      "  14.75  15.32]\n",
      "0.863277784431\n",
      "7.05105591298\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "prediccion = model.predict(xTest)\n",
    "prediccion = np.round(prediccion, decimals= 2)\n",
    "print(prediccion)\n",
    "print(yTest)\n",
    "MSE = mean_squared_error(yTest, prediccion)\n",
    "#mse = np.mean((yTest-prediccion)**2)\n",
    "bias_medio = calcular_bias_medio(xTest, yTest, prediccion)\n",
    "print(bias_medio)\n",
    "print(MSE-(bias_medio/2)) \n",
    "#Como MSE es el error medio y el bias_medio es la desviación total partimos por 2 (mitad de la desviación arriba, \n",
    "#la otra mitad hacia abajo). Por tanto el mínimo es 7.05 que si redondeamos nos quedamos con 7"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Si redondeamos al suelo quedándonos con la cifra más significativa, en este caso la parte entera, nos quedaría 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pregunta 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Dado el problema de clasificación Blood Transfusion Service Center, ¿cuál es el valor del hiper-parámetro número de vecinos que produce el mínimo error de entrenamiento con validación cruzada (5-CV)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters Cross-Validation {'n_neighbors': 29, 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "hyperParams = {'n_neighbors': range(1,100),\n",
    "               'weights': ['uniform', 'distance']}\n",
    "\n",
    "#Create an instance of Neighbors Classifier and fit the data for the grid parameters\n",
    "modelCV = GridSearchCV(neighbors.KNeighborsClassifier(), \n",
    "                     hyperParams, cv=5, scoring='accuracy')\n",
    "modelCV.fit(xTrain, yTrain)\n",
    "print \"Best hyperparameters Cross-Validation\", modelCV.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pregunta 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Dado el problema de clasificación Blood Transfusion Service Center, si se utiliza como método de selección de variables forward stepwise selection, ¿en qué orden se van añadiendo las variables?\n",
    "\n",
    "Formato de la respuesta (si las variables se añaden en el orden 0, 1, 3, 2): 0 1 3 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: {'std_err': 0.001376128970911626, 'avg_score': 0.77091788781628356, 'std_dev': 0.0027522579418232519, 'ci_bound': 0.0035374521374647587, 'feature_idx': (0,), 'cv_scores': array([ 0.76859504,  0.76666667,  0.77310924,  0.77310924,  0.77310924])}, 2: {'std_err': 0.001376128970911626, 'avg_score': 0.77091788781628356, 'std_dev': 0.0027522579418232519, 'ci_bound': 0.0035374521374647587, 'feature_idx': (1, 2), 'cv_scores': array([ 0.76859504,  0.76666667,  0.77310924,  0.77310924,  0.77310924])}, 3: {'std_err': 0.0058109944919597818, 'avg_score': 0.76752853207398664, 'std_dev': 0.011621988983919565, 'ci_bound': 0.014937636893700111, 'feature_idx': (1, 2, 3), 'cv_scores': array([ 0.76859504,  0.78333333,  0.77310924,  0.74789916,  0.76470588])}, 4: {'std_err': 0.012131447963495893, 'avg_score': 0.7942668472347616, 'std_dev': 0.024262895926991785, 'ci_bound': 0.031184879786799412, 'feature_idx': (0, 1, 2, 3), 'cv_scores': array([ 0.82644628,  0.75833333,  0.78991597,  0.78151261,  0.81512605])}}\n"
     ]
    }
   ],
   "source": [
    "print(diccionario_metricas) #0 2 3 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pregunta 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Dado el problema de clasificación Blood Transfusion Service Center, ¿cuál es el mínimo error de test?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  1.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.\n",
      "  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  1.  1.  1.  1.  0.  0.  1.  0.  1.  0.  0.  0.  1.  1.  0.  0.  0.\n",
      "  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  1.  0.  1.\n",
      "  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.\n",
      "  1.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  1.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  0.  1.  0.  0.\n",
      "  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  1.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.\n",
      "  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.]\n",
      "0.226666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "prediccion = model.predict(xTest)\n",
    "prediccion = np.round(prediccion, decimals= 2)\n",
    "print(prediccion)\n",
    "print(yTest)\n",
    "MSE = mean_squared_error(yTest, prediccion)\n",
    "#mse = np.mean((yTest-prediccion)**2)\n",
    "print(MSE) #Al ser un problema de clasificación nos quedamos sólo con el MSE"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Si redondeamos al suelo quedándonos con la cifra más significativa, en este caso el primer decimal, nos quedaría 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pregunta 5"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Dado el siguiente conjunto de datos de clasificación con 6 observaciones, 3 variables de entrada y una variable de salida:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<div align=\"center\">\n",
    "\n",
    "<table cellspacing=\"0\" cellpadding=\"0\" border=\"1\">\n",
    " <tbody><tr>\n",
    "  <td valign=\"top\">\n",
    "  <p><span lang=\"ES\">Observación</span></p>\n",
    "  </td>\n",
    "  <td valign=\"top\">\n",
    "  <p align=\"center\"><span lang=\"ES\">X<sub>1</sub></span></p>\n",
    "  </td>\n",
    "  <td valign=\"top\">\n",
    "  <p align=\"center\"><span lang=\"ES\">X<sub>2</sub></span></p>\n",
    "  </td>\n",
    "  <td valign=\"top\">\n",
    "  <p align=\"center\"><span lang=\"ES\">X<sub>3</sub></span></p>\n",
    "  </td>\n",
    "  <td valign=\"top\">\n",
    "  <p align=\"center\"><span lang=\"ES\">Y</span></p>\n",
    "  </td>\n",
    " </tr>\n",
    " <tr>\n",
    "  <td valign=\"top\">\n",
    "  <p><span lang=\"ES\">1</span></p>\n",
    "  </td>\n",
    "  <td valign=\"top\">\n",
    "  <p align=\"center\"><span lang=\"ES\">0</span></p>\n",
    "  </td>\n",
    "  <td valign=\"top\">\n",
    "  <p align=\"center\"><span lang=\"ES\">3</span></p>\n",
    "  </td>\n",
    "  <td valign=\"top\">\n",
    "  <p align=\"center\"><span lang=\"ES\">2</span></p>\n",
    "  </td>\n",
    "  <td valign=\"top\">\n",
    "  <p align=\"center\"><span lang=\"ES\">1</span></p>\n",
    "  </td>\n",
    " </tr>\n",
    " <tr>\n",
    "  <td valign=\"top\">\n",
    "  <p><span lang=\"ES\">2</span></p>\n",
    "  </td>\n",
    "  <td valign=\"top\">\n",
    "  <p align=\"center\"><span lang=\"ES\">3</span></p>\n",
    "  </td>\n",
    "  <td valign=\"top\">\n",
    "  <p align=\"center\"><span lang=\"ES\">0</span></p>\n",
    "  </td>\n",
    "  <td valign=\"top\">\n",
    "  <p align=\"center\"><span lang=\"ES\">1</span></p>\n",
    "  </td>\n",
    "  <td valign=\"top\">\n",
    "  <p align=\"center\"><span lang=\"ES\">0</span></p>\n",
    "  </td>\n",
    " </tr>\n",
    " <tr>\n",
    "  <td valign=\"top\">\n",
    "  <p><span lang=\"ES\">3</span></p>\n",
    "  </td>\n",
    "  <td valign=\"top\">\n",
    "  <p align=\"center\"><span lang=\"ES\">0</span></p>\n",
    "  </td>\n",
    "  <td valign=\"top\">\n",
    "  <p align=\"center\"><span lang=\"ES\">3</span></p>\n",
    "  </td>\n",
    "  <td valign=\"top\">\n",
    "  <p align=\"center\"><span lang=\"ES\">-1</span></p>\n",
    "  </td>\n",
    "  <td valign=\"top\">\n",
    "  <p align=\"center\"><span lang=\"ES\">0</span></p>\n",
    "  </td>\n",
    " </tr>\n",
    " <tr>\n",
    "  <td valign=\"top\">\n",
    "  <p><span lang=\"ES\">4</span></p>\n",
    "  </td>\n",
    "  <td valign=\"top\">\n",
    "  <p align=\"center\"><span lang=\"ES\">3</span></p>\n",
    "  </td>\n",
    "  <td valign=\"top\">\n",
    "  <p align=\"center\"><span lang=\"ES\">0</span></p>\n",
    "  </td>\n",
    "  <td valign=\"top\">\n",
    "  <p align=\"center\"><span lang=\"ES\">-1</span></p>\n",
    "  </td>\n",
    "  <td valign=\"top\">\n",
    "  <p align=\"center\"><span lang=\"ES\">1</span></p>\n",
    "  </td>\n",
    " </tr>\n",
    " <tr>\n",
    "  <td valign=\"top\">\n",
    "  <p><span lang=\"ES\">5</span></p>\n",
    "  </td>\n",
    "  <td valign=\"top\">\n",
    "  <p align=\"center\"><span lang=\"ES\">1</span></p>\n",
    "  </td>\n",
    "  <td valign=\"top\">\n",
    "  <p align=\"center\"><span lang=\"ES\">2</span></p>\n",
    "  </td>\n",
    "  <td valign=\"top\">\n",
    "  <p align=\"center\"><span lang=\"ES\">1</span></p>\n",
    "  </td>\n",
    "  <td valign=\"top\">\n",
    "  <p align=\"center\"><span lang=\"ES\">1</span></p>\n",
    "  </td>\n",
    " </tr>\n",
    " <tr>\n",
    "  <td valign=\"top\">\n",
    "  <p><span lang=\"ES\">6</span></p>\n",
    "  </td>\n",
    "  <td valign=\"top\">\n",
    "  <p align=\"center\"><span lang=\"ES\">2</span></p>\n",
    "  </td>\n",
    "  <td valign=\"top\">\n",
    "  <p align=\"center\"><span lang=\"ES\">1</span></p>\n",
    "  </td>\n",
    "  <td valign=\"top\">\n",
    "  <p align=\"center\"><span lang=\"ES\">1</span></p>\n",
    "  </td>\n",
    "  <td valign=\"top\">\n",
    "  <p align=\"center\"><span lang=\"ES\">0</span></p>\n",
    "  </td>\n",
    " </tr>\n",
    "</tbody></table>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Suponiendo que se quiere hacer la predicción de la variable de salida para X1=0,  X2=0, X3=0 mediante KNN.\n",
    "Indica la predicción para K=1 y los ejemplos que producen dicha predicción (introduce los ejemplos ordenados por el número de observación). EN CASO DE EMPATE DEBES INCLUIR TODOS LOS EJEMPLOS QUE SE ENCUENTREN EN ESA SITUACIÓN.\n",
    "\n",
    "Ejemplo del formato de respuesta para clase 0 y ejemplos 4 y 5: 0 4 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.60555127546\n",
      "3.16227766017\n",
      "3.16227766017\n",
      "3.16227766017\n",
      "2.44948974278\n",
      "2.44948974278\n"
     ]
    }
   ],
   "source": [
    "puntos = []\n",
    "puntos.append(Punto(0,3,2))\n",
    "puntos.append(Punto(3,0,1))\n",
    "puntos.append(Punto(0,3,-1))\n",
    "puntos.append(Punto(3,0,-1))\n",
    "puntos.append(Punto(1,2,1))\n",
    "puntos.append(Punto(2,1,1))\n",
    "for punto in puntos:\n",
    "    print distanciaEuclides(puntoOrigen,punto)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Para K=1 los dos vecinos más cercanos son el 5 y el 6, como tanto la clase 0 la 1 se encuentran a la misma distancia, escogemos por omisión la primera que es la 0. Por tanto, la respuesta sería 0 5 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pregunta 6"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Dado el problema de problema de regresión Energy Efficiency con la variable de salida cooling load, ¿cuál es el valor del hiper-parámetro número de vecinos que produce el mínimo error de entrenamiento con validación cruzada (5-CV)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters Cross-Validation {'n_neighbors': 3, 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "#NOTA IMPORTANTE: Le quito el redondeo a tres decimales y se lo dejo a 4 porque para este problema tenemos que ser \n",
    "#algo más precisos ya que la estimación que me da está en el mismo o muy cerca de uno de los puntos frontera\n",
    "\n",
    "hyperParams = {'n_neighbors': range(1,100),\n",
    "               'weights': ['uniform', 'distance']}\n",
    "\n",
    "#Create an instance of Neighbors Reggresor and fit the data for the grid parameters\n",
    "modelCV = GridSearchCV(neighbors.KNeighborsRegressor(), \n",
    "                     hyperParams, cv=5, scoring=None)\n",
    "modelCV.fit(xTrain, yTrain)\n",
    "print \"Best hyperparameters Cross-Validation\", modelCV.best_params_"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Como indica la salida el mejor número de vecinos para el problema de regresión es de 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pregunta 7"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Dado el problema de problema de regresión Energy Efficiency con la variable de salida cooling load, ¿cuál es el mínimo error de entrenamiento con validación cruzada (5-CV)?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Puesto que en el conjunto de entrenamiento el MSE se estima, y lo ideal sería que coincidiera con el MSE del conjunto de test, si para el conjunto de test ya teníamos 7 como mínimo error, para el conjunto de entrenamiento, si la estimación de MSE es buena, debería de ser el mismo mínimo error, o lo que es lo mismo, 7 también."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pregunta 8"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Dado el problema de clasificación Blood Transfusion Service Center, si se utiliza como método de selección de variables backward stepwise selection, ¿en qué orden se van eliminando las variables?\n",
    "\n",
    "Formato de la respuesta (si las variables se eliminan en el orden 0, 1, 3, 2): 0 1 3 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: {'std_err': 0.001376128970911626, 'avg_score': 0.77091788781628356, 'std_dev': 0.0027522579418232519, 'ci_bound': 0.0035374521374647587, 'feature_idx': (0,), 'cv_scores': array([ 0.76859504,  0.76666667,  0.77310924,  0.77310924,  0.77310924])}, 2: {'std_err': 0.01428022783780499, 'avg_score': 0.75919566173576869, 'std_dev': 0.028560455675609983, 'ci_bound': 0.036708494302581683, 'feature_idx': (0, 3), 'cv_scores': array([ 0.78512397,  0.70833333,  0.74789916,  0.78151261,  0.77310924])}, 3: {'std_err': 0.011961628886842551, 'avg_score': 0.77758548047318088, 'std_dev': 0.023923257773685105, 'ci_bound': 0.030748345952843648, 'feature_idx': (0, 1, 3), 'cv_scores': array([ 0.80165289,  0.73333333,  0.77310924,  0.78991597,  0.78991597])}, 4: {'std_err': 0.012131447963495893, 'avg_score': 0.7942668472347616, 'std_dev': 0.024262895926991785, 'ci_bound': 0.031184879786799412, 'feature_idx': (0, 1, 2, 3), 'cv_scores': array([ 0.82644628,  0.75833333,  0.78991597,  0.78151261,  0.81512605])}}\n"
     ]
    }
   ],
   "source": [
    "print(diccionario_metricas) #1 3 0 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pregunta 9"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Dado el siguiente conjunto de datos de clasificación con 6 observaciones, 3 variables de entrada y una variable de salida:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "\n",
    "<table cellspacing=\"0\" cellpadding=\"0\" border=\"1\">\n",
    " <tbody><tr>\n",
    "  <td valign=\"top\">\n",
    "  <p><span lang=\"ES\">Observación</span></p>\n",
    "  </td>\n",
    "  <td valign=\"top\">\n",
    "  <p align=\"center\"><span lang=\"ES\">X<sub>1</sub></span></p>\n",
    "  </td>\n",
    "  <td valign=\"top\">\n",
    "  <p align=\"center\"><span lang=\"ES\">X<sub>2</sub></span></p>\n",
    "  </td>\n",
    "  <td valign=\"top\">\n",
    "  <p align=\"center\"><span lang=\"ES\">X<sub>3</sub></span></p>\n",
    "  </td>\n",
    "  <td valign=\"top\">\n",
    "  <p align=\"center\"><span lang=\"ES\">Y</span></p>\n",
    "  </td>\n",
    " </tr>\n",
    " <tr>\n",
    "  <td valign=\"top\">\n",
    "  <p><span lang=\"ES\">1</span></p>\n",
    "  </td>\n",
    "  <td valign=\"top\">\n",
    "  <p align=\"center\"><span lang=\"ES\">0</span></p>\n",
    "  </td>\n",
    "  <td valign=\"top\">\n",
    "  <p align=\"center\"><span lang=\"ES\">3</span></p>\n",
    "  </td>\n",
    "  <td valign=\"top\">\n",
    "  <p align=\"center\"><span lang=\"ES\">2</span></p>\n",
    "  </td>\n",
    "  <td valign=\"top\">\n",
    "  <p align=\"center\"><span lang=\"ES\">1</span></p>\n",
    "  </td>\n",
    " </tr>\n",
    " <tr>\n",
    "  <td valign=\"top\">\n",
    "  <p><span lang=\"ES\">2</span></p>\n",
    "  </td>\n",
    "  <td valign=\"top\">\n",
    "  <p align=\"center\"><span lang=\"ES\">3</span></p>\n",
    "  </td>\n",
    "  <td valign=\"top\">\n",
    "  <p align=\"center\"><span lang=\"ES\">0</span></p>\n",
    "  </td>\n",
    "  <td valign=\"top\">\n",
    "  <p align=\"center\"><span lang=\"ES\">1</span></p>\n",
    "  </td>\n",
    "  <td valign=\"top\">\n",
    "  <p align=\"center\"><span lang=\"ES\">0</span></p>\n",
    "  </td>\n",
    " </tr>\n",
    " <tr>\n",
    "  <td valign=\"top\">\n",
    "  <p><span lang=\"ES\">3</span></p>\n",
    "  </td>\n",
    "  <td valign=\"top\">\n",
    "  <p align=\"center\"><span lang=\"ES\">0</span></p>\n",
    "  </td>\n",
    "  <td valign=\"top\">\n",
    "  <p align=\"center\"><span lang=\"ES\">3</span></p>\n",
    "  </td>\n",
    "  <td valign=\"top\">\n",
    "  <p align=\"center\"><span lang=\"ES\">-1</span></p>\n",
    "  </td>\n",
    "  <td valign=\"top\">\n",
    "  <p align=\"center\"><span lang=\"ES\">0</span></p>\n",
    "  </td>\n",
    " </tr>\n",
    " <tr>\n",
    "  <td valign=\"top\">\n",
    "  <p><span lang=\"ES\">4</span></p>\n",
    "  </td>\n",
    "  <td valign=\"top\">\n",
    "  <p align=\"center\"><span lang=\"ES\">3</span></p>\n",
    "  </td>\n",
    "  <td valign=\"top\">\n",
    "  <p align=\"center\"><span lang=\"ES\">0</span></p>\n",
    "  </td>\n",
    "  <td valign=\"top\">\n",
    "  <p align=\"center\"><span lang=\"ES\">-1</span></p>\n",
    "  </td>\n",
    "  <td valign=\"top\">\n",
    "  <p align=\"center\"><span lang=\"ES\">1</span></p>\n",
    "  </td>\n",
    " </tr>\n",
    " <tr>\n",
    "  <td valign=\"top\">\n",
    "  <p><span lang=\"ES\">5</span></p>\n",
    "  </td>\n",
    "  <td valign=\"top\">\n",
    "  <p align=\"center\"><span lang=\"ES\">1</span></p>\n",
    "  </td>\n",
    "  <td valign=\"top\">\n",
    "  <p align=\"center\"><span lang=\"ES\">2</span></p>\n",
    "  </td>\n",
    "  <td valign=\"top\">\n",
    "  <p align=\"center\"><span lang=\"ES\">1</span></p>\n",
    "  </td>\n",
    "  <td valign=\"top\">\n",
    "  <p align=\"center\"><span lang=\"ES\">1</span></p>\n",
    "  </td>\n",
    " </tr>\n",
    " <tr>\n",
    "  <td valign=\"top\">\n",
    "  <p><span lang=\"ES\">6</span></p>\n",
    "  </td>\n",
    "  <td valign=\"top\">\n",
    "  <p align=\"center\"><span lang=\"ES\">2</span></p>\n",
    "  </td>\n",
    "  <td valign=\"top\">\n",
    "  <p align=\"center\"><span lang=\"ES\">1</span></p>\n",
    "  </td>\n",
    "  <td valign=\"top\">\n",
    "  <p align=\"center\"><span lang=\"ES\">1</span></p>\n",
    "  </td>\n",
    "  <td valign=\"top\">\n",
    "  <p align=\"center\"><span lang=\"ES\">0</span></p>\n",
    "  </td>\n",
    " </tr>\n",
    "</tbody></table>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Suponiendo que se quiere hacer la predicción de la variable de salida para X1=0,  X2=0, X3=0 mediante KNN.\n",
    "Indica la predicción para K=3 y los ejemplos que producen dicha predicción (introduce los ejemplos ordenados por el número de observación). EN CASO DE EMPATE DEBES INCLUIR TODOS LOS EJEMPLOS QUE SE ENCUENTREN EN ESA SITUACIÓN.\n",
    "\n",
    "Ejemplo del formato de respuesta para clase 0 y ejemplos 4 y 5: 0 4 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.60555127546\n",
      "3.16227766017\n",
      "3.16227766017\n",
      "3.16227766017\n",
      "2.44948974278\n",
      "2.44948974278\n"
     ]
    }
   ],
   "source": [
    "puntos = []\n",
    "puntos.append(Punto(0,3,2))\n",
    "puntos.append(Punto(3,0,1))\n",
    "puntos.append(Punto(0,3,-1))\n",
    "puntos.append(Punto(3,0,-1))\n",
    "puntos.append(Punto(1,2,1))\n",
    "puntos.append(Punto(2,1,1))\n",
    "for punto in puntos:\n",
    "    print distanciaEuclides(puntoOrigen,punto)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Para K=3 los 5 vecinos más cercanos son el 5 y el 6 por una parte, y luego 2 3 4 por otra, en el primer caso como tanto la clase 0 como la 1 se encuentran a la misma distancia, escogemos por omisión la primera que es la 0. En el siguiente caso, como hay dos vecinos de la clase 0 por uno de la clase 1 nos quedamos también con la clase 0. Por tanto, si ordenamos, la respuesta sería 0 2 3 4 5 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pregunta 10"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Dado el problema de clasificación Blood Transfusion Service Center, ¿cuál es el mínimo error de entrenamiento con validación cruzada (5-CV)?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Idem que la pregunta 7 pero para este problema de clasificación el mínimo error de test era 0.2, si la estimación del MSE es buena, el mínimo error tiene que ser el mismo."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
