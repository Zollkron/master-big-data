{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boletines 1 y 2 (Ejercicios)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(x: 0, y: 0, z: 0)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "class Punto:\n",
    "    \n",
    "    def __init__(self, x,y,z):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.z = z\n",
    "        \n",
    "    def imprimirPunto(self):\n",
    "        print \"(x: \" + str(self.x) + \", y: \" + str(self.y) + \", z: \" + str(self.z) + \")\"\n",
    "\n",
    "def distanciaEuclides(punto1, punto2):\n",
    "    distancia = math.sqrt((punto2.x-punto1.x)**2+(punto2.y-punto1.y)**2+(punto2.z-punto1.z)**2)\n",
    "    return distancia\n",
    "\n",
    "puntoOrigen = Punto(0,0,0)\n",
    "puntoOrigen.imprimirPunto()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apartado a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.60555127546\n",
      "3.16227766017\n",
      "3.16227766017\n",
      "3.16227766017\n",
      "2.44948974278\n",
      "2.44948974278\n"
     ]
    }
   ],
   "source": [
    "puntos = []\n",
    "puntos.append(Punto(0,3,2))\n",
    "puntos.append(Punto(3,0,1))\n",
    "puntos.append(Punto(0,3,-1))\n",
    "puntos.append(Punto(3,0,-1))\n",
    "puntos.append(Punto(1,2,1))\n",
    "puntos.append(Punto(2,1,1))\n",
    "for punto in puntos:\n",
    "    print distanciaEuclides(puntoOrigen,punto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apartado b "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para K=1 la predicción sería del 50% de probabilidad de que el punto elegido sea Punto(1,2,1) y otro 50% de probabilidad de que el punto elegido sea Punto(2,1,1), ya que ambos puntos son los vecinos más próximos al punto de test Punto(0,0,0), ya que ambos se encuentran a la misma distancia euclídea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apartado c "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para K=3 la predicción sería el Punto(1,2,1) y Punto(2,1,1) de forma segura al ser los dos vecinos más próximos en distancia euclídea, y el tercer vecino más próximo sería con un 1/3 de probabilidad o bien Punto(3,0,1), o bien Punto(0,3,-1), o bien Punto(3,0,-1) ya que dichos 3 puntos serían los siguientes más próximos y están a la misma distancia euclídea los tres del punto de test Punto(0,0,0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apartado a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cuatro variables de entrada numéricas -> Recency (months),Frequency (times), Monetary (c.c. blood), y Time (months)\n",
    "- Una de salida booleana diciendo si sí o si no donó sangre en Marzo de 2007 -> \"whether he/she donated blood in March 2007\"\n",
    "- Hay 748 instancias.\n",
    "- Dos clases: Los que sí donaron en Marzo de 2007 y los que no. La distribución es 0 ó 1.\n",
    "- Se eliminan como valores perdidos los NaN (Not a Number), ya que las variables tienen que contener números válidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moises/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(748, 5)\n",
      "xRaw, y [[  2.00000000e+00   5.00000000e+01   1.25000000e+04   9.80000000e+01]\n",
      " [  0.00000000e+00   1.30000000e+01   3.25000000e+03   2.80000000e+01]\n",
      " [  1.00000000e+00   1.60000000e+01   4.00000000e+03   3.50000000e+01]\n",
      " ..., \n",
      " [  2.30000000e+01   3.00000000e+00   7.50000000e+02   6.20000000e+01]\n",
      " [  3.90000000e+01   1.00000000e+00   2.50000000e+02   3.90000000e+01]\n",
      " [  7.20000000e+01   1.00000000e+00   2.50000000e+02   7.20000000e+01]] [ 1.  1.  1.  1.  0.  0.  1.  0.  1.  1.  0.  0.  1.  0.  1.  1.  1.  1.\n",
      "  1.  1.  1.  0.  1.  1.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  0.  1.\n",
      "  1.  1.  1.  1.  1.  0.  1.  0.  1.  1.  0.  0.  0.  0.  0.  1.  0.  0.\n",
      "  1.  1.  1.  1.  0.  0.  0.  1.  0.  1.  1.  0.  1.  0.  0.  0.  0.  0.\n",
      "  1.  0.  1.  1.  1.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  1.\n",
      "  1.  0.  0.  0.  0.  0.  0.  1.  1.  1.  1.  1.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  0.  0.  1.  0.  0.  1.  0.  0.  1.  1.  1.  1.  1.  0.  0.\n",
      "  1.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  1.  0.  0.  1.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.\n",
      "  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.\n",
      "  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  0.  0.  0.  0.  0.  1.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.\n",
      "  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.\n",
      "  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  0.  0.  1.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.\n",
      "  1.  1.  1.  0.  1.  1.  1.  0.  0.  0.  1.  0.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  0.  0.  1.  0.  0.  1.  1.  1.  0.  0.  0.  1.  1.  1.  1.  1.\n",
      "  1.  0.  1.  1.  0.  1.  0.  0.  1.  1.  0.  1.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  1.\n",
      "  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.\n",
      "  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "mean, std [    9.50668449     5.51470588  1378.67647059    34.28208556] [    8.08998246     5.83540254  1458.85063437    24.36041432]\n",
      "Eliminate missing values: mean, std [    9.50668449     5.51470588  1378.67647059    34.28208556] [    8.08998246     5.83540254  1458.85063437    24.36041432]\n",
      "Data after x standardizing [[-0.92789873  7.62334626  7.62334626  2.61563344]\n",
      " [-1.17511806  1.28273826  1.28273826 -0.2578809 ]\n",
      " [-1.0515084   1.79684161  1.79684161  0.02947053]\n",
      " ..., \n",
      " [ 1.66790417 -0.43093957 -0.43093957  1.13782607]\n",
      " [ 3.64565877 -0.77367514 -0.77367514  0.19367135]\n",
      " [ 7.72477762 -0.77367514 -0.77367514  1.54832812]]\n",
      "mean, std [    9.50668449     5.51470588  1378.67647059    34.28208556] [    8.08998246     5.83540254  1458.85063437    24.36041432]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing, cross_validation, neighbors\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.externals import joblib\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "datasetName = 'bloodTransfusion.data'\n",
    "datasetDelimiter = ','\n",
    "\n",
    "# load the CSV file as a numpy matrix\n",
    "dataset = np.loadtxt(datasetName, delimiter=datasetDelimiter)\n",
    "print dataset.shape\n",
    "# separate the data from the target attributes\n",
    "xRaw = dataset[:,0:dataset.shape[1]-1]\n",
    "y = dataset[:,dataset.shape[1]-1]\n",
    "print \"xRaw, y\", xRaw, y\n",
    "print \"mean, std\", xRaw.mean(axis=0), xRaw.std(axis=0)\n",
    "# missing values\n",
    "imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "xPrep = imp.fit_transform(xRaw)\n",
    "print \"Eliminate missing values: mean, std\", xPrep.mean(axis=0), xPrep.std(axis=0)\n",
    "#Standardize data\n",
    "scaler = preprocessing.StandardScaler().fit(xPrep)\n",
    "x=scaler.transform(xPrep)\n",
    "print \"Data after x standardizing\", x\n",
    "print \"mean, std\", scaler.mean_, scaler.scale_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apartado b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la página web de la documentación oficial de Scikit-Learn para esta clase http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html podemos ver\n",
    "\n",
    "- Parámetros\n",
    "\n",
    "n_neighbors : int, optional (default = 5)\n",
    "\n",
    "    Number of neighbors to use by default for k_neighbors queries.\n",
    "\n",
    "weights : str or callable, optional (default = ‘uniform’)\n",
    "\n",
    "    weight function used in prediction. Possible values:\n",
    "\n",
    "        ‘uniform’ : uniform weights. All points in each neighborhood are weighted equally.\n",
    "        ‘distance’ : weight points by the inverse of their distance. in this case, closer neighbors of a query point will have a greater influence than neighbors which are further away.\n",
    "        [callable] : a user-defined function which accepts an array of distances, and returns an array of the same shape containing the weights.\n",
    "\n",
    "algorithm : {‘auto’, ‘ball_tree’, ‘kd_tree’, ‘brute’}, optional\n",
    "\n",
    "    Algorithm used to compute the nearest neighbors:\n",
    "\n",
    "        ‘ball_tree’ will use BallTree\n",
    "        ‘kd_tree’ will use KDTree\n",
    "        ‘brute’ will use a brute-force search.\n",
    "        ‘auto’ will attempt to decide the most appropriate algorithm based on the values passed to fit method.\n",
    "\n",
    "    Note: fitting on sparse input will override the setting of this parameter, using brute force.\n",
    "\n",
    "leaf_size : int, optional (default = 30)\n",
    "\n",
    "    Leaf size passed to BallTree or KDTree. This can affect the speed of the construction and query, as well as the memory required to store the tree. The optimal value depends on the nature of the problem.\n",
    "\n",
    "metric : string or DistanceMetric object (default = ‘minkowski’)\n",
    "\n",
    "    the distance metric to use for the tree. The default metric is minkowski, and with p=2 is equivalent to the standard Euclidean metric. See the documentation of the DistanceMetric class for a list of available metrics.\n",
    "\n",
    "p : integer, optional (default = 2)\n",
    "\n",
    "    Power parameter for the Minkowski metric. When p = 1, this is equivalent to using manhattan_distance (l1), and euclidean_distance (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.\n",
    "\n",
    "metric_params : dict, optional (default = None)\n",
    "\n",
    "    Additional keyword arguments for the metric function.\n",
    "\n",
    "n_jobs : int, optional (default = 1)\n",
    "\n",
    "    The number of parallel jobs to run for neighbors search. If -1, then the number of jobs is set to the number of CPU cores. Doesn’t affect fit method.\n",
    "\n",
    "- Métodos\n",
    "\n",
    "    - fit(X, y) \tFit the model using X as training data and y as target values\n",
    "    - get_params([deep]) \tGet parameters for this estimator.\n",
    "    - kneighbors([X, n_neighbors, return_distance]) \tFinds the K-neighbors of a point.\n",
    "    - kneighbors_graph([X, n_neighbors, mode]) \tComputes the (weighted) graph of k-Neighbors for points in X\n",
    "    - predict(X) \tPredict the class labels for the provided data\n",
    "    - predict_proba(X) \tReturn probability estimates for the test data X.\n",
    "    - score(X, y[, sample_weight]) \tReturns the mean accuracy on the given test data and labels.\n",
    "    - set_params(\\*\\*params) \tSet the parameters of this estimator.\n",
    "    - __init__(n_neighbors=5, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=1, **kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apartado c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xTrain [[-0.68067941  0.59726713  0.59726713  0.15262115]\n",
      " [-0.80428907 -0.08820401 -0.08820401 -0.91468418]\n",
      " [-0.92789873 -0.77367514 -0.77367514 -1.32518623]\n",
      " ..., \n",
      " [-0.30985042  0.9400027   0.9400027   2.2461816 ]\n",
      " [-0.80428907  0.42589934  0.42589934  0.64522361]\n",
      " [ 0.80263654 -0.25957179 -0.25957179 -0.05262988]] \n",
      "xTest [[-0.68067941 -0.43093957 -0.43093957 -0.2578809 ]\n",
      " [-0.92789873  0.9400027   0.9400027   0.27577176]\n",
      " [-0.92789873  0.08316378  0.08316378 -0.79153356]\n",
      " [-0.68067941  0.76863491  0.76863491 -0.2578809 ]\n",
      " [-0.92789873  6.08103621  6.08103621  2.61563344]\n",
      " [-0.92789873 -0.60230736 -0.60230736 -1.24308582]\n",
      " [ 0.55541721 -0.77367514 -0.77367514 -0.83258377]\n",
      " [-0.92789873 -0.60230736 -0.60230736 -1.24308582]\n",
      " [ 1.66790417 -0.43093957 -0.43093957  0.23472156]\n",
      " [-0.68067941  1.11137048  1.11137048 -0.01157967]\n",
      " [ 0.18458823  0.08316378  0.08316378  0.27577176]\n",
      " [ 0.55541721 -0.25957179 -0.25957179  0.15262115]\n",
      " [-0.92789873 -0.77367514 -0.77367514 -1.32518623]\n",
      " [-0.68067941  1.28273826  1.28273826  0.19367135]\n",
      " [-0.92789873  1.28273826  1.28273826  0.76837422]\n",
      " [ 1.66790417  0.42589934  0.42589934  1.4251775 ]\n",
      " [-0.18624076 -0.60230736 -0.60230736 -0.75048336]\n",
      " [ 1.42068485 -0.77367514 -0.77367514 -0.54523233]\n",
      " [ 0.55541721  0.25453156  0.25453156  1.54832812]\n",
      " [-0.68067941  0.42589934  0.42589934  0.23472156]\n",
      " [ 0.18458823  0.25453156  0.25453156  1.21992648]\n",
      " [ 0.18458823 -0.60230736 -0.60230736 -0.95573438]\n",
      " [ 0.18458823 -0.77367514 -0.77367514 -0.95573438]\n",
      " [-0.68067941 -0.77367514 -0.77367514 -1.24308582]\n",
      " [-0.43346009 -0.43093957 -0.43093957 -0.33998131]\n",
      " [ 0.55541721  0.42589934  0.42589934 -0.33998131]\n",
      " [-0.92789873 -0.77367514 -0.77367514 -1.32518623]\n",
      " [-0.68067941  2.31094497  2.31094497  1.4251775 ]\n",
      " [ 1.04985586 -0.60230736 -0.60230736 -0.46313192]\n",
      " [ 0.18458823  0.25453156  0.25453156  1.13782607]\n",
      " [-0.92789873  0.59726713  0.59726713 -0.50418213]\n",
      " [-0.68067941 -0.60230736 -0.60230736 -0.13473028]\n",
      " [ 3.52204911 -0.77367514 -0.77367514  0.15262115]\n",
      " [-0.68067941  0.08316378  0.08316378  0.02947053]\n",
      " [-0.92789873 -0.43093957 -0.43093957  1.75357914]\n",
      " [-0.68067941 -0.77367514 -0.77367514 -1.24308582]\n",
      " [ 0.80263654 -0.77367514 -0.77367514 -0.75048336]\n",
      " [-0.68067941  1.45410605  1.45410605  2.12303099]\n",
      " [-0.30985042 -0.60230736 -0.60230736 -0.75048336]\n",
      " [ 0.80263654 -0.77367514 -0.77367514 -0.75048336]\n",
      " [ 0.18458823 -0.60230736 -0.60230736 -0.95573438]\n",
      " [ 0.06097856 -0.08820401 -0.08820401  0.15262115]\n",
      " [-0.68067941 -0.77367514 -0.77367514 -1.24308582]\n",
      " [-1.17511806  1.28273826  1.28273826 -0.2578809 ]\n",
      " [ 0.18458823 -0.25957179 -0.25957179  0.97362525]\n",
      " [ 0.55541721 -0.08820401 -0.08820401  1.63042853]\n",
      " [-0.68067941  0.08316378  0.08316378  0.48102279]\n",
      " [ 0.55541721 -0.60230736 -0.60230736 -0.83258377]\n",
      " [-0.80428907  1.45410605  1.45410605  0.02947053]\n",
      " [ 0.18458823  0.42589934  0.42589934  0.27577176]\n",
      " [ 1.42068485 -0.43093957 -0.43093957 -0.33998131]\n",
      " [-0.0626311   0.42589934  0.42589934  0.15262115]\n",
      " [ 0.18458823 -0.60230736 -0.60230736 -0.83258377]\n",
      " [ 0.18458823 -0.77367514 -0.77367514 -0.95573438]\n",
      " [ 0.80263654 -0.08820401 -0.08820401  0.23472156]\n",
      " [-0.92789873  0.42589934  0.42589934  0.15262115]\n",
      " [-0.68067941 -0.60230736 -0.60230736  0.48102279]\n",
      " [ 0.18458823 -0.08820401 -0.08820401 -0.66838295]\n",
      " [ 0.18458823 -0.08820401 -0.08820401  0.64522361]\n",
      " [ 0.55541721 -0.60230736 -0.60230736 -0.83258377]\n",
      " [-0.68067941 -0.08820401 -0.08820401  0.97362525]\n",
      " [-0.92789873 -0.77367514 -0.77367514 -1.32518623]\n",
      " [-0.92789873  0.08316378  0.08316378 -0.2578809 ]\n",
      " [-0.92789873  1.11137048  1.11137048  1.46622771]\n",
      " [-0.68067941 -0.77367514 -0.77367514 -1.24308582]\n",
      " [-0.68067941 -0.77367514 -0.77367514 -1.24308582]\n",
      " [ 0.55541721 -0.60230736 -0.60230736 -0.83258377]\n",
      " [ 0.55541721 -0.60230736 -0.60230736 -0.83258377]\n",
      " [ 1.66790417 -0.60230736 -0.60230736  2.16408119]\n",
      " [-1.17511806  3.51051945  3.51051945  1.71252894]\n",
      " [ 1.66790417  1.62547383  1.62547383  0.93257504]\n",
      " [ 0.18458823  0.59726713  0.59726713  1.54832812]\n",
      " [-0.92789873 -0.77367514 -0.77367514 -1.32518623]\n",
      " [-0.92789873  0.08316378  0.08316378  0.43997258]\n",
      " [-0.68067941 -0.60230736 -0.60230736  0.27577176]\n",
      " [-0.68067941 -0.77367514 -0.77367514 -1.24308582]\n",
      " [ 0.55541721 -0.08820401 -0.08820401 -0.83258377]\n",
      " [ 0.80263654 -0.60230736 -0.60230736 -0.75048336]\n",
      " [-0.92789873  1.62547383  1.62547383  1.21992648]\n",
      " [-0.92789873  0.08316378  0.08316378 -0.33998131]\n",
      " [-0.92789873  0.08316378  0.08316378 -0.79153356]\n",
      " [ 0.18458823  1.9682094   1.9682094   1.83567955]\n",
      " [-0.92789873 -0.08820401 -0.08820401 -0.33998131]\n",
      " [-0.92789873 -0.43093957 -0.43093957  0.72732402]\n",
      " [-0.92789873 -0.08820401 -0.08820401 -0.75048336]\n",
      " [-0.92789873  0.9400027   0.9400027   0.48102279]\n",
      " [-0.68067941 -0.77367514 -0.77367514 -1.24308582]\n",
      " [-0.92789873  0.08316378  0.08316378 -0.2578809 ]\n",
      " [ 1.66790417 -0.43093957 -0.43093957 -0.2578809 ]\n",
      " [ 7.97199695 -0.77367514 -0.77367514  1.63042853]\n",
      " [ 0.80263654 -0.25957179 -0.25957179 -0.2578809 ]\n",
      " [ 3.15122012 -0.43093957 -0.43093957  1.21992648]\n",
      " [-0.68067941  2.9964161   2.9964161   0.97362525]\n",
      " [-0.68067941  0.25453156  0.25453156 -0.38103151]\n",
      " [-0.92789873  6.42377178  6.42377178  2.12303099]\n",
      " [-0.92789873  0.9400027   0.9400027   0.23472156]\n",
      " [-0.92789873  0.9400027   0.9400027  -0.33998131]\n",
      " [ 1.66790417  0.25453156  0.25453156  2.2051314 ]\n",
      " [-0.30985042  1.45410605  1.45410605  0.5631232 ]\n",
      " [-0.92789873 -0.77367514 -0.77367514 -1.32518623]\n",
      " [-0.68067941 -0.08820401 -0.08820401 -0.75048336]\n",
      " [ 0.55541721  2.13957718  2.13957718  1.79462935]\n",
      " [-0.80428907 -0.60230736 -0.60230736 -0.46313192]\n",
      " [-0.43346009 -0.60230736 -0.60230736 -0.95573438]\n",
      " [ 0.55541721 -0.77367514 -0.77367514 -0.83258377]\n",
      " [ 0.18458823 -0.25957179 -0.25957179  1.01467545]\n",
      " [ 1.66790417 -0.77367514 -0.77367514 -0.46313192]\n",
      " [-0.92789873 -0.60230736 -0.60230736 -0.95573438]\n",
      " [-0.68067941  0.25453156  0.25453156 -0.09368008]\n",
      " [ 1.9151235   0.08316378  0.08316378  0.64522361]\n",
      " [-0.92789873 -0.77367514 -0.77367514 -1.32518623]\n",
      " [ 1.42068485 -0.77367514 -0.77367514 -0.54523233]\n",
      " [ 0.55541721  0.08316378  0.08316378  0.68627381]\n",
      " [ 0.55541721 -0.77367514 -0.77367514 -0.83258377]\n",
      " [ 0.18458823  0.9400027   0.9400027   0.15262115]\n",
      " [ 1.42068485 -0.08820401 -0.08820401  1.05572566]\n",
      " [-0.92789873 -0.25957179 -0.25957179 -0.75048336]\n",
      " [-0.92789873 -0.60230736 -0.60230736 -1.32518623]\n",
      " [ 1.42068485 -0.77367514 -0.77367514 -0.54523233]\n",
      " [ 1.66790417 -0.43093957 -0.43093957  2.2461816 ]\n",
      " [-0.92789873  0.08316378  0.08316378  0.27577176]\n",
      " [-0.68067941  0.59726713  0.59726713  0.72732402]\n",
      " [ 0.43180755 -0.43093957 -0.43093957 -0.83258377]\n",
      " [ 1.66790417 -0.25957179 -0.25957179  0.43997258]\n",
      " [-0.68067941  0.08316378  0.08316378 -0.75048336]\n",
      " [ 0.18458823 -0.60230736 -0.60230736 -0.54523233]\n",
      " [-0.92789873 -0.60230736 -0.60230736 -1.32518623]\n",
      " [-0.68067941 -0.77367514 -0.77367514 -1.24308582]\n",
      " [ 0.80263654  1.79684161  1.79684161  1.75357914]\n",
      " [ 0.80263654  0.25453156  0.25453156 -0.2578809 ]\n",
      " [ 0.18458823  0.9400027   0.9400027   0.31682197]\n",
      " [-0.68067941 -0.43093957 -0.43093957 -0.75048336]\n",
      " [-0.92789873 -0.25957179 -0.25957179 -0.75048336]\n",
      " [-0.92789873 -0.43093957 -0.43093957 -1.03783479]\n",
      " [ 0.18458823  0.42589934  0.42589934  0.72732402]\n",
      " [-0.92789873  0.08316378  0.08316378 -0.50418213]\n",
      " [ 1.66790417 -0.43093957 -0.43093957  0.5631232 ]\n",
      " [ 1.42068485 -0.43093957 -0.43093957 -0.33998131]\n",
      " [ 1.66790417 -0.60230736 -0.60230736 -0.2578809 ]\n",
      " [-0.0626311  -0.77367514 -0.77367514 -1.03783479]\n",
      " [-0.30985042  0.76863491  0.76863491  0.52207299]\n",
      " [ 0.55541721 -0.25957179 -0.25957179 -0.33998131]\n",
      " [ 0.06097856 -0.25957179 -0.25957179 -0.75048336]\n",
      " [ 0.18458823  0.59726713  0.59726713  0.15262115]\n",
      " [-1.0515084   0.25453156  0.25453156  0.93257504]\n",
      " [-0.68067941 -0.77367514 -0.77367514 -1.24308582]\n",
      " [-0.68067941 -0.25957179 -0.25957179 -0.33998131]\n",
      " [ 1.42068485 -0.43093957 -0.43093957  0.02947053]\n",
      " [ 0.18458823 -0.08820401 -0.08820401  0.02947053]\n",
      " [ 0.80263654 -0.77367514 -0.77367514 -0.75048336]] \n",
      "yTrain [ 1.  1.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.  0.  0.\n",
      "  1.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  0.  1.  1.  0.  0.  1.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.\n",
      "  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  1.  0.\n",
      "  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  1.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  1.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  1.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.\n",
      "  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.\n",
      "  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.\n",
      "  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.\n",
      "  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  0.  0.  0.  1.\n",
      "  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.\n",
      "  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  0.  1.  0.  1.  1.  0.\n",
      "  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  1.  0.  1.  0.  1.  1.  0.  0.  1.  0.  1.  1.  1.  0.  0.\n",
      "  0.  1.  1.  0.  1.  0.  0.  1.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  0.  1.  0.  1.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.\n",
      "  1.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.  0.\n",
      "  0.  1.  0.  1.  0.  1.  1.  1.  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  0.  1.\n",
      "  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  1.  0.\n",
      "  0.  0.  1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  0.\n",
      "  0.  1.  0.  1.  0.  1.  1.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  1.\n",
      "  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.\n",
      "  0.  0.  0.  0.] \n",
      "yTest [ 0.  1.  1.  1.  1.  0.  0.  1.  0.  1.  0.  0.  0.  1.  1.  0.  0.  0.\n",
      "  0.  1.  0.  0.  1.  0.  0.  0.  0.  1.  0.  1.  1.  0.  0.  1.  0.  1.\n",
      "  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.\n",
      "  1.  1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  1.  0.  1.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  0.  1.  0.  0.\n",
      "  0.  0.  0.  0.  1.  1.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.  0.  1.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.\n",
      "  0.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "#Divide in training and test, shuffling the examples and keeping the proportion of examples of each class\n",
    "xTrain, xTest, yTrain, yTest = cross_validation.train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "print 'xTrain', xTrain, \"\\nxTest\", xTest, \"\\nyTrain\", yTrain, \"\\nyTest\", yTest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apartado d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"one standard error rule\" is applied when selecting models through cross-validation (or more generally through any randomization-based procedure).\n",
    "\n",
    "Assume we consider models Mτ\n",
    "indexed by a complexity parameter τ∈ℝ, such that Mτ is \"more complex\" than Mτ′ exactly when τ>τ′. Assume further that we assess the quality of a model M by some randomization process, e.g., cross-validation. Let q(M) denote the \"average\" quality of M\n",
    "\n",
    ", e.g., the mean out-of-bag prediction error across many cross-validation runs. We wish to minimize this quantity.\n",
    "\n",
    "However, since our quality measure comes from some randomization procedure, it comes with variability. Let s(M)\n",
    "denote the standard error of the quality of M across the randomization runs, e.g., the standard deviation of the out-of-bag prediction error of M\n",
    "\n",
    "over cross-validation runs.\n",
    "\n",
    "Then we choose the model Mτ\n",
    ", where τ is the smallest τ\n",
    "\n",
    "such that\n",
    "\n",
    "q(Mτ)≤q(Mτ′)+s(Mτ′),\n",
    "\n",
    "where τ′\n",
    "indexes the (on average) best model, q(Mτ′)=minτq(Mτ)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters Cross-Validation {'n_neighbors': 4, 'weights': 'uniform'}\n",
      "0.719 (+/-0.026) for {'n_neighbors': 1, 'weights': 'uniform'}\n",
      "()\n",
      "0.719 (+/-0.026) for {'n_neighbors': 1, 'weights': 'distance'}\n",
      "()\n",
      "0.768 (+/-0.021) for {'n_neighbors': 2, 'weights': 'uniform'}\n",
      "()\n",
      "0.729 (+/-0.034) for {'n_neighbors': 2, 'weights': 'distance'}\n",
      "()\n",
      "0.751 (+/-0.018) for {'n_neighbors': 3, 'weights': 'uniform'}\n",
      "()\n",
      "0.739 (+/-0.020) for {'n_neighbors': 3, 'weights': 'distance'}\n",
      "()\n",
      "0.771 (+/-0.031) for {'n_neighbors': 4, 'weights': 'uniform'}\n",
      "()\n",
      "0.746 (+/-0.028) for {'n_neighbors': 4, 'weights': 'distance'}\n",
      "()\n",
      "Para los scores de test del CV [7, 7, 2, 6, 3, 5, 1, 4] el mejor ranking es 1 y pertenece al pliegue cuyo n_vecinos es 4 y su peso uniform\n",
      "0.740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moises/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "/home/moises/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "/home/moises/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg0AAAFdCAYAAACAfl7+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxNAgSZKKGBokSVIRQ4MkSSry/wFuCCX0r/yfTQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbb47de0d10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg0AAAFdCAYAAACAfl7+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSSpiaJAkSUUMDZIkqYihQZIkFfkfz7x0tIejfhgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbb07977d10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La estimacion de CV-5 era 0.740 y el resultado del test es 0.740\n"
     ]
    }
   ],
   "source": [
    "hyperParams = {'n_neighbors': range(1,5),\n",
    "               'weights': ['uniform', 'distance']}\n",
    "\n",
    "#Create an instance of Neighbors Classifier and fit the data for the grid parameters\n",
    "modelCV = GridSearchCV(neighbors.KNeighborsClassifier(), \n",
    "                     hyperParams, cv=5, scoring='accuracy')\n",
    "modelCV.fit(xTrain, yTrain)\n",
    "print \"Best hyperparameters Cross-Validation\", modelCV.best_params_\n",
    "neighList, errList, devList = [], [], []\n",
    "i = 0\n",
    "for hyperP, mean_score, scores in modelCV.grid_scores_:\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean_score, scores.std(), hyperP))\n",
    "    if hyperP['weights'] == modelCV.best_params_['weights']:\n",
    "        neighList.append(hyperP['n_neighbors'])\n",
    "        errList.append(mean_score)\n",
    "        devList.append(scores.std())\n",
    "    print()    \n",
    "\n",
    "#Ahora comprobamos con los demás resultados entre los que se haya el vector de ranking (scikit-learn v0.18.1)\n",
    "\n",
    "#print \"Resultados:\", modelCV.cv_results_\n",
    "oserList = list(modelCV.cv_results_['rank_test_score'])\n",
    "#Escogemos el que mejor ranking que normalmente será 1\n",
    "regla_un_error_estandar = min(oserList)\n",
    "#Nos quedamos con el primer índice que cumpla la regla\n",
    "indice = [i for i,x in enumerate(oserList) if x == regla_un_error_estandar][0] \n",
    "vecinos = modelCV.grid_scores_[indice][0]['n_neighbors']\n",
    "#print(vecinos)\n",
    "peso = modelCV.grid_scores_[indice][0]['weights']\n",
    "#print(peso)\n",
    "print(\"Para los scores de test del CV %r el mejor ranking es %i y pertenece al pliegue cuyo n_vecinos es %i y su peso %s\" \n",
    "      % (oserList, regla_un_error_estandar, vecinos, peso))\n",
    "#Según la teoría vista en clase (transparencias 23 y 25 del tema 1) debería de escoger el pliegue que \n",
    "#cumpla con la regla 'one-standar-error-rule'. Scikit-Learn ya nos facilita un vector con el ranking de los\n",
    "#mejores test scores.\n",
    "\n",
    "#Aplicamos la regla para quedarnos el mínimo t (esa será nuestra estimación del error de test del CV)\n",
    "estimacionCV = list(modelCV.cv_results_['mean_test_score'])[indice]-list(modelCV.cv_results_['std_test_score'])[indice]\n",
    "print(\"%0.3f\" % estimacionCV)\n",
    "\n",
    "#De entre todos los pliegues de la validación cruzada, elige como mejores hiperparámetros el pliegue\n",
    "#cuyo número de vecinos es 4 y su peso es uniforme con el score 0.771, y desviación estándar de +/- 0.031,\n",
    "#el cual como hemos podido ver es el que mejor ranking de test scores tiene.\n",
    "plt.errorbar(neighList, errList, yerr = devList)\n",
    "plt.xlim(neighList[0]-1, neighList[len(neighList)-1]+1)\n",
    "plt.ylim(errList[0]-0.1, errList[len(errList)-1]+0.1)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "model = neighbors.KNeighborsClassifier(n_neighbors = modelCV.best_params_['n_neighbors'], \n",
    "                                       weights = modelCV.best_params_['weights'])\n",
    "model.fit(xTrain, yTrain)\n",
    "precision_media = model.score(xTest,yTest)\n",
    "\n",
    "plt.errorbar(neighList, errList, yerr = devList)\n",
    "plt.xlim(neighList[0]-1, neighList[len(neighList)-1]+1)\n",
    "plt.ylim(errList[0]-0.1, errList[len(errList)-1]+0.1)\n",
    "plt.plot(modelCV.best_params_['n_neighbors'], precision_media, 'ro')\n",
    "plt.show()\n",
    "print(\"La estimacion de CV-5 era %0.3f y el resultado del test es %0.3f\" % (estimacionCV, precision_media))\n",
    "#Podemos observar que la estimación de la Validación Cruzada de 5 pliegues ha sido realmente buena \n",
    "#ya que acierta de pleno, aparte de estar dentro del rango (0.740,0.802)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apartado a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('N. de vecinos ', 4, ' y N. de Variables ', 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[2017-06-08 02:19:12] Features: 1/4 -- score: 0.762639650902\n",
      "[2017-06-08 02:19:12] Features: 2/4 -- score: 0.754110702132\n",
      "[2017-06-08 02:19:12] Features: 3/4 -- score: 0.772529689562\n",
      "[2017-06-08 02:19:12] Features: 4/4 -- score: 0.770835011691"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.763 (+/-0.015) para 1 variables seleccionadas\n",
      "0.754 (+/-0.026) para 2 variables seleccionadas\n",
      "0.773 (+/-0.035) para 3 variables seleccionadas\n",
      "0.771 (+/-0.031) para 4 variables seleccionadas\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg0AAAFdCAYAAACAfl7+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbb078e7310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "\n",
    "#Tal y como nos pide el ejercicio escogemos el mejor parámetro de número de vecinos del ejercicio 2\n",
    "vecinos = modelCV.best_params_['n_neighbors'] \n",
    "variables = 4\n",
    "#Cuatro variables de entrada numéricas -> Recency (months),Frequency (times), Monetary (c.c. blood), y Time (months)\n",
    "print(\"N. de vecinos \", vecinos, \" y N. de Variables \", variables)\n",
    "\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=vecinos)\n",
    "\n",
    "sfs1 = SFS(knn, \n",
    "           k_features=variables, \n",
    "           forward=True, \n",
    "           floating=False, \n",
    "           verbose=2,\n",
    "           scoring='accuracy',\n",
    "           cv=5)\n",
    "\n",
    "sfs1 = sfs1.fit(xTrain, yTrain)\n",
    "diccionario_metricas = sfs1.get_metric_dict(confidence_interval=0.95)\n",
    "varList, errList, devList = [], [], []\n",
    "for i in range(1,len(diccionario_metricas)+1):\n",
    "    puntuacion_media = diccionario_metricas[i]['avg_score']\n",
    "    desviacion_estandar = diccionario_metricas[i]['std_dev']\n",
    "    num_variables_usadas = len(diccionario_metricas[i]['feature_idx'])\n",
    "    print(\"%0.3f (+/-%0.03f) para %i variables seleccionadas\"\n",
    "              % (puntuacion_media, desviacion_estandar, num_variables_usadas))\n",
    "    varList.append(num_variables_usadas)\n",
    "    errList.append(puntuacion_media)\n",
    "    devList.append(desviacion_estandar)\n",
    "    #marcamos el error de test del ejercicio 2 en este paso (Así aprovechamos la misma figura de plot)\n",
    "    plt.plot(num_variables_usadas, precision_media, 'ro')\n",
    "    plt.text(num_variables_usadas, precision_media, str(precision_media))\n",
    "#El paso que cumple la regla 'one-standar-error-rule' es el de 4 variables, porque coincide con lo visto en el\n",
    "#ejercicio anterior al respecto.\n",
    "plt.errorbar(varList, errList, yerr = devList)\n",
    "plt.xlim(varList[0]-1, varList[len(varList)-1]+1)\n",
    "plt.ylim(errList[0]-0.1, errList[len(errList)-1]+0.1)\n",
    "plt.show()\n",
    "#Podemos observar que efectivamente para 4 variables seleccionadas, tanto la estimación como la desviación estándar \n",
    "#son exctamente las mismas que en la Validación Cruzada de 5 pliegues del ejercicio anterior que nos daba como\n",
    "#mejor pliegue el de 4 Vecinos y peso Uniforme del ejercicio y que finalmente fue elegida como la mejor estimación \n",
    "#del error. Es decir, score 0.771 y desviación +/- 0.031 que con la regla del mínimo t sería 0.740.\n",
    "\n",
    "#NOTA: Al poner como marcadores la estimación del error del test hecho en el ejercicio anterior no hace falta \n",
    "#'plottear' de nuevo una nueva figura, en la misma figura se puede hacer la comparativa. Podemos ver que el punto\n",
    "#está exactamente en el 0.740 estimado.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apartado b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('La ultima clave es ', 4, ' y ?hay solo un paso? ', True)\n",
      "0.771 (+/-0.031) para 4 variables seleccionadas\n",
      "('No hay paso ', 3, ' en la seleccion hacia atras porque el algoritmo de seleccion ya habia parado.')\n",
      "('No hay paso ', 2, ' en la seleccion hacia atras porque el algoritmo de seleccion ya habia parado.')\n",
      "('No hay paso ', 1, ' en la seleccion hacia atras porque el algoritmo de seleccion ya habia parado.')\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhQAAAFdCAYAAABbxfTcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBQDQTVAAAN0EBQDQTVAAAN0EBQDQ7f8B9itbHJ4nUHgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbb078c4ed0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Según la documentación esta misma función poniendo forward a 'False' hace la selección hacia atrás:\n",
    "#forward : bool (default: True) Forward selection if True, backward selection otherwise\n",
    "#Así que la volvemos a reutilizar eso sí creándonos otro objeto sfs\n",
    "sfs2 = SFS(knn, \n",
    "           k_features=variables, \n",
    "           forward=False,   \n",
    "           floating=False, \n",
    "           verbose=2,\n",
    "           scoring='accuracy',\n",
    "           cv=5)\n",
    "\n",
    "sfs2 = sfs2.fit(xTrain, yTrain)\n",
    "diccionario_metricas = sfs2.get_metric_dict(confidence_interval=0.95)\n",
    "\n",
    "claves = diccionario_metricas.keys()\n",
    "un_solo_paso = False\n",
    "if(len(claves)==1):\n",
    "    ultima_clave = claves[0]\n",
    "    un_solo_paso = True\n",
    "else:\n",
    "    ultima_clave = claves[len(claves)-1]\n",
    "print(\"La ultima clave es \", ultima_clave, \" y ?hay solo un paso? \", un_solo_paso)\n",
    "\n",
    "varList, errList, devList = [], [], []\n",
    "#Ahora vamos hacia atrás, pero como ya sabemos de antemano que ya se va a quedar con el de 4 variables como la \n",
    "#mejor estimación, el algoritmo ya se paró en el primer paso, por lo que sólo tenemos un paso y con el fin \n",
    "#de evitar el error 'KeyError' se hace un control de excepciones\n",
    "for i in range(ultima_clave,0,-1):\n",
    "    try:\n",
    "        puntuacion_media = diccionario_metricas[i]['avg_score']\n",
    "        desviacion_estandar = diccionario_metricas[i]['std_dev']\n",
    "        num_variables_usadas = len(diccionario_metricas[i]['feature_idx'])\n",
    "        print(\"%0.3f (+/-%0.03f) para %i variables seleccionadas\"\n",
    "                  % (puntuacion_media, desviacion_estandar, num_variables_usadas))\n",
    "        varList.append(num_variables_usadas)\n",
    "        errList.append(puntuacion_media)\n",
    "        devList.append(desviacion_estandar)\n",
    "        #marcamos el error de test del ejercicio 2 en este paso (Así aprovechamos la misma figura de plot)\n",
    "        plt.plot(num_variables_usadas, precision_media, 'ro')\n",
    "        plt.text(num_variables_usadas, precision_media, str(precision_media))\n",
    "    except KeyError:\n",
    "        print(\"No hay paso \", i, \" en la seleccion hacia atras porque el algoritmo de seleccion ya habia parado.\")\n",
    "plt.errorbar(varList, errList, yerr = devList)\n",
    "plt.xlim(varList[0]-1, varList[len(varList)-1]+1)\n",
    "plt.ylim(errList[0]-0.1, errList[len(errList)-1]+0.1)\n",
    "plt.show()\n",
    "#Lo primero que podemos apreciar es que efectivamente el algoritmo de selección hacia atrás ya toma como mejor\n",
    "#estimación la de 4 variables, para y ya no sigue, porque no tiene sentido de que lo haga, ya que tanto la \n",
    "#estimación como la desviación estándar son exctamente las mismas que las del Apartado a) de este ejercicio\n",
    "#y, además, las mimas que en la Validación Cruzada de 5 pliegues del ejercicio anterior que nos daba como\n",
    "#mejor pliegue el de 4 Vecinos y peso Uniforme, y que finalmente fue elegida como la mejor estimación \n",
    "#del error con t mínimo de 0.740. Es decir, score 0.771 y desviación +/- 0.031. Y cómo ya sabíamos que \n",
    "#éste era el modelo seleccionado porque era el que cumplía con la regla 'one-standard-error-rule', \n",
    "#podemos concluir que la estimación nuevamente ha sido muy buena, ya que acierta.\n",
    "\n",
    "#Cabe reseñar que al ir hacia atrás sólo ha habido un paso. Como ya sabemos scikit-learn internamente hace un\n",
    "#rank para cada combinación, si el rank que tiene ésta ya es 1, es que ya el mejor rank de todos, de modo que\n",
    "#ya no hace falta que siga ejecutándose el algoritmo de selección.\n",
    "\n",
    "#NOTA: Al poner como marcador la estimción del error del test hecho en el ejercicio anterior no hace falta \n",
    "#'plottear' de nuevo una nueva figura, en la misma figura se puede hacer la comparativa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apartado a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ocho variables de entrada numéricas -> X1,X2,X3,X4,X5,X6,X7,X8\n",
    "- Una de salida de valor real -> Y2\n",
    "- Hay 768 instancias.\n",
    "- No hay clases ya que es un problema de regresión y NO de clasificación.\n",
    "- Se eliminan como valores perdidos los NaN (Not a Number), ya que las variables tienen que contener números válidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n",
      "xRaw, y [[  9.80000000e-01   5.14500000e+02   2.94000000e+02 ...,   2.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  9.80000000e-01   5.14500000e+02   2.94000000e+02 ...,   3.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  9.80000000e-01   5.14500000e+02   2.94000000e+02 ...,   4.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " ..., \n",
      " [  6.20000000e-01   8.08500000e+02   3.67500000e+02 ...,   3.00000000e+00\n",
      "    4.00000000e-01   5.00000000e+00]\n",
      " [  6.20000000e-01   8.08500000e+02   3.67500000e+02 ...,   4.00000000e+00\n",
      "    4.00000000e-01   5.00000000e+00]\n",
      " [  6.20000000e-01   8.08500000e+02   3.67500000e+02 ...,   5.00000000e+00\n",
      "    4.00000000e-01   5.00000000e+00]] [ 21.33  21.33  21.33  21.33  28.28  25.38  25.16  29.6   27.3   21.97\n",
      "  23.49  27.87  23.77  21.46  21.16  24.93  37.73  31.27  30.93  39.44\n",
      "  29.79  29.68  29.79  29.4   10.9   11.19  10.94  11.17  11.27  11.72\n",
      "  11.29  11.67  11.74  12.05  11.73  11.93  12.4   12.23  12.4   12.14\n",
      "  16.78  16.8   16.75  16.67  12.07  12.22  12.08  12.04  26.47  26.37\n",
      "  26.44  26.29  32.92  29.87  29.58  34.33  30.89  25.6   27.03  31.73\n",
      "  27.31  24.91  24.61  28.51  41.68  35.28  34.43  43.33  33.87  34.07\n",
      "  34.14  33.67  13.43  13.71  13.48  13.7   13.8   14.28  13.87  14.27\n",
      "  14.28  14.61  14.3   14.45  13.9   13.72  13.88  13.65  19.37  19.43\n",
      "  19.34  19.32  14.34  14.5   14.33  14.27  25.95  25.63  26.13  25.89\n",
      "  32.54  29.44  29.36  34.2   30.91  25.63  27.36  31.9   27.38  25.02\n",
      "  24.8   28.79  41.07  34.62  33.87  42.86  33.91  34.07  34.17  33.78\n",
      "  13.39  13.72  13.57  13.79  13.67  14.11  13.8   14.21  13.2   13.54\n",
      "  13.32  13.51  14.86  14.75  15.    14.74  19.23  19.34  19.32  19.3\n",
      "  14.37  14.57  14.27  14.24  25.68  26.02  25.84  26.14  34.14  32.85\n",
      "  30.08  29.67  31.73  31.01  25.9   27.4   28.68  27.54  25.35  24.93\n",
      "  43.12  41.22  35.1   34.29  33.85  34.11  34.48  34.5   13.6   13.36\n",
      "  13.65  13.49  14.14  13.77  14.3   13.87  14.44  14.27  14.67  14.4\n",
      "  13.46  13.7   13.59  13.83  19.14  19.18  19.37  19.29  14.09  14.23\n",
      "  14.14  13.89  25.91  25.72  26.18  25.87  29.34  33.91  32.83  29.92\n",
      "  27.17  31.76  31.06  25.81  24.61  28.61  27.57  25.16  34.25  43.3\n",
      "  41.86  35.29  34.11  33.62  33.89  34.05  13.2   13.36  13.21  13.53\n",
      "  13.67  14.12  13.79  14.2   14.29  14.49  14.42  14.73  14.86  14.67  15.\n",
      "  14.83  19.24  19.25  19.42  19.48  14.37  14.34  14.28  14.47  25.64\n",
      "  25.98  25.88  26.18  29.82  29.52  34.45  33.01  25.82  27.33  32.04\n",
      "  31.28  25.11  24.77  28.88  27.69  34.99  34.18  43.14  41.26  34.25\n",
      "  34.35  33.64  33.88  13.65  13.44  13.72  13.5   14.18  13.75  14.26\n",
      "  13.89  14.55  14.28  14.46  14.39  14.54  14.81  14.65  14.87  19.24\n",
      "  19.18  19.26  19.29  14.24  13.97  13.99  14.15  29.79  29.79  29.28\n",
      "  29.49  36.12  33.17  32.71  37.58  33.98  28.61  30.12  34.73  30.17\n",
      "  27.84  27.25  31.39  43.8   37.81  36.85  45.52  36.85  37.58  37.45\n",
      "  36.62  15.19  15.5   15.28  15.5   15.42  15.85  15.44  15.81  15.21\n",
      "  15.63  15.48  15.78  16.39  16.27  16.39  16.19  21.13  21.19  21.09\n",
      "  21.08  15.77  15.95  15.77  15.76  29.62  29.69  30.18  30.02  35.56\n",
      "  32.64  32.77  37.72  33.37  27.89  29.9   34.52  28.27  26.96  26.72\n",
      "  29.88  43.86  37.41  36.77  45.97  36.87  37.35  37.28  36.81  14.73\n",
      "  15.1   15.18  15.44  14.91  15.4   14.94  15.32  15.52  15.85  15.66\n",
      "  15.99  15.89  15.85  16.22  15.87  20.47  20.56  20.48  20.43  15.32\n",
      "  15.64  15.14  15.3   29.43  29.78  30.1   30.19  36.35  35.1   32.83\n",
      "  32.46  33.52  32.93  28.38  29.82  28.77  27.76  26.95  26.41  45.13\n",
      "  43.66  37.76  36.87  36.07  36.44  37.28  37.29  14.49  13.79  14.72\n",
      "  14.76  14.92  14.74  15.57  14.94  14.92  14.38  15.44  15.17  15.53\n",
      "  15.8   16.14  16.26  19.87  20.03  20.46  20.28  14.89  14.96  14.89\n",
      "  14.35  29.61  29.59  30.19  30.12  32.12  37.12  36.16  33.16  29.45\n",
      "  34.19  33.93  28.31  26.3   29.43  28.76  27.34  36.26  45.48  44.16\n",
      "  37.26  37.2   36.76  37.05  37.51  14.92  15.24  15.03  15.35  14.67\n",
      "  15.09  15.2   15.64  15.37  15.73  15.83  16.13  15.95  15.59  16.17\n",
      "  16.14  19.65  19.76  20.37  19.9   15.41  15.56  15.07  15.38  29.53\n",
      "  29.77  30.    30.2   32.25  32.    37.19  35.62  28.02  29.43  34.15\n",
      "  33.47  26.53  26.08  29.31  28.14  37.54  36.66  45.28  43.73  36.93\n",
      "  37.01  35.73  36.15  14.48  14.58  14.81  14.03  15.27  14.71  15.23\n",
      "  14.97  15.14  14.97  15.22  14.6   15.83  16.03  15.8   16.06  20.13\n",
      "  20.01  20.19  20.29  15.19  14.61  14.61  14.75  33.37  33.34  32.83\n",
      "  33.04  39.28  36.38  35.92  40.99  35.99  30.66  31.7   36.73  31.71\n",
      "  29.13  28.99  33.54  45.29  39.07  38.35  46.94  39.55  40.85  40.63\n",
      "  39.48  16.94  17.25  17.03  17.25  17.1   17.51  17.12  17.47  16.5   17.\n",
      "  16.87  17.2   18.14  18.03  18.14  17.95  22.72  22.73  22.72  22.53\n",
      "  17.2   17.21  17.15  17.2   32.96  33.13  33.94  33.78  38.35  35.39\n",
      "  34.94  40.66  35.48  30.53  32.28  36.86  30.34  27.93  28.95  32.92\n",
      "  45.59  39.41  38.84  48.03  39.48  40.4   40.47  39.7   16.43  16.93\n",
      "  16.99  17.03  16.77  17.37  17.27  17.51  16.44  17.01  17.23  17.22\n",
      "  17.85  17.89  18.36  18.15  21.72  22.07  22.09  21.93  17.36  17.38\n",
      "  16.86  16.99  32.78  33.24  33.86  34.    37.26  35.04  33.82  33.31\n",
      "  35.22  34.7   30.11  31.6   32.43  30.65  29.77  29.64  46.44  44.18\n",
      "  38.81  38.23  38.17  38.48  39.66  40.1   16.08  15.39  16.57  16.6\n",
      "  16.11  15.47  16.7   16.1   16.35  15.84  16.99  17.02  17.04  17.63\n",
      "  18.1   18.22  20.78  20.72  21.54  21.53  16.9   17.14  16.56  16.    32.95\n",
      "  33.06  33.95  33.88  33.98  39.92  39.22  36.1   31.53  36.2   36.21  31.\n",
      "  28.2   32.35  31.14  28.43  38.33  47.59  46.23  39.56  40.36  39.67\n",
      "  39.85  40.77  16.61  16.74  16.9   17.32  16.85  17.2   17.23  17.74\n",
      "  16.81  16.88  16.9   17.39  17.86  17.82  18.36  18.24  21.68  21.54\n",
      "  22.25  22.49  17.1   16.79  16.58  16.79  32.88  33.23  33.76  34.01\n",
      "  33.94  33.14  38.79  37.27  29.69  31.2   36.26  35.71  29.93  29.56\n",
      "  33.84  32.54  38.56  37.7   47.01  44.87  39.37  39.8   37.79  38.18\n",
      "  16.69  16.62  16.94  16.7   15.59  14.58  15.33  15.31  16.63  15.87\n",
      "  16.54  16.74  17.64  17.79  17.55  18.06  20.82  20.21  20.71  21.4\n",
      "  16.88  17.11  16.61  16.03]\n",
      "mean, std [  7.64166667e-01   6.71708333e+02   3.18500000e+02   1.76604167e+02\n",
      "   5.25000000e+00   3.50000000e+00   2.34375000e-01   2.81250000e+00] [  0.10570859  88.02874964  43.59806953  45.13653573   1.75         1.11803399\n",
      "   0.1331338    1.5499496 ]\n",
      "Eliminate missing values: mean, std [  7.64166667e-01   6.71708333e+02   3.18500000e+02   1.76604167e+02\n",
      "   5.25000000e+00   3.50000000e+00   2.34375000e-01   2.81250000e+00] [  0.10570859  88.02874964  43.59806953  45.13653573   1.75         1.11803399\n",
      "   0.1331338    1.5499496 ]\n",
      "Data after x standardizing [[ 2.04177671 -1.78587489 -0.56195149 ..., -1.34164079 -1.76044698\n",
      "  -1.81457514]\n",
      " [ 2.04177671 -1.78587489 -0.56195149 ..., -0.4472136  -1.76044698\n",
      "  -1.81457514]\n",
      " [ 2.04177671 -1.78587489 -0.56195149 ...,  0.4472136  -1.76044698\n",
      "  -1.81457514]\n",
      " ..., \n",
      " [-1.36381225  1.55394308  1.12390297 ..., -0.4472136   1.2440492\n",
      "   1.41133622]\n",
      " [-1.36381225  1.55394308  1.12390297 ...,  0.4472136   1.2440492\n",
      "   1.41133622]\n",
      " [-1.36381225  1.55394308  1.12390297 ...,  1.34164079  1.2440492\n",
      "   1.41133622]]\n",
      "mean, std [  7.64166667e-01   6.71708333e+02   3.18500000e+02   1.76604167e+02\n",
      "   5.25000000e+00   3.50000000e+00   2.34375000e-01   2.81250000e+00] [  0.10570859  88.02874964  43.59806953  45.13653573   1.75         1.11803399\n",
      "   0.1331338    1.5499496 ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing, cross_validation, neighbors\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.externals import joblib\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "datasetName = 'EnergyEfficiency.data'\n",
    "datasetDelimiter = ','\n",
    "\n",
    "# load the CSV file as a numpy matrix\n",
    "dataset = np.loadtxt(datasetName, delimiter=datasetDelimiter, skiprows=1) #Nos saltamos la cabecera\n",
    "print dataset.shape\n",
    "# separate the data from the target attributes\n",
    "xRaw = dataset[:,0:dataset.shape[1]-1]\n",
    "y = dataset[:,dataset.shape[1]-1]\n",
    "print \"xRaw, y\", xRaw, y\n",
    "print \"mean, std\", xRaw.mean(axis=0), xRaw.std(axis=0)\n",
    "# missing values\n",
    "imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "xPrep = imp.fit_transform(xRaw)\n",
    "print \"Eliminate missing values: mean, std\", xPrep.mean(axis=0), xPrep.std(axis=0)\n",
    "#Standardize data\n",
    "scaler = preprocessing.StandardScaler().fit(xPrep)\n",
    "x=scaler.transform(xPrep)\n",
    "print \"Data after x standardizing\", x\n",
    "print \"mean, std\", scaler.mean_, scaler.scale_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apartado b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la página web de la documentación oficial de Scikit-Learn para esta clase http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html podemos ver\n",
    "\n",
    "- Parámetros\n",
    "\n",
    "n_neighbors : int, optional (default = 5)\n",
    "\n",
    "    Number of neighbors to use by default for k_neighbors queries.\n",
    "\n",
    "weights : str or callable\n",
    "\n",
    "    weight function used in prediction. Possible values:\n",
    "\n",
    "        ‘uniform’ : uniform weights. All points in each neighborhood are weighted equally.\n",
    "        ‘distance’ : weight points by the inverse of their distance. in this case, closer neighbors of a query point will have a greater influence than neighbors which are further away.\n",
    "        [callable] : a user-defined function which accepts an array of distances, and returns an array of the same shape containing the weights.\n",
    "\n",
    "    Uniform weights are used by default.\n",
    "\n",
    "algorithm : {‘auto’, ‘ball_tree’, ‘kd_tree’, ‘brute’}, optional\n",
    "\n",
    "    Algorithm used to compute the nearest neighbors:\n",
    "\n",
    "        ‘ball_tree’ will use BallTree\n",
    "        ‘kd_tree’ will use KDtree\n",
    "        ‘brute’ will use a brute-force search.\n",
    "        ‘auto’ will attempt to decide the most appropriate algorithm based on the values passed to fit method.\n",
    "\n",
    "    Note: fitting on sparse input will override the setting of this parameter, using brute force.\n",
    "\n",
    "leaf_size : int, optional (default = 30)\n",
    "\n",
    "    Leaf size passed to BallTree or KDTree. This can affect the speed of the construction and query, as well as the memory required to store the tree. The optimal value depends on the nature of the problem.\n",
    "\n",
    "metric : string or DistanceMetric object (default=’minkowski’)\n",
    "\n",
    "    the distance metric to use for the tree. The default metric is minkowski, and with p=2 is equivalent to the standard Euclidean metric. See the documentation of the DistanceMetric class for a list of available metrics.\n",
    "\n",
    "p : integer, optional (default = 2)\n",
    "\n",
    "    Power parameter for the Minkowski metric. When p = 1, this is equivalent to using manhattan_distance (l1), and euclidean_distance (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.\n",
    "\n",
    "metric_params : dict, optional (default = None)\n",
    "\n",
    "    Additional keyword arguments for the metric function.\n",
    "\n",
    "n_jobs : int, optional (default = 1)\n",
    "\n",
    "    The number of parallel jobs to run for neighbors search. If -1, then the number of jobs is set to the number of CPU cores. Doesn’t affect fit method.\n",
    "\n",
    "\n",
    "- Métodos\n",
    "\n",
    "    - fit(X, y) \tFit the model using X as training data and y as target values\n",
    "    - get_params([deep]) \tGet parameters for this estimator.\n",
    "    - kneighbors([X, n_neighbors, return_distance]) \tFinds the K-neighbors of a point.\n",
    "    - kneighbors_graph([X, n_neighbors, mode]) \tComputes the (weighted) graph of k-Neighbors for points in X\n",
    "    - predict(X) \tPredict the target for the provided data\n",
    "    - score(X, y[, sample_weight]) \tReturns the coefficient of determination R^2 of the prediction.\n",
    "    - set_params(\\*\\*params) \tSet the parameters of this estimator.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apartado c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xTrain [[-0.22861593  0.16235226 -1.68585446 ...,  1.34164079  1.2440492\n",
      "  -0.5242106 ]\n",
      " [-0.03941654 -0.1159659   2.24780595 ...,  0.4472136  -1.00932293\n",
      "  -0.5242106 ]\n",
      " [ 1.28497917 -1.22923856  0.         ...,  1.34164079 -1.00932293\n",
      "   1.41133622]\n",
      " ..., \n",
      " [ 1.28497917 -1.22923856  0.         ..., -0.4472136   1.2440492\n",
      "   0.12097168]\n",
      " [-0.51241501  0.44067043 -1.12390297 ...,  1.34164079  1.2440492\n",
      "  -1.16939287]\n",
      " [ 0.52818162 -0.67260223  0.         ..., -1.34164079  1.2440492\n",
      "   0.76615395]] \n",
      "xTest [[-0.98541347  0.99730676  0.         ..., -0.4472136   1.2440492\n",
      "   0.12097168]\n",
      " [-0.22861593  0.16235226 -1.68585446 ...,  0.4472136  -1.00932293\n",
      "  -0.5242106 ]\n",
      " [ 0.24438254 -0.39428407  0.56195149 ..., -0.4472136  -1.00932293\n",
      "  -0.5242106 ]\n",
      " ..., \n",
      " [-0.98541347  0.99730676  0.         ...,  0.4472136  -1.00932293\n",
      "   0.76615395]\n",
      " [-1.36381225  1.55394308  1.12390297 ...,  1.34164079  0.11736313\n",
      "   1.41133622]\n",
      " [-1.36381225  1.55394308  1.12390297 ..., -1.34164079  0.11736313\n",
      "  -0.5242106 ]] \n",
      "yTrain [ 17.03  34.17  33.01  27.54  15.95  25.72  36.85  15.81  25.63  32.83\n",
      "  16.19  21.93  15.8   35.22  15.19  35.99  40.4   15.2   31.27  44.87\n",
      "  33.88  25.98  33.37  27.25  16.81  25.64  13.65  39.56  34.15  12.22\n",
      "  15.33  24.61  13.87  14.94  27.84  15.14  14.37  15.64  20.71  14.21\n",
      "  18.14  15.87  18.22  25.68  14.18  29.68  17.01  14.97  11.93  19.76\n",
      "  27.69  35.92  14.28  18.14  15.19  15.73  25.02  17.25  34.73  29.44\n",
      "  15.5   14.34  26.18  27.76  32.71  14.48  45.13  15.32  16.74  14.83\n",
      "  35.29  32.12  34.11  14.09  15.77  17.55  11.73  38.35  15.44  16.88\n",
      "  15.44  17.79  32.43  27.4   32.83  20.21  37.28  40.99  27.17  34.43\n",
      "  17.95  31.71  33.24  23.77  41.22  18.36  33.04  21.54  25.11  33.17\n",
      "  17.89  24.93  18.24  16.62  27.34  14.67  36.38  30.53  16.13  16.85\n",
      "  28.95  31.53  24.93  29.52  29.69  25.16  20.19  20.13  30.91  36.76\n",
      "  37.76  17.2   19.34  39.22  43.66  14.58  13.21  16.61  16.11  28.61\n",
      "  35.1   14.14  29.31  30.2   26.18  32.25  14.86  19.25  13.77  14.67\n",
      "  39.8   33.78  27.57  34.19  25.95  15.84  15.95  14.58  19.43  37.29\n",
      "  14.4   21.33  12.08  13.49  36.26  29.61  31.9   14.75  17.38  14.2\n",
      "  15.56  29.36  27.38  33.62  29.43  36.87  34.45  15.07  15.83  14.11\n",
      "  37.05  40.85  14.92  17.36  14.29  10.94  14.73  18.36  38.18  29.9\n",
      "  21.33  15.    16.27  30.19  19.37  26.53  37.58  44.18  14.89  16.77\n",
      "  47.59  14.49  37.26  21.09  20.03  15.77  15.85  40.77  20.01  35.71\n",
      "  36.66  15.83  32.    33.52  32.96  41.07  15.59  33.06  29.79  35.28\n",
      "  30.12  13.8   41.26  22.73  16.63  30.02  38.81  19.34  37.01  29.6\n",
      "  32.77  17.23  37.58  30.65  39.28  19.18  20.29  37.41  14.67  31.01\n",
      "  29.58  11.29  19.87  36.21  32.54  36.1   33.31  33.94  14.34  20.72\n",
      "  30.89  27.31  35.73  33.64  30.12  13.65  21.68  15.03  34.25  32.46\n",
      "  14.81  45.48  34.5   12.4   31.6   31.14  34.    30.17  33.76  28.14\n",
      "  16.57  34.29  13.67  25.9   29.62  31.73  26.08  43.8   17.1   16.93\n",
      "  37.72  45.59  36.62  20.28  20.37  25.35  26.29  22.49  16.03  16.03\n",
      "  15.1   15.24  16.99  13.53  18.15  36.85  13.48  19.26  17.    28.27\n",
      "  16.06  28.28  21.72  37.12  39.48  35.62  33.95  25.38  14.57  17.12\n",
      "  14.74  33.82  20.48  32.35  29.79  40.36  14.54  14.24  14.26  20.46\n",
      "  29.93  19.18  15.53  13.67  39.67  15.21  33.16  15.89  13.39  14.61\n",
      "  15.31  21.46  29.77  37.51  37.79  33.84  43.12  16.7   14.28  20.43\n",
      "  14.97  31.7   29.45  39.07  22.53  25.87  13.89  33.91  35.48  17.11\n",
      "  33.85  27.36  37.73  28.51  16.17  29.43  17.86  25.63  28.99  33.47\n",
      "  16.79  21.19  19.9   29.53  45.28  27.89  16.9   36.44  22.72  14.5\n",
      "  29.59  14.45  40.1   16.35  15.57  16.61  17.51  17.32  15.48  37.35\n",
      "  34.07  15.22  14.71  35.56  14.12  21.54  25.84  29.79  11.72  33.87\n",
      "  15.27  22.09  14.44  13.6   34.52  20.47  36.2   17.14  16.7   36.86\n",
      "  14.23  19.23  28.76  38.17  28.88  33.98  29.28  33.23  15.39  19.24\n",
      "  12.05  19.37  12.07  32.64  24.91  29.56  29.92  14.96  17.21  28.38\n",
      "  28.61  13.71  32.93  46.94  29.13  16.1   46.23  38.48  13.36  36.73\n",
      "  30.11  15.8   19.32  34.11  39.66  38.23  20.78  17.74  19.42  43.33\n",
      "  10.9   15.64  13.2   13.54  26.96  28.79  34.48  25.16  36.16  16.94\n",
      "  14.46  16.6   32.92  17.85  14.61  14.15  15.59  16.39  13.72  14.03\n",
      "  14.86  48.03  29.43  34.07  15.37  11.19  24.8   32.85  31.73  33.37\n",
      "  15.09  40.47  19.3   34.25  15.78  38.33  25.82  44.16  14.72  17.51\n",
      "  39.44  21.13  33.98  13.75  14.42  14.33  14.6   19.24  13.99  27.93\n",
      "  38.79  26.3   19.14  15.99  16.56  16.94  14.39  16.79  13.59  11.74\n",
      "  14.28  45.52  27.87  16.67  13.88  12.4   27.03  16.8   14.76  16.87\n",
      "  43.3   34.14  38.84  13.79  17.15  26.13  20.56  13.32  29.4   21.53\n",
      "  17.25  15.66  15.14  15.3   31.76  15.52  17.03  17.23  30.19  36.12\n",
      "  34.99  17.27  33.91  14.27  47.01  18.06  13.36  35.39  37.81  16.5\n",
      "  15.85  14.73  17.04  14.24  13.46  13.51  31.2   12.04  16.39  25.81\n",
      "  13.9   34.7   18.03  17.22  26.95  19.32  14.3   14.89  33.78  29.49\n",
      "  25.6   15.63  34.18  37.27  33.93  16.75  22.07  36.35  15.76  14.28\n",
      "  28.02  40.63  29.87  16.58  13.2   11.27  13.83  15.35  15.23  33.88\n",
      "  29.67  29.82  22.25  33.54  45.29  29.64  16.74  13.44  29.79  16.26\n",
      "  26.14  17.02  14.27  25.89  36.26  14.35  17.82  42.86  13.43  30.66\n",
      "  39.92  15.87  14.3   13.65  39.48  37.19  16.88  15.28  28.77  16.43\n",
      "  19.65  34.14  39.7   16.54  14.81  34.01  21.97  36.81  17.39  21.4\n",
      "  25.91  35.04  17.47  28.2 ] \n",
      "yTest [ 17.63  13.57  34.62  21.16  33.34  34.2   30.18  30.34  29.82  24.61\n",
      "  11.67  38.35  14.65  39.41  37.7   31.06  13.87  34.33  15.38  15.4\n",
      "  14.38  33.13  14.14  43.86  11.17  17.37  14.47  16.69  14.27  37.54\n",
      "  13.97  16.14  46.44  16.22  29.78  36.07  16.08  36.93  17.2   16.78\n",
      "  13.7   36.77  17.2   26.41  27.3   26.02  13.89  15.17  32.83  31.    33.94\n",
      "  14.27  34.05  17.64  37.2   13.7   21.33  31.39  37.26  16.9   18.1\n",
      "  14.91  33.86  13.72  15.85  14.49  45.97  14.55  32.04  36.87  32.78\n",
      "  13.79  24.77  16.86  19.48  29.88  32.95  43.73  32.88  17.1   40.66\n",
      "  30.08  13.72  14.61  32.54  26.72  25.88  30.93  14.37  16.99  16.99\n",
      "  31.28  15.5   26.44  39.55  17.2   29.77  16.44  12.14  37.28  35.1\n",
      "  28.68  23.49  33.87  13.5   28.31  38.56  16.14  15.42  21.33  20.82\n",
      "  33.89  32.28  19.29  14.94  19.29  14.87  43.14  27.33  39.37  33.14\n",
      "  15.18  15.44  34.94  14.74  39.85  16.9   30.1   14.92  29.69  33.67\n",
      "  26.37  41.86  13.79  36.15  12.23  28.43  26.47  34.35  15.47  21.08\n",
      "  22.72  29.34  13.8   41.68  16.    32.92  37.45  14.92  15.41  30.    15.\n",
      "  14.75  15.32]\n"
     ]
    }
   ],
   "source": [
    "#Divide in training and test, shuffling the examples and keeping the proportion of examples of each class\n",
    "xTrain, xTest, yTrain, yTest = cross_validation.train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "print 'xTrain', xTrain, \"\\nxTest\", xTest, \"\\nyTrain\", yTrain, \"\\nyTest\", yTest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apartado d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters Cross-Validation {'n_neighbors': 3, 'weights': 'uniform'}\n",
      "0.899153 (+/-0.035186) for {'n_neighbors': 1, 'weights': 'uniform'}\n",
      "()\n",
      "0.899153 (+/-0.035186) for {'n_neighbors': 1, 'weights': 'distance'}\n",
      "()\n",
      "0.917060 (+/-0.013370) for {'n_neighbors': 2, 'weights': 'uniform'}\n",
      "()\n",
      "0.917084 (+/-0.013840) for {'n_neighbors': 2, 'weights': 'distance'}\n",
      "()\n",
      "0.922651 (+/-0.011406) for {'n_neighbors': 3, 'weights': 'uniform'}\n",
      "()\n",
      "0.922485 (+/-0.012137) for {'n_neighbors': 3, 'weights': 'distance'}\n",
      "()\n",
      "0.918388 (+/-0.011876) for {'n_neighbors': 4, 'weights': 'uniform'}\n",
      "()\n",
      "0.919772 (+/-0.012610) for {'n_neighbors': 4, 'weights': 'distance'}\n",
      "()\n",
      "0.911244506293\n",
      "Para los scores de test del CV [7, 7, 6, 5, 1, 2, 4, 3] el mejor ranking es 1 y pertenece al pliegue cuyo n_vecinos es 3 y su peso uniform\n",
      "[0.035125161661899967, 0.035125161661899947, 0.01334714258002808, 0.013813461158532702, 0.011391887833230387, 0.012119557336485731, 0.011868306382685384, 0.012600078072999708]\n",
      "0.911259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moises/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "/home/moises/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n",
      "/home/moises/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg0AAAFdCAYAAACAfl7+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSVIVQ4MkSapiaJAkSVX+HzMDMhnLf5p7AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbb07738d50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg0AAAFdCAYAAACAfl7+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbb420a5a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La estimacion de CV-5 era 0.911245 y el resultado del test es 0.920\n"
     ]
    }
   ],
   "source": [
    "#NOTA IMPORTANTE: Le quito el redondeo a tres decimales y se lo dejo a 4 porque para este problema tenemos que ser \n",
    "#algo más precisos ya que la estimación que me da está en el mismo o muy cerca de uno de los puntos frontera\n",
    "\n",
    "hyperParams = {'n_neighbors': range(1,5),\n",
    "               'weights': ['uniform', 'distance']}\n",
    "\n",
    "#Create an instance of Neighbors Reggresor and fit the data for the grid parameters\n",
    "modelCV = GridSearchCV(neighbors.KNeighborsRegressor(), \n",
    "                     hyperParams, cv=5, scoring=None)\n",
    "modelCV.fit(xTrain, yTrain)\n",
    "print \"Best hyperparameters Cross-Validation\", modelCV.best_params_\n",
    "neighList, errList, devList = [], [], []\n",
    "i = 0\n",
    "estimacionCV1 = float(\"inf\")\n",
    "for hyperP, mean_score, scores in modelCV.grid_scores_:\n",
    "    print(\"%0.4f (+/-%0.4f) for %r\"\n",
    "              % (mean_score, scores.std(), hyperP))\n",
    "    if hyperP['weights'] == modelCV.best_params_['weights']:\n",
    "        neighList.append(hyperP['n_neighbors'])\n",
    "        errList.append(mean_score)\n",
    "        devList.append(scores.std())\n",
    "        if hyperP['n_neighbors'] == modelCV.best_params_['n_neighbors']:\n",
    "                estimacionCV1 = mean_score - scores.std()\n",
    "    print()    \n",
    "print(\"%0.4f\" % estimacionCV1)\n",
    "\n",
    "#Ahora comprobamos con los demás resultados entre los que se haya el vector de ranking (scikit-learn v0.18.1)\n",
    "\n",
    "#print \"Resultados:\", modelCV.cv_results_\n",
    "oserList = list(modelCV.cv_results_['rank_test_score'])\n",
    "#Escogemos el que mejor ranking que normalmente será 1\n",
    "regla_un_error_estandar = min(oserList)\n",
    "#Nos quedamos con el primer índice que cumpla la regla\n",
    "indice = [i for i,x in enumerate(oserList) if x == regla_un_error_estandar][0] \n",
    "vecinos = modelCV.grid_scores_[indice][0]['n_neighbors']\n",
    "#print(vecinos)\n",
    "peso = modelCV.grid_scores_[indice][0]['weights']\n",
    "#print(peso)\n",
    "print(\"Para los scores de test del CV %r el mejor ranking es %i y pertenece al pliegue cuyo n_vecinos es %i y su peso %s\" \n",
    "      % (oserList, regla_un_error_estandar, vecinos, peso))\n",
    "#Según la teoría vista en clase (transparencias 23 y 25 del tema 1) debería de escoger el pliegue que \n",
    "#cumpla con la regla 'one-standar-error-rule'. Scikit-Learn ya nos facilita un vector con el ranking de los\n",
    "#mejores test scores.\n",
    "\n",
    "#Aplicamos la regla para quedarnos el mínimo t (esa será nuestra estimación del error de test del CV)\n",
    "print(list(modelCV.cv_results_['std_test_score']))\n",
    "estimacionCV2 = list(modelCV.cv_results_['mean_test_score'])[indice]-list(modelCV.cv_results_['std_test_score'])[indice]\n",
    "print(\"%0.4f\" % estimacionCV2)\n",
    "\n",
    "#Por diferencias que desconozco entre los grid_scrores_ y los cv_results_ para este problema en concreto no coinciden\n",
    "#como las listas de datos para los plots se toman de los grid_scores por coherencia me quedaré con la estimación de éste.\n",
    "estimacionCV = estimacionCV1\n",
    "\n",
    "#De entre todos los pliegues de la validación cruzada, elige como mejores hiperparámetros el pliegue\n",
    "#cuyo número de vecinos es 3 y su peso es uniforme con el score 0.9227, y desviación estándar de +/- 0.0114,\n",
    "#el cual como hemos podido ver es el que mejor ranking de test scores tiene.\n",
    "plt.errorbar(neighList, errList, yerr = devList)\n",
    "plt.xlim(neighList[0]-1, neighList[len(neighList)-1]+1)\n",
    "plt.ylim(errList[0]-0.1, errList[len(errList)-1]+0.1)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "model = neighbors.KNeighborsRegressor(n_neighbors = modelCV.best_params_['n_neighbors'], \n",
    "                                       weights = modelCV.best_params_['weights'])\n",
    "model.fit(xTrain, yTrain)\n",
    "precision_media = model.score(xTest,yTest)\n",
    "\n",
    "plt.errorbar(neighList, errList, yerr = devList)\n",
    "plt.xlim(neighList[0]-1, neighList[len(neighList)-1]+1)\n",
    "plt.ylim(errList[0]-0.1, errList[len(errList)-1]+0.1)\n",
    "plt.plot(modelCV.best_params_['n_neighbors'], precision_media, 'ro')\n",
    "plt.show()\n",
    "print(\"La estimacion de CV-5 era %0.4f y el resultado del test es %0.4f\" % (estimacionCV, precision_media))\n",
    "#Podemos observar que la estimación de la Validación Cruzada de 5 pliegues ha sido bastante buena ya que se aproxima \n",
    "#mucho, estimaciónCV1 estimaba 0.9112 y estimaciónCV2 estimaba 0.9113, y al final ha sido 0.9205, \n",
    "#si tomamos la estimaciónCV2  está dentro del rango (0.9113,0.9341) si tomamos la estimaciónCV1 no por muy poco,\n",
    "#esto último puede deberse a temas de redondeos pero de un modo u otro o está justo en el punto frontera o\n",
    "#muy cerca de él."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
